<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>简介 on HTTP 协议学习笔记</title>
    <link>https://example.com/http/</link>
    <description>Recent content in 简介 on HTTP 协议学习笔记</description>
    <generator>Hugo -- gohugo.io</generator><atom:link href="https://example.com/http/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>1.1 基础概念</title>
      <link>https://example.com/http/docs/part1-overview/1.1-basic-concept/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/http/docs/part1-overview/1.1-basic-concept/</guid>
      <description>1.1 基础概念 # 1.1.1 请求和响应报文 # 客户端发送一个请求报文给服务器，服务器根据请求报文中的信息进行处理，并将处理结果放入响应报文中返回给客户端。
请求报文结构：
第一行是包含了请求方法、URL、协议版本； 接下来的多行都是请求首部 Header，每个首部都有一个首部名称，以及对应的值。 一个空行用来分隔首部和内容主体 Body 最后是请求的内容主体 GET http://www.example.com/ HTTP/1.1 Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9 Accept-Encoding: gzip, deflate Accept-Language: zh-CN,zh;q=0.9,en;q=0.8 Cache-Control: max-age=0 Host: www.example.com If-Modified-Since: Thu, 17 Oct 2019 07:18:26 GMT If-None-Match: &amp;#34;3147526947+gzip&amp;#34; Proxy-Connection: keep-alive Upgrade-Insecure-Requests: 1 User-Agent: Mozilla/5.0 xxx param1=1&amp;amp;param2=2 响应报文结构：
第一行包含协议版本、状态码以及描述，最常见的是 200 OK 表示请求成功了 接下来多行也是首部内容 一个空行分隔首部和内容主体 最后是响应的内容主体 HTTP/1.1 200 OK Age: 529651 Cache-Control: max-age=604800 Connection: keep-alive Content-Encoding: gzip Content-Length: 648 Content-Type: text/html; charset=UTF-8 Date: Mon, 02 Nov 2020 17:53:39 GMT Etag: &amp;#34;3147526947+ident+gzip&amp;#34; Expires: Mon, 09 Nov 2020 17:53:39 GMT Keep-Alive: timeout=4 Last-Modified: Thu, 17 Oct 2019 07:18:26 GMT Proxy-Connection: keep-alive Server: ECS (sjc/16DF) Vary: Accept-Encoding X-Cache: HIT &amp;lt;!</description>
    </item>
    
    <item>
      <title>2.1 代理</title>
      <link>https://example.com/http/docs/part2-break-ice/2.1-proxy/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/http/docs/part2-break-ice/2.1-proxy/</guid>
      <description>2.1 代理 # 代理最基本的一个功能是负载均衡。因为在面向客户端时屏蔽了源服务器，客户端看到的只是代理服务器，源服务器究竟有多少台、是哪些 IP 地址都不知道。于是代理服务器就可以掌握请求分发的 “大权”，决定由后面的哪台服务器来响应请求。
在负载均衡的同时，代理服务还可以执行更多的功能，比如：
健康检查：使用“心跳”等机制监控后端服务器，发现有故障就及时“踢出”集群，保证服务高可用；
安全防护：保护被代理的后端服务器，限制 IP 地址或流量，抵御网络攻击和过载；
加密卸载：对外网使用 SSL/TLS 加密通信认证，而在安全的内网不加密，消除加解密成本；
数据过滤：拦截上下行的数据，任意指定策略修改请求或者响应；
内容缓存：暂存、复用服务器响应。
2.1.1 匿名代理 # 匿名代理（Anonymous Proxy）用于隐藏客户端的真实 IP 地址，使客户端在互联网上的活动难以被追踪。匿名代理通常是由第三方提供的，客户端需要将网络流量转发给代理服务器，代理服务器会替代客户端向目标服务器发送请求，并将响应返回给客户端。
匿名代理的主要功能是隐藏客户端的真实 IP 地址，使客户端在互联网上的活动更加隐秘和安全。因为许多网站和服务都会记录访问者的 IP 地址，如果客户端使用匿名代理进行访问，就可以避免自己的真实 IP 地址被记录和追踪。匿名代理也可以用于访问被封锁的网站和服务，因为代理服务器的 IP 地址通常不会被封锁。
需要注意的是，匿名代理并不能完全保障客户端的隐私和安全，因为代理服务器仍然可以访问客户端的真实 IP 地址和网络流量。此外，一些不良的匿名代理可能会收集客户端的个人信息或恶意篡改网络流量，导致客户端的网络安全受到威胁。因此，使用匿名代理时应该选择可靠的服务提供商，并保持警惕。
2.1.2 透明代理 # 透明代理（Transparent Proxy）在转发客户端请求时不会修改任何请求头信息，目标服务器可以获取到客户端的真实 IP 地址和其他相关信息。透明代理通常是由 ISP（Internet Service Provider，互联网服务提供商）或公司内部网络部署的。
与匿名代理和高匿代理不同，透明代理不会对客户端的请求进行任何加密或隐藏，客户端无法隐匿自己的真实身份和位置。这种代理的主要作用是提高访问速度、节约带宽和监控网络流量。例如，ISP 可以通过透明代理实现流量控制、缓存加速、防火墙过滤等功能，公司可以通过透明代理实现员工网络访问的管理和监控。
需要注意的是，透明代理在传输数据时不会加密，因此在使用透明代理时，用户应该注意保护自己的数据安全。另外，一些不良的透明代理可能会篡改用户的网络流量或收集用户的个人信息，因此用户需要选择可靠的代理服务提供商，并保持警惕。
2.1.3 正向代理 # 正向代理的代理服务器是部署在客户端，而对服务端来说，它以为对它发起请求的是代理服务器，而真正请求的客户端对服务端来说是不可见的。
2.1.4 反向代理 # 反向代理的代理服务器是部署在服务端，而对客户端来说，它以为对它做出响应的是代理服务器，而真正响应的服务端对客户端来说是不可见的。
2.1.5 头字段 # Via # Via 是一个通用字段，请求头或响应头里都可以出现。每当报文经过一个代理节点，代理服务器就会把自身的信息追加到字段的末尾，就像是经手人盖了一个章。如果通信链路中有很多中间代理，就会在 Via 里形成一个链表，这样就可以知道报文究竟走过了多少个环节才到达了目的地。
X-Forwarded-For # “X-Forwarded-For” 的字面意思是 “为谁而转发”，形式上和 “Via” 差不多，也是每经过一个代理节点就会在字段里追加一个信息。但 “Via” 追加的是代理主机名（或者域名），而 “X-Forwarded-For” 追加的是请求方的 IP 地址。所以，在字段里最左边的 IP 地址就是客户端的地址。</description>
    </item>
    
    <item>
      <title>1.2 概述</title>
      <link>https://example.com/http/docs/part1-overview/1.2-net-overview/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/http/docs/part1-overview/1.2-net-overview/</guid>
      <description>1.2 概述 # 网络把主机连接起来，而互连网（internet）是把多种不同的网络连接起来，因此互连网是网络的网络。而互联网（Internet）是全球范围的互连网。
1.2.1 ISP # 互联网服务提供商 ISP（Internet Service Provider） 可以从互联网管理机构获得许多 IP 地址，同时拥有通信线路以及路由器等联网设备，个人或机构向 ISP 缴纳一定的费用就可以接入互联网。
目前的互联网是一种多层次 ISP 结构，ISP 根据覆盖面积的大小分为第一层 ISP、区域 ISP 和接入 ISP。互联网交换点 IXP（Internet Exchange Point） 允许两个 ISP 直接相连而不用经过第三个 ISP。
1.2.2 主机之间的通信方式 # 客户-服务器（C/S）：客户是服务的请求方，服务器是服务的提供方。 对等（P2P）：不区分客户和服务器。 1.2.3 电路交换与分组交换 # 电路交换 # 电路交换用于电话通信系统，两个用户要通信之前需要建立一条专用的物理链路，并且在整个通信过程中始终占用该链路。由于通信的过程中不可能一直在使用传输线路，因此电路交换对线路的利用率很低，往往不到 10%。
分组交换 # 每个分组都有首部和尾部，包含了源地址和目的地址等控制信息，在同一个传输线路上同时传输多个分组互相不会影响，因此在同一条传输线路上允许同时传输多个分组，也就是说分组交换不需要占用传输线路。
在一个邮局通信系统中，邮局收到一份邮件之后，先存储下来，然后把相同目的地的邮件一起转发到下一个目的地，这个过程就是存储转发过程，分组交换也使用了存储转发过程。
1.2.4 时延 # 总时延 = 排队时延 + 处理时延 + 传输时延 + 传播时延
排队时延 # 分组在路由器的输入队列和输出队列中排队等待的时间，取决于网络当前的通信量。
处理时延 # 主机或路由器收到分组时进行处理所需要的时间，例如分析首部、从分组中提取数据、进行差错检验或查找适当的路由等。
传输时延 # 主机或路由器传输数据帧所需要的时间。
其中l表示数据帧的长度，v表示传输速率。</description>
    </item>
    
    <item>
      <title>2.2 网络分层模型</title>
      <link>https://example.com/http/docs/part2-break-ice/2.2-network-layer-model/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/http/docs/part2-break-ice/2.2-network-layer-model/</guid>
      <description>2.2 网络分层模型 # 2.2.1 TCP/IP 网络分层模型 # TCP/IP 协议总共有四层，每一层需要下层的支撑，同时又支撑着上层，任何一层被抽掉都可能会导致整个协议栈坍塌。
第一层叫 “链接层”（link layer），负责在以太网、WiFi 这样的底层网络上发送原始数据包，工作在网卡这个层次，使用 MAC 地址来标记网络上的设备，所以有时候也叫 MAC 层。
第二层叫 “网际层 ”或者 “网络互连层”（internet layer），IP 协议就处在这一层。因为 IP 协议定义了 “IP 地址” 的概念，所以就可以在 “链接层” 的基础上，用 IP 地址取代 MAC 地址，把许许多多的局域网、广域网连接成一个虚拟的巨大网络，在这个网络里找设备时只要把 IP 地址再 “翻译” 成 MAC 地址就可以了。
第三层叫 “传输层”（transport layer），这个层次协议的职责是保证数据在 IP 地址标记的两点之间“可靠”地传输，是 TCP/UDP 协议工作的层次。TCP 是一个有状态的协议，需要先与对方建立连接然后才能发送数据，而且保证数据不丢失不重复。而 UDP 则比较简单，它无状态，不用事先建立连接就可以任意发送数据，但不保证数据一定会发到对方。两个协议的另一个重要区别在于数据的形式。TCP 的数据是连续的 “字节流”，有先后顺序，而 UDP 则是分散的小数据包，是顺序发，乱序收。
协议栈的第四层叫 “应用层”（application layer），由于有了下面的三层的基础，在这一层有各种面向具体应用的协议。例如 Telnet、SSH、FTP、SMTP 等等，当然还有 HTTP。
MAC 层的传输单位是帧（frame），IP 层的传输单位是包（packet），TCP 层的传输单位是段（segment），HTTP 的传输单位则是消息或报文（message）。但这些名词并没有什么本质的区分，可以统称为数据包。
2.2.2 OSI 网络分层模型 # OSI，全称是“开放式系统互联通信参考模型”（Open System Interconnection Reference Model）。由于 TCP/IP 诞生于 1970 年代，当时除了它还有很多其他的网络协议，整个网络世界比较混乱。这个时候国际标准组织（ISO）注意到了这种现象，感觉 “野路子” 太多，就想要来个 “大一统”。于是设计出了一个新的网络分层模型，想用这个新框架来统一既存的各种网络协议，这就是 OSI 模型的来历。OSI 模型分成了七层，部分层次与 TCP/IP 很像，从下到上分别是：</description>
    </item>
    
    <item>
      <title>1.3 物理层</title>
      <link>https://example.com/http/docs/part1-overview/1.3-physical-layer/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/http/docs/part1-overview/1.3-physical-layer/</guid>
      <description>1.3 物理层 # 通信方式 # 根据信息在传输线上的传送方向，分为以下三种通信方式：
单工通信：单向传输 半双工通信：双向交替传输 全双工通信：双向同时传输 带通调制 # 模拟信号是连续的信号，数字信号是离散的信号。带通调制把数字信号转换为模拟信号。</description>
    </item>
    
    <item>
      <title>2.3 实体数据</title>
      <link>https://example.com/http/docs/part2-break-ice/2.3-entity-data/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/http/docs/part2-break-ice/2.3-entity-data/</guid>
      <description>2.3 实体数据 # 2.3.1 MIME # “多用途互联网邮件扩展”（Multipurpose Internet Mail Extensions），简称为 MIME。
HTTP 用 MIME 标准规范来标记 body 的数据类型，这就是 “MIME type”。MIME 把数据分成了八大类，每个大类下再细分出多个子类，形式是“type/subtype” 的字符串。
简单列举一下在 HTTP 里经常遇到的几个类别：
text：文本格式的可读数据，最熟悉的应该就是 text/html 了，表示超文本文档，此外还有纯文本 text/plain、样式表 text/css 等。
image：图像文件，有 image/gif、image/jpeg、image/png 等。audio/video：音频和视频数据，例如 audio/mpeg、video/mp4 等。
application：数据格式不固定，可能是文本也可能是二进制，必须由上层应用程序来解释。常见的有 application/json，application/javascript、application/pdf 等，另外，如果实在是不知道数据是什么类型，像刚才说的 “黑盒”，就会是 application/octet-stream，即不透明的二进制数据。
HTTP 在传输时为了节约带宽，有时候还会压缩数据，为了不要让浏览器 “猜”，还需要有一个 “Encoding type”，告诉数据是用的什么编码格式，这样对方才能正确解压缩，还原出原始的数据。比起 MIME type 来说，Encoding type 就少了很多，常用的只有下面三种：
gzip：GNU zip 压缩格式，也是互联网上最流行的压缩格式；
deflate：zlib（deflate）压缩格式，流行程度仅次于 gzip；
br：一种专门为 HTTP 优化的新压缩算法（Brotli）。
Accept 字段标记的是客户端可理解的 MIME type，可以用 “,” 做分隔符列出多个类型，让服务器有更多的选择余地，例如下面的这个头：
Accept: text/html,application/xml,image/webp,image/png 这就是告诉服务器：“我能够看懂 HTML、XML 的文本，还有 webp 和 png 的图片，请给我这四类格式的数据”。相应的，服务器会在响应报文里用头字段 Content-Type 告诉实体数据的真实类型：</description>
    </item>
    
    <item>
      <title>1.4 链路层</title>
      <link>https://example.com/http/docs/part1-overview/1.4-link-layer/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/http/docs/part1-overview/1.4-link-layer/</guid>
      <description>1.4 链路层 # 1.4.1 基本问题 # 1. 封装成帧 # 将网络层传下来的分组添加首部和尾部，用于标记帧的开始和结束。
2. 透明传输 # 透明表示一个实际存在的事物看起来好像不存在一样。
帧使用首部和尾部进行定界，如果帧的数据部分含有和首部尾部相同的内容，那么帧的开始和结束位置就会被错误的判定。需要在数据部分出现首部尾部相同的内容前面插入转义字符。如果数据部分出现转义字符，那么就在转义字符前面再加个转义字符。在接收端进行处理之后可以还原出原始数据。这个过程透明传输的内容是转义字符，用户察觉不到转义字符的存在。
3. 差错检测 # 目前数据链路层广泛使用了循环冗余检验（CRC）来检查比特差错。
1.4.2 信道分类 # 1. 广播信道 # 一对多通信，一个节点发送的数据能够被广播信道上所有的节点接收到。
所有的节点都在同一个广播信道上发送数据，因此需要有专门的控制方法进行协调，避免发生冲突（冲突也叫碰撞）。
主要有两种控制方法进行协调，一个是使用信道复用技术，一是使用 CSMA/CD 协议。
2. 点对点信道 # 一对一通信。
因为不会发生碰撞，因此也比较简单，使用 PPP 协议进行控制。
1.4.3 信道复用技术 # 1. 频分复用 # 频分复用的所有主机在相同的时间占用不同的频率带宽资源。
2. 时分复用 # 时分复用的所有主机在不同的时间占用相同的频率带宽资源。
使用频分复用和时分复用进行通信，在通信的过程中主机会一直占用一部分信道资源。但是由于计算机数据的突发性质，通信过程没必要一直占用信道资源而不让出给其它用户使用，因此这两种方式对信道的利用率都不高。
3. 统计时分复用 # 是对时分复用的一种改进，不固定每个用户在时分复用帧中的位置，只要有数据就集中起来组成统计时分复用帧然后发送。
4. 波分复用 # 光的频分复用。由于光的频率很高，因此习惯上用波长而不是频率来表示所使用的光载波。
5. 码分复用 # 为每个用户分配 m bit 的码片，并且所有的码片正交，对于任意两个码片 和 有
为了讨论方便，取 m=8，设码片 为 00011011。在拥有该码片的用户发送比特 1 时就发送该码片，发送比特 0 时就发送该码片的反码 11100100。</description>
    </item>
    
    <item>
      <title>2.4 连接管理</title>
      <link>https://example.com/http/docs/part2-break-ice/2.4-connection-management/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/http/docs/part2-break-ice/2.4-connection-management/</guid>
      <description>2.4 连接管理 # 2.4.1 短连接与长连接 # HTTP 协议最初（0.9/1.0）是个非常简单的协议，通信过程也采用了简单的 “请求 - 应答” 方式。它底层的数据传输基于 TCP/IP，每次发送请求前需要先与服务器建立连接，收到响应报文后会立即关闭连接。因为客户端与服务器的整个连接过程很短暂，不会与服务器保持长时间的连接状态，所以就被称为 “短连接”（short-lived connections）。
早期的 HTTP 协议也被称为是 “无连接” 的协议。短连接的缺点相当严重，因为在 TCP 协议里，建立连接和关闭连接都是非常 “昂贵” 的操作
针对短连接暴露出的缺点，HTTP 协议就提出了 “长连接” 的通信方式，也叫 “持久连接”（persistent connections）、“连接保活”（keep alive）、“连接复用”（connection reuse）。
长连接使用的 “成本均摊” 的思路，既然 TCP 的连接和关闭非常耗时间，那么就把这个时间成本由原来的一个 “请求 - 应答” 均摊到多个 “请求 - 应答” 上。这样虽然不能改善 TCP 的连接效率，但基于 “分母效应”，每个 “请求 - 应答” 的无效时间就会降低不少，整体传输效率也就提高了。
由于长连接对性能的改善效果非常显著，所以在 HTTP/1.1 中的连接都会默认启用长连接。不需要用什么特殊的头字段指定，只要向服务器发送了第一次请求，后续的请求都会重复利用第一次打开的 TCP 连接，也就是长连接，在这个连接上收发数据。
2.4.2 关闭连接 # 因为 TCP 连接长时间不关闭，服务器必须在内存里保存它的状态，这就占用了服务器的资源。如果有大量的空闲长连接只连不发，就会很快耗尽服务器的资源，导致服务器无法为真正有需要的用户提供服务。所以，长连接也需要在恰当的时间关闭，不能永远保持与服务器的连接，这在客户端或者服务器都可以做到。
在客户端，可以在请求头里加上 “Connection: close” 字段，告诉服务器：“这次通信后就关闭连接”。服务器看到这个字段，就知道客户端要主动关闭连接，于是在响应报文里也加上这个字段，发送之后就调用 Socket API 关闭 TCP 连接。</description>
    </item>
    
    <item>
      <title>1.5 网络层</title>
      <link>https://example.com/http/docs/part1-overview/1.5-network-layer/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/http/docs/part1-overview/1.5-network-layer/</guid>
      <description>1.5 网络层 # 1.5.1 概述 # 因为网络层是整个互联网的核心，因此应当让网络层尽可能简单。网络层向上只提供简单灵活的、无连接的、尽最大努力交互的数据报服务。
使用 IP 协议，可以把异构的物理网络连接起来，使得在网络层看起来好像是一个统一的网络。
与 IP 协议配套使用的还有三个协议：
地址解析协议 ARP（Address Resolution Protocol） 网际控制报文协议 ICMP（Internet Control Message Protocol） 网际组管理协议 IGMP（Internet Group Management Protocol） 1.5.2 IP 数据报格式 # 版本 : 有 4（IPv4）和 6（IPv6）两个值；
首部长度 占 4 位，因此最大值为 15。值为 1 表示的是 1 个 32 位字的长度，也就是 4 字节。因为固定部分长度为 20 字节，因此该值最小为 5。如果可选字段的长度不是 4 字节的整数倍，就用尾部的填充部分来填充。 区分服务 : 用来获得更好的服务，一般情况下不使用。
总长度 : 包括首部长度和数据部分长度。
生存时间 ：TTL，它的存在是为了防止无法交付的数据报在互联网中不断兜圈子。以路由器跳数为单位，当 TTL 为 0 时就丢弃数据报。
协议 ：指出携带的数据应该上交给哪个协议进行处理，例如 ICMP、TCP、UDP 等。</description>
    </item>
    
    <item>
      <title>2.5 Cookie</title>
      <link>https://example.com/http/docs/part2-break-ice/2.5-cookie/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/http/docs/part2-break-ice/2.5-cookie/</guid>
      <description>2.5 Cookie # 2.5.1 什么是 Cookie # 当用户通过浏览器第一次访问服务器的时候，服务器肯定是不知道他的身份的。所以，就要创建一个独特的身份标识数据，格式是 “key=value”，然后放进 Set-Cookie 字段里，随着响应报文一同发给浏览器。
浏览器收到响应报文，看到里面有 Set-Cookie，知道这是服务器给的身份标识，于是就保存起来，下次再请求的时候就自动把这个值放进 Cookie 字段里发给服务器。因为第二次请求里面有了 Cookie 字段，服务器就知道这个用户不是新人，之前来过，就可以拿出 Cookie 里的值，识别出用户的身份，然后提供个性化的服务。服务器有时会在响应头里添加多个 Set-Cookie，存储多个 “key=value”。但浏览器这边发送时不需要用多个 Cookie 字段，只要在一行里用 “;” 隔开就行。
2.5.2 Cookie 的属性 # 生存周期 # Cookie 的生存周期，也就是它的有效期，让它只能在一段时间内可用，一旦超过这个期限浏览器就认为是 Cookie 失效，在存储里删除，也不会发送给服务器。
Cookie 的有效期可以使用 Expires 和 Max-Age 两个属性来设置。Expires 俗称过期时间，用的是绝对时间点，可以理解为截止日期（deadline）。Max-Age 用的是相对时间，单位是秒，浏览器用收到报文的时间点再加上 Max-Age，就可以得到失效的绝对时间。
Expires 和 Max-Age 可以同时出现，两者的失效时间可以一致，也可以不一致，但浏览器会优先采用 Max-Age 计算失效期。
如果不指定 Expires 或 Max-Age 属性，那么 Cookie 仅在浏览器运行时有效，一旦浏览器关闭就会失效，这被称为会话 Cookie (session cookie) 或内存 Cookie (in-memory cookie), 在 Chrome 浏览器里过期时间会显示为 “Session” 或 “N/A”。</description>
    </item>
    
    <item>
      <title>1.6 传输层</title>
      <link>https://example.com/http/docs/part1-overview/1.6-transport-layer/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/http/docs/part1-overview/1.6-transport-layer/</guid>
      <description>1.6 传输层 # 网络层只把分组发送到目的主机，但是真正通信的并不是主机而是主机中的进程。传输层提供了进程间的逻辑通信，传输层向高层用户屏蔽了下面网络层的核心细节，使应用程序看起来像是在两个传输层实体之间有一条端到端的逻辑通信信道。
1.6.1 UDP 和 TCP 的特点 # 用户数据报协议 UDP（User Datagram Protocol）是无连接的，尽最大可能交付，没有拥塞控制，面向报文（对于应用程序传下来的报文不合并也不拆分，只是添加 UDP 首部），支持一对一、一对多、多对一和多对多的交互通信。
传输控制协议 TCP（Transmission Control Protocol）是面向连接的，提供可靠交付，有流量控制，拥塞控制，提供全双工通信，面向字节流（把应用层传下来的报文看成字节流，把字节流组织成大小不等的数据块），每一条 TCP 连接只能是点对点的（一对一）。
1.6.2 UDP 首部格式 # 首部字段只有 8 个字节，包括源端口、目的端口、长度、检验和。12 字节的伪首部是为了计算检验和临时添加的。
1.6.3 TCP 首部格式 # 序号 ：用于对字节流进行编号，例如序号为 301，表示第一个字节的编号为 301，如果携带的数据长度为 100 字节，那么下一个报文段的序号应为 401。
确认号 ：期望收到的下一个报文段的序号。例如 B 正确收到 A 发送来的一个报文段，序号为 501，携带的数据长度为 200 字节，因此 B 期望下一个报文段的序号为 701，B 发送给 A 的确认报文段中确认号就为 701。
数据偏移 ：指的是数据部分距离报文段起始处的偏移量，实际上指的是首部的长度。
确认 ACK ：当 ACK=1 时确认号字段有效，否则无效。TCP 规定，在连接建立后所有传送的报文段都必须把 ACK 置 1。
同步 SYN ：在连接建立时用来同步序号。当 SYN=1，ACK=0 时表示这是一个连接请求报文段。若对方同意建立连接，则响应报文中 SYN=1，ACK=1。</description>
    </item>
    
    <item>
      <title>2.6 Cache</title>
      <link>https://example.com/http/docs/part2-break-ice/2.6-cache/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/http/docs/part2-break-ice/2.6-cache/</guid>
      <description>2.6 Cache # 2.6.1 服务端缓存控制 # 服务器标记资源有效期使用的头字段是 “Cache-Control”，里面的值 “max-age=30” 就是资源的有效时间，相当于告诉浏览器，“这个页面只能缓存 30 秒，之后就算是过期，不能用。”
除了 “Cache-Control&amp;rsquo;”，服务器也可以用 “Expires” 字段来标记资源的有效期，它的形式和 Cookie 的差不多，同样属于 “过时” 的属性，优先级低于 “Cache-Control&amp;rsquo;”。 还有一个历史遗留字段 “Pragma:no-cache”，它相当于 “Cache-Control: no-cache”，除非为了兼容HTTP/1.0 否则不建议使用。
这里的 max-age 是 “生存时间”（又叫“新鲜度” “缓存寿命”，类似 TTL，Time-To-Live），时间的计算起点是响应报文的创建时刻（即 Date 字段，也就是离开服务器的时刻），而不是客户端收到报文的时刻，也就是说包含了在链路传输过程中所有节点所停留的时间。
“max-age” 是 HTTP 缓存控制最常用的属性，此外在响应报文里还可以用其他的属性来更精确地指示浏览器应该如何使用缓存：
no-store：不允许缓存，用于某些变化非常频繁的数据，例如秒杀页面；
no-cache：它的字面含义容易与 no-store 搞混，实际的意思并不是不允许缓存，而是可以缓存，但在使用之前必须要去服务器验证是否过期，是否有最新的版本；
must-revalidate：又是一个和 no-cache 相似的词，它的意思是如果缓存不过期就可以继续使用，但过期了如果还想用就必须去服务器验证。
可以拿生鲜速递来举例说明一下：
no-store：买来的西瓜不允许放进冰箱，要么立刻吃，要么立刻扔掉；
no-cache：可以放进冰箱，但吃之前必须问超市有没有更新鲜的，有就吃超市里的；
must-revalidate：可以放进冰箱，保鲜期内可以吃，过期了就要问超市让不让吃。
2.6.2 客户端缓存控制 # 其实不止服务器可以发 “Cache-Control” 头，浏览器也可以发 “Cache-Control”，也就是说请求 - 应答的双方都可以用这个字段进行缓存控制，互相协商缓存的使用策略。
当点 “刷新” 按钮的时候，浏览器会在请求头里加一个 “Cache-Control: max-age=0”。因为 max-age 是 “生存时间”，max-age=0 的意思就是拿到最新的数据，而本地缓存里的数据至少保存了几秒钟，所以浏览器就不会使用缓存，而是向服务器发请求。服务器看到 max-age=0，也就会用一个最新生成的报文回应浏览器。
浏览器用 “Cache-Control” 做缓存控制只能是刷新数据，不能很好地利用缓存数据，又因为缓存会失效，使用前还必须要去服务器验证是否是最新版。所以 HTTP 协议就定义了一系列 “If” 开头的 “条件请求” 字段，专门用来检查验证资源是否过期，验证的责任交给服务器，浏览器只需 “坐享其成”。</description>
    </item>
    
    <item>
      <title>1.7 应用层</title>
      <link>https://example.com/http/docs/part1-overview/1.7-application-layer/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/http/docs/part1-overview/1.7-application-layer/</guid>
      <description>1.7 应用层 # 1.7.1 域名系统 # DNS 是一个分布式数据库，提供了主机名和 IP 地址之间相互转换的服务。这里的分布式数据库是指，每个站点只保留它自己的那部分数据。
域名具有层次结构，从上到下依次为：根域名、顶级域名、二级域名。
DNS 可以使用 UDP 或者 TCP 进行传输，使用的端口号都为 53。大多数情况下 DNS 使用 UDP 进行传输，这就要求域名解析器和域名服务器都必须自己处理超时和重传从而保证可靠性。在两种情况下会使用 TCP 进行传输：
如果返回的响应超过的 512 字节（UDP 最大只支持 512 字节的数据）。 区域传送（区域传送是主域名服务器向辅助域名服务器传送变化的那部分数据）。 1.7.2 文件传送协议 # FTP 使用 TCP 进行连接，它需要两个连接来传送一个文件：
控制连接：服务器打开端口号 21 等待客户端的连接，客户端主动建立连接后，使用这个连接将客户端的命令传送给服务器，并传回服务器的应答。 数据连接：用来传送一个文件数据。 根据数据连接是否是服务器端主动建立，FTP 有主动和被动两种模式：
主动模式：服务器端主动建立数据连接，其中服务器端的端口号为 20，客户端的端口号随机，但是必须大于 1024，因为 0~1023 是熟知端口号。 被动模式：客户端主动建立数据连接，其中客户端的端口号由客户端自己指定，服务器端的端口号随机。 主动模式要求客户端开放端口号给服务器端，需要去配置客户端的防火墙。被动模式只需要服务器端开放端口号即可，无需客户端配置防火墙。但是被动模式会导致服务器端的安全性减弱，因为开放了过多的端口号。
1.7.3 动态主机配置协议 # DHCP (Dynamic Host Configuration Protocol) 提供了即插即用的连网方式，用户不再需要手动配置 IP 地址等信息。
DHCP 配置的内容不仅是 IP 地址，还包括子网掩码、网关 IP 地址。
DHCP 工作过程如下：</description>
    </item>
    
    <item>
      <title>2.7 HTTPS</title>
      <link>https://example.com/http/docs/part2-break-ice/2.7-https/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/http/docs/part2-break-ice/2.7-https/</guid>
      <description>2.7 HTTPS # 2.7.1 什么是 https # 如果通信过程具备了四个特性，就可以认为是 “安全” 的，这四个特性是：机密性、完整性，身份认证和不可否认。HTTPS 为 HTTP 增加了这四大安全特性。
机密性由对称加密 AES 保证，完整性由 SHA384 摘要算法保证，身份认证和不可否认由RSA非对称加密保证
HTTPS 规定了新的协议名 “https”，默认端口号 443，至于其他的什么请求 - 应答模式、报文结构、请求方法、URI、头字段、连接管理等等都完全沿用 HTTP，没有任何新的东西。也就是说，除了协议名 “http” 和端口号 80 这两点不同，HTTPS 协议在语法、语义上和 HTTP 完全一样，优缺点也 “照单全收”（当然要除去 “明文” 和 “不安全”）。
HTTPS 把 HTTP 下层的传输协议由 TCP/IP 换成了 SSL/TLS，由 “HTTP over TCP/IP” 变成了 “HTTP over SSL/TLS”，让 HTTP 运行在了安全的 SSL/TLS 协议上，收发报文不再使用 Socket API，而是调用专门的安全接口。
2.7.2 SSL/TLS # SSL 即安全套接层（Secure Sockets Layer），在 OSI 模型中处于第 5 层（会话层），由网景公司于 1994 年发明，有 v2 和 v3 两个版本，而 v1 因为有严重的缺陷从未公开过。SSL 发展到 v3 时已经证明了它自身是一个非常好的安全通信协议，于是互联网工程组 IETF 在 1999 年把它改名为 TLS（传输层安全，Transport Layer Security），正式标准化，版本号从 1.</description>
    </item>
    
    <item>
      <title>1.8 Socket</title>
      <link>https://example.com/http/docs/part1-overview/1.8-socket/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/http/docs/part1-overview/1.8-socket/</guid>
      <description>1.8 Socket # 1.8.1 I/O 模型 # 一个输入操作通常包括两个阶段：
等待数据准备好 从内核向进程复制数据 对于一个套接字上的输入操作，第一步通常涉及等待数据从网络中到达。当所等待数据到达时，它被复制到内核中的某个缓冲区。第二步就是把数据从内核缓冲区复制到应用进程缓冲区。
Unix 有五种 I/O 模型：
阻塞式 I/O 非阻塞式 I/O I/O 复用（select 和 poll） 信号驱动式 I/O（SIGIO） 异步 I/O（AIO） 阻塞式 I/O # 请求数据时，若没有数据准备好，应用进程被阻塞，直到数据从内核缓冲区复制到应用进程缓冲区中才返回。
应该注意到，在阻塞的过程中，其它应用进程还可以执行，因此阻塞不意味着整个操作系统都被阻塞。因为其它应用进程还可以执行，所以不消耗 CPU 时间，这种模型的 CPU 利用率会比较高。
下图中，recvfrom() 用于接收 Socket 传来的数据，并复制到应用进程的缓冲区 buf 中。这里把 recvfrom() 当成系统调用。
ssize_t recvfrom(int sockfd, void *buf, size_t len, int flags, struct sockaddr *src_addr, socklen_t *addrlen); 非阻塞式 I/O # 应用进程执行系统调用之后，内核返回一个错误码。应用进程可以继续执行，但是需要不断的执行系统调用来获知 I/O 是否完成，这种方式称为轮询（polling）。
由于 CPU 要处理更多的系统调用，因此这种模型的 CPU 利用率比较低。</description>
    </item>
    
  </channel>
</rss>
