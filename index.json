[{"categories":["essays"],"content":"几年前，一位好朋友去世了，九零后，跟我年纪一样。我跟他从小就认识，我们一起上的小学，一起上的初中，高中之后便联系的少了，后来我去外地读书，联系的就更少了。 那还是二零一九，那时我刚从西安来北京。一天夜里，都很晚了，我妈打电话跟我说，他去世了，好像是心梗，让我在外面多注意身体。天啊，当我听到这个消息的时候，我简直不敢相信，我反复确认了几次，无疑的确是他。 那晚我很难过，因为我不久之前还见过他。二零一九的春节，那天应该是初二的早晨，我骑着电瓶车去外公家拜年，外公家跟他老家离的不远，就几步路，那天早晨我在路边看到了他，我没有停下来，心想就几步路，我回来的时候再去找他，但是等我再往回走的时候他就不在家了。如今听到噩耗，再想起这件事，我真的特别后悔当时应该停下来见他一面。后来，我把这件事说给我女朋友听，她也特别感慨的说，想做什么事一定要赶紧去做。是啊，一定要赶紧去做，毕竟世事无常。 我跟他太久没有联系了，没有他的电话，也没有他的微信，后来在QQ 里找到他的联系方式。我尝试着发了一条消息过去，QQ 的那边，他媳妇回了一条消息，说他人已经不在了。后来有个初中同学联系到了我，是他班上的，建了一个微信群，想尽点绵薄之力，我们一人凑了点钱，由一个在老家的同学给他家里送了去，但他妈妈只是领了我们的心意。他实在是太年轻了，而且新婚不久，孩子才一岁。 这张照片是上初中时我们一起去皖南事变烈士陵园拍的，也是我跟他唯一的一张合影。 2020 年时家里发大水，家里的东西都泡水了，这张照片后来也不知所踪。 左三是他\" 左三是他 有一次我回家，我爸还跟我说在一次婚宴上见过他。他过世后，一次在我大舅家吃饭的时候，他家的一个亲戚也在，在聊起他的时候，直夸他在外面干活能吃苦，人不错。 我跟他从小相识，一起在村小学读书，一起在田埂上疯跑，他教我掏鸟窝，网知了，在我眼里，他好像什么都会，他教了我很多技能，带给我很多快乐。上初中的时候，我跟他一起骑车上学，放学也一起回家。他每天早上都是骑着车来我外婆家等我，等我吃完早饭一起走，一路上我们有好几个同学都一起。下午放学他有时也在我外婆家跟我一起做完作业才回家，这些事如今历历在目，但是他却永远不在了。 也许是年纪大了，不知不觉对有些事越来越伤感。几次提笔想写点什么，但是每次都写不出来，心里总记挂这件事，可能是那次我没有停下来见他吧。 2021年10月15日完 ","date":"2022-03-16","objectID":"/old-pal/:0:0","tags":["随笔"],"title":"纪念一位老友","uri":"/old-pal/"},{"categories":["算法与数学"],"content":"LeetCode 热题 HOT 100,Leetcode,两数之和","date":"2022-03-25","objectID":"/hot100/","tags":["leetcode"],"title":"LeetCode 热题 HOT 100","uri":"/hot100/"},{"categories":["算法与数学"],"content":"1. 两数之和 题目地址：https://leetcode-cn.com/problems/two-sum/ ","date":"2022-03-25","objectID":"/hot100/:1:0","tags":["leetcode"],"title":"LeetCode 热题 HOT 100","uri":"/hot100/"},{"categories":["算法与数学"],"content":"解题思路 嵌套遍历数组，外层遍历的值和内层遍历的值相加，如果相加等于目标值，则返回结果，否则继续遍历。内层遍历开始的位置是外层遍历的位置加 1，结束的位置是数组长度。 ","date":"2022-03-25","objectID":"/hot100/:1:1","tags":["leetcode"],"title":"LeetCode 热题 HOT 100","uri":"/hot100/"},{"categories":["算法与数学"],"content":"go 实现 package main import \"fmt\" func twoSum(nums []int, target int) []int { for index, value := range nums { for i := index + 1; i \u003c len(nums); i++ { if (value + nums[i]) == target { return []int{index, i} } } } return nil } func main() { fmt.Println(twoSum([]int{3, 2, 4}, 6)) } ","date":"2022-03-25","objectID":"/hot100/:1:2","tags":["leetcode"],"title":"LeetCode 热题 HOT 100","uri":"/hot100/"},{"categories":["算法与数学"],"content":"20. 有效的括号 题目地址：https://leetcode-cn.com/problems/valid-parentheses/ ","date":"2022-03-25","objectID":"/hot100/:2:0","tags":["leetcode"],"title":"LeetCode 热题 HOT 100","uri":"/hot100/"},{"categories":["算法与数学"],"content":"解题思路 判断括号的有效性可以使用「栈」这一数据结构来解决。 我们遍历给定的字符串 s。当我们遇到一个左括号时，我们会期望在后续的遍历中，有一个相同类型的右括号将其闭合。由于后遇到的左括号要先闭合，因此我们可以将这个左括号放入栈顶。 当我们遇到一个右括号时，我们需要将一个相同类型的左括号闭合。此时，我们可以取出栈顶的左括号并判断它们是否是相同类型的括号。如果不是相同的类型，或者栈中并没有左括号，那么字符串 s 无效，返回 False。为了快速判断括号的类型，我们可以使用哈希表存储每一种括号。哈希表的键为右括号，值为相同类型的左括号。 在遍历结束后，如果栈中没有左括号，说明我们将字符串 s 中的所有左括号闭合，返回 True，否则返回 False。 注意到有效字符串的长度一定为偶数，因此如果字符串的长度为奇数，我们可以直接返回 False，省去后续的遍历判断过程。 ","date":"2022-03-25","objectID":"/hot100/:2:1","tags":["leetcode"],"title":"LeetCode 热题 HOT 100","uri":"/hot100/"},{"categories":["算法与数学"],"content":"go 实现 package main import \"fmt\" func isValid(s string) bool { n := len(s) if n%2 != 0 { // 奇数直接退出 return false } pairs := map[byte]byte{ ')': '(', ']': '[', '}': '{', } stack := []byte{} for i := 0; i \u003c n; i++ { if pairs[s[i]] \u003e 0 { // 如果是右括号,判断栈顶是否是对应的左括号,果然有对应的左括号,则弹出栈顶元素,否则直接退出 if len(stack) == 0 || stack[len(stack)-1] != pairs[s[i]] { return false } stack = stack[:len(stack)-1] } else { stack = append(stack, s[i]) } } return len(stack) == 0 } func main() { fmt.Println(isValid(\"()[]{}\")) } 版权信息 作者：LeetCode-Solution 链接：https://leetcode-cn.com/problem-list/2cktkvj 来源：力扣（LeetCode） ","date":"2022-03-25","objectID":"/hot100/:2:2","tags":["leetcode"],"title":"LeetCode 热题 HOT 100","uri":"/hot100/"},{"categories":["golang"],"content":"垃圾回收（Garbage Collection，GC）是编程语言中提供的自动的内存管理机制，自动释放不需要的内存对象，让出存储器资源。GC 过程中无需程序员手动执行。 GC 机制在现代很多编程语言都支持，GC 能力的性能与优劣也是不同语言之间对比度指标之一。 ","date":"2022-04-06","objectID":"/go-gc/:0:0","tags":["golang"],"title":"Go GC 原理","uri":"/go-gc/"},{"categories":["golang"],"content":"堆和栈 栈：由操作系统自动分配释放，存放函数的参数值，局部变量的值等。 堆：一般由程序员分配和释放，若程序员不释放，程序结束时可能由 OS 回收。 栈使用的是一级缓存，他们通常都是被调用时处于存储空间中，调用完毕立即释放。 堆则是存放在二级缓存中，生命周期由虚拟机的垃圾回收算法来决定，但并不是一旦成为孤儿对象就能被回收。 申请到栈内存好处：函数返回直接释放，不会引起垃圾回收，对性能没有影响。 ","date":"2022-04-06","objectID":"/go-gc/:1:0","tags":["golang"],"title":"Go GC 原理","uri":"/go-gc/"},{"categories":["golang"],"content":"标记清除算法 Go v1.3 之前使用普通的标记-清除（mark and sweep）算法，主要有两个主要的步骤： 标记(Mark phase)，找出不可达的对象，然后做上标记。 清除(Sweep phase)，回收标记好的对象。 ","date":"2022-04-06","objectID":"/go-gc/:2:0","tags":["golang"],"title":"Go GC 原理","uri":"/go-gc/"},{"categories":["golang"],"content":"第一步 暂停程序业务逻辑， 分类出可达和不可达的对象，然后做上标记。 程序与对象的可达关系程序与对象的可达关系 \" 程序与对象的可达关系 👆图中表示是程序与对象的可达关系，目前程序的可达对象有对象 1-2-3，对象 4-7 等五个对象。 ","date":"2022-04-06","objectID":"/go-gc/:2:1","tags":["golang"],"title":"Go GC 原理","uri":"/go-gc/"},{"categories":["golang"],"content":"第二步 开始标记，程序找出它所有可达的对象，并做上标记👇。 找出可达对象找出可达对象 \" 找出可达对象 对象 1-2-3 、对象 4-7 等五个对象被做上标记。 ","date":"2022-04-06","objectID":"/go-gc/:2:2","tags":["golang"],"title":"Go GC 原理","uri":"/go-gc/"},{"categories":["golang"],"content":"第三步 标记完了之后，然后开始清除未标记的对象。 清除对象清除对象 \" 清除对象 对象 5，6 不可达，被 GC 清除。 操作简单，但是，mark and sweep 算法在执行的时候，需要程序暂停！即 STW（stop the world），STW 的过程中，CPU 不执行用户代码，全部用于垃圾回收，这个过程的影响很大，所以 STW 也是一些回收机制最大的难题和希望优化的点。 在执行第三步的这段时间，程序会暂定停止任何工作，卡在那等待回收执行完毕。 ","date":"2022-04-06","objectID":"/go-gc/:2:3","tags":["golang"],"title":"Go GC 原理","uri":"/go-gc/"},{"categories":["golang"],"content":"第四步 停止暂停，让程序继续执行。然后循环重复这个过程，直到 process 程序生命周期结束。 ","date":"2022-04-06","objectID":"/go-gc/:2:4","tags":["golang"],"title":"Go GC 原理","uri":"/go-gc/"},{"categories":["golang"],"content":"缺点与优化 标记清除算法明了，过程鲜明干脆，但是也有非常严重的问题，就是 STW，让程序暂停，程序出现卡顿。 Go V1.3版本之前就是用这种方式来实施的。执行 GC 的基本流程就是首先启动 STW 暂停，然后执行标记，再执行数据回收，最后停止 STW ，如下图👇 STWSTW \" STW 从👆来看，全部的 GC 时间都是包裹在 STW 范围之内的，这样貌似程序暂停的时间过长，影响程序的运行性能。所以Go v1.3 做了简单的优化，将 STW 的步骤提前，减少 STW 暂停的时间范围 👇 STW优化STW优化 \" STW优化 主要是将 STW 的步骤提前了一步，因为在 Sweep 清除的时候，可以不需要 STW 停止，因为这些对象已经是不可达对象了，不会出现回收写冲突等问题，清除操作和用户逻辑可以并发。 但是无论怎么优化，Go v1.3 都面临这个一个重要问题，就是 mark-and-sweep 算法会暂停整个程序 。 ","date":"2022-04-06","objectID":"/go-gc/:2:5","tags":["golang"],"title":"Go GC 原理","uri":"/go-gc/"},{"categories":["golang"],"content":"有STW的三色标记法 Go 中的垃圾回收主要应用三色标记法，GC 过程和其他用户 goroutine 可并发运行，但需要一定时间的 STW。 所谓三色标记法实际上就是通过三个阶段的标记来确定需要清除的对象有哪些。 ","date":"2022-04-06","objectID":"/go-gc/:3:0","tags":["golang"],"title":"Go GC 原理","uri":"/go-gc/"},{"categories":["golang"],"content":"第一步 每次新创建的对象，默认的颜色都是标记为“白色”👇 白色对象白色对象 \" 白色对象 上图所示，我们的程序可抵达的内存对象关系如左图所示，右边的标记表，是用来记录目前每个对象的标记颜色分类。 这里所谓“程序”，是一些对象的根节点集合。如果我们将“程序”展开，会得到类似如下的表现形式： 程序的根节点集合展开程序的根节点集合展开 \" 程序的根节点集合展开 ","date":"2022-04-06","objectID":"/go-gc/:3:1","tags":["golang"],"title":"Go GC 原理","uri":"/go-gc/"},{"categories":["golang"],"content":"第二步 每次 GC 回收开始， 会从根节点开始遍历所有对象，把遍历到的对象从白色集合放入“灰色”集合： 遍历根对象遍历根对象 \" 遍历根对象 本次遍历是一次遍历，非递归形式，是从程序初次可抵达的对象遍历一层，如上图所示，当前可抵达的对象是对象1和对象4，那么自然本轮遍历结束，对象1和对象4就会被标记为灰色，灰色标记表就会多出这两个对象。 ","date":"2022-04-06","objectID":"/go-gc/:3:2","tags":["golang"],"title":"Go GC 原理","uri":"/go-gc/"},{"categories":["golang"],"content":"第三步 遍历灰色集合，将灰色对象引用的对象从白色集合放入灰色集合，之后将此灰色对象放入黑色集合： 遍历_2遍历_2 \" 遍历_2 这一次遍历是只扫描灰色对象，将灰色对象的第一层遍历可抵达的对象由白色变为灰色，如：对象2、对象7。 而之前的灰色对象1 和对象4 则会被标记为黑色，同时由灰色标记表移动到黑色标记表中。 ","date":"2022-04-06","objectID":"/go-gc/:3:3","tags":["golang"],"title":"Go GC 原理","uri":"/go-gc/"},{"categories":["golang"],"content":"第四步 重复第三步， 直到灰色中无任何对象，如图👇所示： 遍历_3遍历_3 \" 遍历_3 遍历_4遍历_4 \" 遍历_4 当我们全部的可达对象都遍历完后，灰色标记表将不再存在灰色对象。 目前全部内存的数据只有两种颜色，黑色和白色。那么，黑色对象就是我们程序逻辑可达（需要的）对象，这些数据是目前支撑程序正常业务运行的，是合法的有用数据，不可删除。白色的对象是全部不可达对象，目前程序逻辑并不依赖他们，那么白色对象就是内存中目前的垃圾数据，需要被清除。 ","date":"2022-04-06","objectID":"/go-gc/:3:4","tags":["golang"],"title":"Go GC 原理","uri":"/go-gc/"},{"categories":["golang"],"content":"第五步 回收所有的白色标记表的对象，也就是回收垃圾，如图所示👇： GC 回收GC 回收 \" GC 回收 将全部的白色对象进行删除回收，剩下的就是全部依赖的黑色对象。 这里面可能会有很多并发流程均会被扫描，执行并发流程的内存可能相互依赖，为了在 GC 过程中保证数据的安全，在开始三色标记之前就会加上 STW，在扫描确定黑白对象之后再放开 STW。但是很明显这样的 GC 扫描的性能实在是太低了。 所以现在的三色标记法还是会 STW。 ","date":"2022-04-06","objectID":"/go-gc/:3:5","tags":["golang"],"title":"Go GC 原理","uri":"/go-gc/"},{"categories":["golang"],"content":"没有STW的三色标记法 如果没有 STW，那么也就不会再存在性能上的问题，那么假设如果三色标记法不加入STW会发生什么事情❓ 还是基于上述的三色标记法来分析，他是一定要依赖 STW 的，因为如果不暂停程序，程序的逻辑可能会改变对象的引用关系，这种动作如果在标记阶段做了修改，会影响标记结果的正确性。 来看看一个场景，如果三色标记法，标记过程不使用 STW 将会发生什么事情❓ 我们把初始状态设置为已经经历了第一轮扫描，目前黑色的有对象1和对象4，灰色的有对象2和对象7，其他的为白色对象，且对象2是通过指针 p 指向对象3的，如下图所示。 no ST2 01no ST2 01 \" no ST2 01 现在如果三色标记过程不启动 STW，那么在 GC 扫描过程中，任意的对象均可能发生读写操作，如下图所示，在还没有扫描到对象2的时候，已经标记为黑色的对象4，此时创建指针 q，并且指向白色的对象3。 no ST2 02no ST2 02 \" no ST2 02 与此同时灰色的对象2将指针 p 移除，那么白色的对象3实则是被挂在了已经扫描完成的黑色的对象4下，如下图所示。 no ST2 03no ST2 03 \" no ST2 03 然后我们正常执行三色标记的算法逻辑，将所有灰色的对象标记为黑色，那么对象2和对象7就被标记成了黑色，如下图所示。 no ST2 04no ST2 04 \" no ST2 04 那么就执行了三色标记的最后一步，将所有白色对象当做垃圾进行回收，如图所示。 no ST2 05no ST2 05 \" no ST2 05 但是最后我们才发现，本来是对象4合法引用的对象3，却被GC给“误杀”回收掉了。 可以看出，有两种情况，在三色标记法中，是不希望被发生的。 👉 一个白色对象被黑色对象引用 （白色被挂在黑色下） 👉 灰色对象与它之间可达关系的白色对象遭到破坏 （灰色同时丢了该白色） 如果当以上两个条件同时满足时，就会出现对象丢失现象！ 并且，上面所示的场景中，如果示例中的白色对象3还有很多下游对象的话， 也会一并都清理掉。 为了防止这种现象的发生，最简单的方式就是 STW，直接禁止掉其他用户程序对对象引用关系的干扰，但是 STW的过程有明显的资源浪费，对所有的用户程序都有很大影响 。 那么是否可以在保证对象不丢失的情况下合理的尽可能的提高 GC 效率，减少 STW 时间呢❓ 答案是可以的，我们只要使用一种机制，尝试去破坏上面的两个必要条件就可以了。 ","date":"2022-04-06","objectID":"/go-gc/:4:0","tags":["golang"],"title":"Go GC 原理","uri":"/go-gc/"},{"categories":["golang"],"content":"屏障机制 如果让 GC 回收器，满足下面两种情况之一时，即可保证对象不丢失。这两种方式就是强三色不变式和弱三色不变式。 ","date":"2022-04-06","objectID":"/go-gc/:5:0","tags":["golang"],"title":"Go GC 原理","uri":"/go-gc/"},{"categories":["golang"],"content":"强三色不变式 强三色不变式实际上是强制性的不允许黑色对象引用白色对象，这样就不会出现有白色对象被误删的情况。 强三色不变式强三色不变式 \" 强三色不变式 ","date":"2022-04-06","objectID":"/go-gc/:5:1","tags":["golang"],"title":"Go GC 原理","uri":"/go-gc/"},{"categories":["golang"],"content":"弱三色不变式 所有被黑色对象引用的白色对象都处于灰色保护状态。 弱三色不变式弱三色不变式 \" 弱三色不变式 弱三色不变式强调，黑色对象可以引用白色对象，但是这个白色对象必须存在其他灰色对象对它的引用，或者可达它的链路上游存在灰色对象。 这样实则是黑色对象引用白色对象，白色对象处于一个危险被删除的状态，但是由于上游灰色对象的引用，可以保护该白色对象，使其安全。 为了遵循上述的两个方式，GC 算法演进到两种屏障方式，分别是插入屏障和删除屏障。 ","date":"2022-04-06","objectID":"/go-gc/:5:2","tags":["golang"],"title":"Go GC 原理","uri":"/go-gc/"},{"categories":["golang"],"content":"插入屏障 具体操作： 在 A 对象引用 B 对象的时候，B 对象被标记为灰色。将 B 挂在 A 下游，B 必须被标记为灰色。 满足：强三色不变式。不存在黑色对象引用白色对象的情况了， 因为白色会强制变成灰色。 伪代码如下： 添加下游对象(当前下游对象slot, 新下游对象ptr) { //1 标记灰色(新下游对象ptr) //2 当前下游对象slot = 新下游对象ptr } 场景： A.添加下游对象(nil, B) //A 之前没有下游， 新添加一个下游对象B， B被标记为灰色 A.添加下游对象(C, B) //A 将下游对象C 更换为B， B被标记为灰色 这段伪代码逻辑就是写屏障，我们知道，黑色对象的内存槽有两种位置，栈和堆。 栈空间的特点是容量小，但是要求响应速度快，因为函数调用弹出频繁使用，所以插入屏障机制，在栈空间的对象操作中不使用，而仅仅使用在堆空间对象的操作中。 接下来，我们用几张图，来模拟一下整个详细的过程，希望能更可观的看清整体流程。 插入屏障01插入屏障01 \" 插入屏障01 插入屏障02插入屏障02 \" 插入屏障02 插入屏障03插入屏障03 \" 插入屏障03 插入屏障04插入屏障04 \" 插入屏障04 插入屏障05插入屏障05 \" 插入屏障05 插入屏障06插入屏障06 \" 插入屏障06 但是如果栈不添加，当全部三色标记扫描之后，栈上有可能依然存在白色对象被引用的情况（如上图的对象9）。 所以要对栈重新进行三色标记扫描，但这次为了对象不丢失，要对本次标记扫描启动 STW 暂停，直到栈空间的三色标记结束。 插入屏障07插入屏障07 \" 插入屏障07 插入屏障08插入屏障08 \" 插入屏障08 插入屏障09插入屏障09 \" 插入屏障09 最后将栈和堆空间扫描剩余的全部白色节点清除，这次 STW 大约的时间在 10~100ms 间。 插入屏障10插入屏障10 \" 插入屏障10 ","date":"2022-04-06","objectID":"/go-gc/:5:3","tags":["golang"],"title":"Go GC 原理","uri":"/go-gc/"},{"categories":["golang"],"content":"删除屏障 具体操作：被删除的对象，如果自身为灰色或者白色，那么被标记为灰色。 满足：弱三色不变式，保护灰色对象到白色对象的路径不会断。 伪代码： 添加下游对象(当前下游对象slot， 新下游对象ptr) { //1 if (当前下游对象slot是灰色 || 当前下游对象slot是白色) { 标记灰色(当前下游对象slot) //slot为被删除对象， 标记为灰色 } //2 当前下游对象slot = 新下游对象ptr } 场景： A.添加下游对象(B, nil) //A对象，删除B对象的引用。 B被A删除，被标记为灰(如果B之前为白) A.添加下游对象(B, C) //A对象，更换下游B变成C。 B被A删除，被标记为灰(如果B之前为白) 接下来，我们用几张图，来模拟一个详细的过程，希望能够更可观的看清楚整体流程。 删除屏障01删除屏障01 \" 删除屏障01 删除屏障02删除屏障02 \" 删除屏障02 删除屏障03删除屏障03 \" 删除屏障03 删除屏障04删除屏障04 \" 删除屏障04 删除屏障05删除屏障05 \" 删除屏障05 删除屏障06删除屏障06 \" 删除屏障06 删除屏障07删除屏障07 \" 删除屏障07 这种方式的回收精度低，一个对象即使被删除了最后一个指向它的指针也依旧可以活过这一轮，在下一轮 GC 中被清理掉。 ","date":"2022-04-06","objectID":"/go-gc/:5:4","tags":["golang"],"title":"Go GC 原理","uri":"/go-gc/"},{"categories":["golang"],"content":"混合写屏障 插入写屏障和删除写屏障的短板： 插入写屏障：结束时需要 STW 来重新扫描栈，标记栈上引用的白色对象的存活。 删除写屏障：回收精度低，GC 开始时 STW 扫描堆栈来记录初始快照（监控对象的内存修改，判断对象是否删除），这个过程会保护开始时刻的所有存活对象。 Go v1.8 版本引入了混合写屏障机制（hybrid write barrier），避免了对栈 re-scan 的过程，极大的减少了 STW 的时间，结合了两者的优点。 ","date":"2022-04-06","objectID":"/go-gc/:6:0","tags":["golang"],"title":"Go GC 原理","uri":"/go-gc/"},{"categories":["golang"],"content":"规则 具体操作： GC 开始将栈上的对象全部扫描并标记为黑色（之后不再进行第二次重复扫描，无需 STW ）。 GC 期间，任何在栈上创建的新对象，均为黑色。 被删除的对象标记为灰色。 被添加的对象标记为灰色。 满足：变形的弱三色不变式。 伪代码： 添加下游对象(当前下游对象slot, 新下游对象ptr) { //1 标记灰色(当前下游对象slot) //只要当前下游对象被移走，就标记灰色 //2 标记灰色(新下游对象ptr) //3 当前下游对象slot = 新下游对象ptr } 屏障技术是不在栈上应用的，因为要保证栈的运行效率。 ","date":"2022-04-06","objectID":"/go-gc/:6:1","tags":["golang"],"title":"Go GC 原理","uri":"/go-gc/"},{"categories":["golang"],"content":"具体场景 我们用几张图，来模拟一个详细的过程，希望能够更可观的看清楚整体流程。 混合写屏障是 GC 的一种屏障机制，所以只是当程序执行 GC 的时候，才会触发这种机制。 GC开始：优先扫描栈区，将可达对象全部标记为黑 混合写屏障01混合写屏障01 \" 混合写屏障01 混合写屏障02混合写屏障02 \" 混合写屏障02 场景一 对象被一个堆对象删除引用，成为栈对象的下游。 伪代码 //前提：堆对象4-\u003e对象7 = 对象7； //对象7 被 对象4引用 栈对象1-\u003e对象7 = 堆对象7； //将堆对象7 挂在 栈对象1 下游 堆对象4-\u003e对象7 = null； //对象4 删除引用 对象7 场景1-01场景1-01 \" 场景1-01 场景1-02场景1-02 \" 场景1-02 场景二 对象被一个栈对象删除引用，成为另一个栈对象的下游。 伪代码： new 栈对象9； 对象8-\u003e对象3 = 对象3； //将栈对象3 挂在 栈对象9 下游 对象2-\u003e对象3 = null； //对象2 删除引用 对象3 场景2-01场景2-01 \" 场景2-01 场景2-02场景2-02 \" 场景2-02 场景2-03场景2-03 \" 场景2-03 场景三 对象被一个堆对象删除引用，成为另一个堆对象的下游。 伪代码： 堆对象10-\u003e对象7 = 堆对象7； //将堆对象7 挂在 堆对象10 下游 堆对象4-\u003e对象7 = null； //对象4 删除引用 对象7 场景3-01场景3-01 \" 场景3-01 场景3-02场景3-02 \" 场景3-02 场景3-03场景3-03 \" 场景3-03 场景四 对象从一个栈对象删除引用，成为另一个堆对象的下游。 伪代码： 堆对象10-\u003e对象7 = 堆对象7； //将堆对象7 挂在 堆对象10 下游 堆对象4-\u003e对象7 = null； //对象4 删除引用 对象7 场景4-01场景4-01 \" 场景4-01 场景4-02场景4-02 \" 场景4-02 场景4-03场景4-03 \" 场景4-03 Go 中的混合写屏障满足弱三色不变式，结合了删除写屏障和插入写屏障的优点，只需要在开始时并发扫描各个 goroutine 的栈，使其变黑并一直保持，这个过程不需要 STW，而标记结束后，因为栈在扫描后始终是黑色的，也无需再进行 re-scan 操作了，减少了 STW 的时间。 ","date":"2022-04-06","objectID":"/go-gc/:6:2","tags":["golang"],"title":"Go GC 原理","uri":"/go-gc/"},{"categories":["golang"],"content":"总结 GoV1.3：普通标记清除法，整体过程需要启动 STW，效率极低。 GoV1.5：三色标记法，堆空间启动写屏障，栈空间不启动，全部扫描之后，需要重新扫描一次栈(需要 STW )，效率普通。 GoV1.8：三色标记法，混合写屏障机制， 栈空间不启动，堆空间启动。整个过程几乎不需要STW，效率较高。 ","date":"2022-04-06","objectID":"/go-gc/:7:0","tags":["golang"],"title":"Go GC 原理","uri":"/go-gc/"},{"categories":["golang"],"content":"参考 golang 的GC原理 Golang三色标记+混合写屏障GC模式全分析 ","date":"2022-04-06","objectID":"/go-gc/:8:0","tags":["golang"],"title":"Go GC 原理","uri":"/go-gc/"},{"categories":["开发者手册"],"content":"github actions replace env vars in file, 将配置文件中的变量替换为环境变量,github actions,github actions 替换配置文件","date":"2022-04-02","objectID":"/github-actions-replace-env-vars-in-file/","tags":["github-actions"],"title":"Github Actions replace env vars in file","uri":"/github-actions-replace-env-vars-in-file/"},{"categories":["开发者手册"],"content":"Github Actions 是个好东西😀，最近在使用的时候有个需求是，我项目不想把设置成私有的，但是有些配置又比较私密，比如 github 的 Personal access token，这种配置就不能暴露出来。 呃，这种需求前辈们估计也遇到过，github actions marketplace 是个好地方，我去里面搜了搜，果然有很多轮子，但是不知道能不能满足需求。 marketplacemarketplace \" marketplace Replace env vars in file 是我选中的一个轮子。 ","date":"2022-04-02","objectID":"/github-actions-replace-env-vars-in-file/:0:0","tags":["github-actions"],"title":"Github Actions replace env vars in file","uri":"/github-actions-replace-env-vars-in-file/"},{"categories":["开发者手册"],"content":"使用 Replace env vars in fileReplace env vars in file \" Replace env vars in file Replace env vars in file 的文档就一句话， Replaces __TOKENS__ with environment variables in file. 我刚开始还不太理解。 好吧，其实是所有的环境变量都必须以__开头，然后以__结尾，这样才能被替换。 我在项目中是这样使用的： 配置文件配置文件 \" 配置文件 action 中替换action 中替换 \" action 中替换 ","date":"2022-04-02","objectID":"/github-actions-replace-env-vars-in-file/:1:0","tags":["github-actions"],"title":"Github Actions replace env vars in file","uri":"/github-actions-replace-env-vars-in-file/"},{"categories":["hugo"],"content":"Gitalk 初始化 issue,Gitalk,自动化,init issue,python 脚本自动初始 gitalk issue,hugo 主题,hugo theme","date":"2022-04-01","objectID":"/gitalk-init-issue/","tags":["gitalk","python","hugo"],"title":"Gitalk 初始化 issue","uri":"/gitalk-init-issue/"},{"categories":["hugo"],"content":"在用 Gitalk 作为个人博客评论系统时，发现有个恶心的点是，每篇文章必须手动初始化一个 issue 或是登录 github 后，把文章一个一个点开界面去初始化 issue，不然就会出现以下的提示 no issusno issus \" no issus 个人觉得这件事情非常麻烦，Gitalk 使用 labels 来映射 issuse，可以看下我用的主题 Gitalk 在初始化评论时发出的网络请求 创建 issue 的请求创建 issue 的请求 \" 创建 issue 的请求 labels 第一个参数是 Gitalk，第二个参数是文章的发布时间，呃，感觉改成文章的 path 会更好，但是 github label 的最大长度是 50 个字符，所以把 path md5 会更好。我看了下源码修改成了 URL path 的 md5 格式 themes/LoveIt/layouts/partials/comment.html comment idcomment id \" comment id 初始工作做完，就可以写脚本了。 ","date":"2022-04-01","objectID":"/gitalk-init-issue/:0:0","tags":["gitalk","python","hugo"],"title":"Gitalk 初始化 issue","uri":"/gitalk-init-issue/"},{"categories":["hugo"],"content":"分析 我们要做的事其实就是给每篇新文章初始化一个 issue，可以用 github Actions 来做这件事。 初始化 issue 大致逻辑初始化 issue 大致逻辑 \" 初始化 issue 大致逻辑 这里有几个稍微麻烦的地方，以下是我的实现方案，仅仅是提供一个思路。 ","date":"2022-04-01","objectID":"/gitalk-init-issue/:1:0","tags":["gitalk","python","hugo"],"title":"Gitalk 初始化 issue","uri":"/gitalk-init-issue/"},{"categories":["hugo"],"content":"获取所有文章信息 怎么获取所有的文章❓，我用的 LoveIt 主题在 build 时在 public 目录里会有一个 index.json 文件，里面包含了所有的文章的信息。 public index.jsonpublic index.json \" public index.json 其他的主题可以使用 sitemap.xml 来获取所有的文章信息，hugo 在 build 时会生成 sitemap.xml 文件。 sitemap.xmlsitemap.xml \" sitemap.xml ","date":"2022-04-01","objectID":"/gitalk-init-issue/:1:1","tags":["gitalk","python","hugo"],"title":"Gitalk 初始化 issue","uri":"/gitalk-init-issue/"},{"categories":["hugo"],"content":"issue 如何初始化 issue内容issue内容 \" issue内容 如上截图👆是我创建的 issue 内容。body 是文章的 URL，title 是文章标题，labels 有 Gitalk 和文章的 URL path 的 md5 两个。那么问题就简单了，我们只需要给每篇文章初始化一个这样的 issue 就可以了。 固定文章的 URL 为唯一标识，组成两个 map ，map 键就是文章的 URL。一个 map 是 github 已存在的 issue 暂定为 issue_map，一个 map 是我们所有文章的 map 暂定为 posts_map ，URL 在 posts_map 中存在但是 issue_map 不存在的就是新增 。URL 在 posts_map 和 issue_map 中都存在但是 posts_map 中的标题跟 issue_map 中的标题不相同可能就是文章标题被修改了。 对于新的 URL 我的做法是承认它是新文章，或是旧文章的 URL 被修改了那只能去 github 手动修改 issue body 为新的 URL, label 为新的 uri 的 md5 值。 ","date":"2022-04-01","objectID":"/gitalk-init-issue/:1:2","tags":["gitalk","python","hugo"],"title":"Gitalk 初始化 issue","uri":"/gitalk-init-issue/"},{"categories":["hugo"],"content":"python 脚本实现 import hashlib import json import sys import time import requests site_url = \"https://xiaobinqt.github.io\" if len(sys.argv) != 4: print(\"Usage:\") print(sys.argv[0], \"token username repo_name\") sys.exit(1) # issue 的 body 就是文章的 URL token = sys.argv[1] username = sys.argv[2] repo_name = sys.argv[3] issue_map = dict() ## [issue_body] = {\"issue_number\": issue_number, \"issue_title\": issue_title} posts_map = dict() # [post_url] = {\"post_uri\":uri,\"post_date\":date,\"post_title\":title} def get_all_gitalk_issues(token, username, repo_name): for i in range(1, 150): # 15000 个 issue 基本够用了,不够可以再加 _, ret = get_issues_page(i) time.sleep(5) if ret == -1: break ## 删除的文章不管.... ## 文章 title 修改了的文章该怎么处理？ 标题可能修改,但是 uri 不变,issue 的 body 是文章地址,只要文章地址不变，就可以直接 update issue title ## uri 如果也变了，相当于是文件的重命名了，这时只能去手动 update issue title 了?..... def update_issue(issue_number, title): if title == \"\": return url = 'https://api.github.com/repos/%s/%s/issues/%d' % (username, repo_name, issue_number) print(\"update_issue url: %s\" % url) data = { 'title': title, } print(\"create_issue req json: %s\" % json.dumps(data)) r = requests.patch(url, data=json.dumps(data), headers={ \"Authorization\": \"token %s\" % token, }, verify=False) if r.status_code == 200: print(\"update_issue success\") else: print(\"update_issue fail, status_code: %d,title: %s,issue_number: %d\" % (r.status_code, title, issue_number)) # 获取所有 label 为 gitalk 的 issue def get_issues_page(page=1): url = 'https://api.github.com/repos/%s/%s/issues?labels=Gitalk\u0026per_page=100\u0026page=%d' % (username, repo_name, page) print(\"get_issues url: %s\" % url) r = requests.get(url, headers={ \"Authorization\": \"token %s\" % token, \"Accept\": \"application/vnd.github.v3+json\" }) if r.status_code != 200: print(\"get_issues_page fail, status_code: %d\" % r.status_code) sys.exit(2) if r.json() == []: return (issue_map, -1) for issue in r.json(): if issue['body'] not in issue_map and issue[\"body\"] != \"\": issue_map[issue['body']] = { \"issue_number\": issue['number'], \"issue_title\": issue['title'] } return (issue_map, 0) # 通过 public/index.json 获取所有的文章 def get_post_titles(): with open(file='public/index.json', mode='r', encoding='utf-8') as f: file_data = f.read() if file_data == \"\" or file_data == [] or file_data == {}: return posts_map file_data = json.loads(file_data) for data in file_data: key = \"%s%s\" % (site_url, data['uri']) if key not in posts_map: posts_map[key] = { \"post_uri\": data['uri'], \"post_date\": data['date'], \"post_title\": data['title'] } return posts_map def create_issue(title=\"\", uri=\"\", date=\"\"): if title == \"\": return url = 'https://api.github.com/repos/%s/%s/issues' % (username, repo_name) print(\"create_issue title: %suri: %sdate: %s\" % (title, uri, date)) m = hashlib.md5() m.update(uri.encode('utf-8')) urlmd5 = m.hexdigest() data = { 'title': title, 'body': '%s%s' % (site_url, uri), 'labels': [ 'Gitalk', urlmd5 ] } print(\"create_issue req json: %s\" % json.dumps(data)) r = requests.post(url, data=json.dumps(data), headers={ \"Authorization\": \"token %s\" % token, }) if r.status_code == 201: print(\"create_issue success\") else: print(\"create_issue fail, status_code: %d,title: %s,req url: %s\\n\" % (r.status_code, title, url)) # 创建 gitalk 创建 issue,如果 issue 已经存在，则不创建 def init_gitalk(): for post_url, item in posts_map.items(): ## 标题被修改了 if post_url in issue_map and item['post_title'] != issue_map[post_url]['issue_title']: update_issue(issue_map[post_url][\"issue_number\"], item['post_title']) elif post_url not in issue_map: # 新增的文章 print(\"title: [%s] , body [%s] issue 不存在,创建...\" % (item[\"post_title\"], post_url)) create_issue(item[\"post_title\"], item[\"post_uri\"], item[\"post_date\"]) # 延迟 5 秒，防止 github api 请求过于频繁： https://docs.github.com/en/rest/guides/best-practices-for-integrators#dealing-with-secondary-rate-limits time.sleep(5) def get_uri_md5(uri): m = hashlib.md5() m.update(uri.encode('utf-8')) return m.hexdigest() if __name__ == \"__main__\": # print(get_uri_md5(\"/gmp-model/\")) ## 执行.... get_all_gitalk_issues(token, username, ","date":"2022-04-01","objectID":"/gitalk-init-issue/:2:0","tags":["gitalk","python","hugo"],"title":"Gitalk 初始化 issue","uri":"/gitalk-init-issue/"},{"categories":["hugo"],"content":"参考 自动初始化 Gitalk 和 Gitment 评论 利用 Github Action 自动初始化 Gitalk 评论之Python篇 ","date":"2022-04-01","objectID":"/gitalk-init-issue/:3:0","tags":["gitalk","python","hugo"],"title":"Gitalk 初始化 issue","uri":"/gitalk-init-issue/"},{"categories":["开发者手册"],"content":"Node-red,Low-code,自定义nodered节点,nodered,节点开发,how to create node-red node","date":"2022-04-01","objectID":"/node-red-glance/","tags":["low-code","node-red"],"title":"Node-RED 节点开发","uri":"/node-red-glance/"},{"categories":["开发者手册"],"content":"概述 Node-RED 是构建物联网 (IOT,Internet of Things) 应用程序的一个强大工具，其重点是简化代码块的“连接\"以执行任务。它使用可视 化编程方法，允许开发人员将预定义的代码块（称为“节点”，Node) 连接起来执行任务。连接的节点，通常是输入节点、处理节点和输出节点的组合，当它们连接在一起时，构成一个“流”(Flows)。 ","date":"2022-04-01","objectID":"/node-red-glance/:1:0","tags":["low-code","node-red"],"title":"Node-RED 节点开发","uri":"/node-red-glance/"},{"categories":["开发者手册"],"content":"安装node-red 安装 node-red 的方式大致有 2 种，使用 docker 和 npm ，docker 安装可以参考。这里使用 npm 安装。个人觉得在本地调试 npm 比 docker 更方便一点，源码都在本地，docker 的话还需要把目录映射出来。 npm 安装直接一行命令就可以搞定，具体可以参考 npm i node-red 安装成功后，会在用户目录下生成一个 .node-red 目录，我用的是 Windows 系统，所以这里的目录是 C:\\Users\\weibin\\.node-red，这个目录下有配置文件 settings.js，里面有一些 node-red 配置项，比如默认端口等。 node-red 目录node-red 目录 \" node-red 目录 ","date":"2022-04-01","objectID":"/node-red-glance/:2:0","tags":["low-code","node-red"],"title":"Node-RED 节点开发","uri":"/node-red-glance/"},{"categories":["开发者手册"],"content":"启动 安装完成后，直接执行 node-red 就可以启动服务。 cmd 启动 node-redcmd 启动 node-red \" cmd 启动 node-red node-red 的默认端口是 1880，直接用浏览器访问 http://127.0.0.1:1880 就可以看到 node-red 的页面。 node-red 界面node-red 界面 \" node-red 界面 ","date":"2022-04-01","objectID":"/node-red-glance/:3:0","tags":["low-code","node-red"],"title":"Node-RED 节点开发","uri":"/node-red-glance/"},{"categories":["开发者手册"],"content":"创建自定义节点 每一个 node-red 节点都是一个 npm 包，开发 npm 节点跟开发 npm 组件包是一样。 一个 node-red 节点主要包括两个文件，一个是 html 文件，一个是 js 文件。html 是界面配置，js 处理逻辑，加上 npm 的 package.json 文件，正常三个文件就可以实现一个 node-red 节点。 ","date":"2022-04-01","objectID":"/node-red-glance/:4:0","tags":["low-code","node-red"],"title":"Node-RED 节点开发","uri":"/node-red-glance/"},{"categories":["开发者手册"],"content":"加法器节点开发 我们创建一个自定义节点实现一个加法器，输入两个数字，输出两个数字的和。 ","date":"2022-04-01","objectID":"/node-red-glance/:4:1","tags":["low-code","node-red"],"title":"Node-RED 节点开发","uri":"/node-red-glance/"},{"categories":["开发者手册"],"content":"新建项目 我们新建一个节点项目 node-sum，这个项目随便放在那个目录下都行，这里我的目录是 D:\\tmp\\node-sum。 新建项目新建项目 \" 新建项目 ","date":"2022-04-01","objectID":"/node-red-glance/:4:2","tags":["low-code","node-red"],"title":"Node-RED 节点开发","uri":"/node-red-glance/"},{"categories":["开发者手册"],"content":"npm 初始化 切到项目目录下，执行 npm init 将项目进行 npm 初始化，然后根据提示填写即可。 npm initnpm init \" npm init 用 IDE 打开 node-sum 项目就可以看到已经给我们初始化好了 package.json 文件。 package.jsonpackage.json \" package.json ","date":"2022-04-01","objectID":"/node-red-glance/:4:3","tags":["low-code","node-red"],"title":"Node-RED 节点开发","uri":"/node-red-glance/"},{"categories":["开发者手册"],"content":"功能实现 sum.html \u003cscript type=\"text/javascript\"\u003e RED.nodes.registerType('sum', { // 这个值 必须和 js 中 RED.nodes.registerType 的值一致 category: '自定义节点', // 分类 color: '#a6bbcf', // 节点颜色 defaults: { name: {value: \"\"}, // name 默认是空 add1: {value: 0}, // add1 默认值 0 add2: {value: 0}, // add2 默认值 0 }, inputs: 0, // 节点有多少输入 0 或者多个 outputs: 1, // 节点有多少输出 0 或者多个 icon: \"file.png\", // 节点使用的图标 paletteLabel: \"加法器\", // 节点显示的名称 label: function () { // 节点的工作区的标签 return this.name || \"加法器\"; }, // 钩子函数,双节节点调出 template 时触发 oneditprepare: function () { console.log(\"oneditprepare 被调用\"); }, // 钩子函数,点击 template 中的完成按钮时触发 oneditsave: function () { console.log(\"oneditsave 被调用\"); } }); \u003c/script\u003e \u003c!--data-template-name 必须和 js 中 RED.nodes.registerType 的值一致 --\u003e \u003c!--template 是模板，可以理解成表单，节点需要的信息可以从这里输入--\u003e \u003cscript type=\"text/html\" data-template-name=\"sum\"\u003e \u003cdiv class=\"form-row\"\u003e \u003clabel for=\"node-input-name\"\u003e\u003ci class=\"fa fa-tag\"\u003e\u003c/i\u003e Name\u003c/label\u003e \u003cinput type=\"text\" id=\"node-input-name\" placeholder=\"Name\"\u003e \u003c/div\u003e \u003cdiv class=\"form-row\"\u003e \u003clabel for=\"node-input-add1\"\u003e\u003ci class=\"fa fa-tag\"\u003e\u003c/i\u003e加数1\u003c/label\u003e \u003cinput type=\"text\" id=\"node-input-add1\" placeholder=\"加数1\"\u003e \u003c/div\u003e \u003cdiv class=\"form-row\"\u003e \u003clabel for=\"node-input-add2\"\u003e\u003ci class=\"fa fa-tag\"\u003e\u003c/i\u003e加数2\u003c/label\u003e \u003cinput type=\"text\" id=\"node-input-add2\" placeholder=\"加数2\"\u003e \u003c/div\u003e \u003c/script\u003e \u003c!--data-help-name 必须和 js 中 RED.nodes.registerType 的值一致 --\u003e \u003c!--help 是节点的帮助文档--\u003e \u003cscript type=\"text/html\" data-help-name=\"sum\"\u003e \u003cp\u003e一个简单的加法器\u003c/p\u003e \u003c/script\u003e sum.js module.exports = function (RED) { function Sum(config) { RED.nodes.createNode(this, config); var node = this; // 获取输入的参数 let add1 = parseInt(config.add1) let add2 = parseInt(config.add2) node.send({ // 向下一个节点输出信息 payload: `${add1}+ ${add2}结果为 ` + (add1 + add2) }); node.on('input', function (msg) { // 接收上游节点接收消息 }); } // 注册一个节点 sum,注册的节点不能重复也就是说同一个 node-red 项目不能有 2 个 registerType sum 节点 RED.nodes.registerType(\"sum\", Sum); } 需要在 package.json 文件里添加 node-red 信息，完整的 package.json 如下： { \"name\": \"node-sum\", \"version\": \"1.0.0\", \"description\": \"node-red 加法器\", \"main\": \"index.js\", \"scripts\": { \"test\": \"echo \\\"Error: no test specified\\\" \u0026\u0026 exit 1\" }, \"keywords\": [ \"node-red\", \"add\" ], \"author\": \"xiaobinqt@163.com\", \"license\": \"ISC\", \"node-red\": { \"nodes\": { \"sum\": \"sum.js\" } } } 在 package.json 中添加的 node-red 信息是固定写法，可以理解成向 node-red 中注册了 nodes 的名称为 sum，注册的 js 文件为 sum.js。 \"node-red\": { \"nodes\": { \"sum\": \"sum.js\" } } ","date":"2022-04-01","objectID":"/node-red-glance/:4:4","tags":["low-code","node-red"],"title":"Node-RED 节点开发","uri":"/node-red-glance/"},{"categories":["开发者手册"],"content":"本地安装 可以通过 npm i 安装刚才的 sum 节点到 node-red 中。切到.node-red 目录下，执行 npm i d:\\tmp\\node-sum 安转本地节点并重启安转本地节点并重启 \" 安转本地节点并重启 然后重启 node-red 就可以看到刚才安装的节点了。 节点安装成功节点安装成功 \" 节点安装成功 ","date":"2022-04-01","objectID":"/node-red-glance/:4:5","tags":["low-code","node-red"],"title":"Node-RED 节点开发","uri":"/node-red-glance/"},{"categories":["开发者手册"],"content":"测试功能 把节点拖到工作区，双击节点（会触发oneditprepare函数）打开编辑区 双节节点填写编辑区双节节点填写编辑区 \" 双节节点填写编辑区 填写完编辑区内容后点击完成（会触发oneditsave函数），点击部署就会在调试窗口输出 node.send 信息。 部署部署 \" 部署 ","date":"2022-04-01","objectID":"/node-red-glance/:4:6","tags":["low-code","node-red"],"title":"Node-RED 节点开发","uri":"/node-red-glance/"},{"categories":["开发者手册"],"content":"参考 Creating your first node Design: i18n ","date":"2022-04-01","objectID":"/node-red-glance/:5:0","tags":["low-code","node-red"],"title":"Node-RED 节点开发","uri":"/node-red-glance/"},{"categories":["开发者手册"],"content":"https,google强制跳到https,ERR_SSL_PROTOCOL_ERROR,How to Stop Chrome from Automatically Redirecting to https","date":"2022-03-29","objectID":"/stop-chrome-auto-redirect-2-https/","tags":["chrome"],"title":"禁止Google浏览器强制跳转https","uri":"/stop-chrome-auto-redirect-2-https/"},{"categories":["开发者手册"],"content":"这几天在使用 google 浏览器打开公司的一个网站时，发现总是自动跳转到 https，以至于出现下面这个页面： ERR_SSL_PROTOCOL_ERRORERR_SSL_PROTOCOL_ERROR \" ERR_SSL_PROTOCOL_ERROR 有时候浏览器太智能了也不是一件好事🤣。 ","date":"2022-03-29","objectID":"/stop-chrome-auto-redirect-2-https/:0:0","tags":["chrome"],"title":"禁止Google浏览器强制跳转https","uri":"/stop-chrome-auto-redirect-2-https/"},{"categories":["开发者手册"],"content":"解决方法 复制链接 chrome://net-internals/#hsts用 Google 浏览器打开，这个页面，在最下面的 Delete domain security policies 填上需要禁止跳转的网站，然后点击Delete。 Delete domain security policiesDelete domain security policies \" Delete domain security policies 这里有个需要注意的地方是，如果我们的网址是 http://g.xiaobinqt.cn:8000，那么Domain 的值填的是 xiaobinqt.cn。 ","date":"2022-03-29","objectID":"/stop-chrome-auto-redirect-2-https/:1:0","tags":["chrome"],"title":"禁止Google浏览器强制跳转https","uri":"/stop-chrome-auto-redirect-2-https/"},{"categories":["开发者手册"],"content":"参考 How to Stop Chrome from Automatically Redirecting to https ","date":"2022-03-29","objectID":"/stop-chrome-auto-redirect-2-https/:2:0","tags":["chrome"],"title":"禁止Google浏览器强制跳转https","uri":"/stop-chrome-auto-redirect-2-https/"},{"categories":["hugo"],"content":"hugo,algolia,algoliasearch,exceptions.AlgoliaUnreachableHostException: Unreachable hosts, algolia索引","date":"2022-03-28","objectID":"/hugo-algolia/","tags":["hugo","algolia"],"title":"hugo algolia Unreachable hosts","uri":"/hugo-algolia/"},{"categories":["hugo"],"content":"最近在使用 hugo algolia 时，在 github actions 同步索引到 algolia 时总是出现这样的错误： action error listaction error list \" action error list Unreachable hostsUnreachable hosts \" Unreachable hosts 我用的 action 插件是Algolia Index Uploader，找了半天发现是参数 algolia_index_id 写的有问题😥： algolia_index_id 填的值algolia_index_id 填的值 \" algolia_index_id 填的值 上传成功后可以去 algolia 官网查看效果： Settings -\u003e Applications -\u003e 进入到应用 -\u003e Search -\u003e Browse 上传索引效果上传索引效果 \" 上传索引效果 ","date":"2022-03-28","objectID":"/hugo-algolia/:0:0","tags":["hugo","algolia"],"title":"hugo algolia Unreachable hosts","uri":"/hugo-algolia/"},{"categories":["hugo"],"content":"参考 Algolia Hosts unreachable ","date":"2022-03-28","objectID":"/hugo-algolia/:1:0","tags":["hugo","algolia"],"title":"hugo algolia Unreachable hosts","uri":"/hugo-algolia/"},{"categories":["理解计算机"],"content":"TCP,UDP,网络模型,实体层,链接层,网络层,传输层,应用层,网络数据包,以太网协议,MAC地址,广播,Physical Layer,Application Layer,Transport Layer,Network Layer,Internet Protocol Suite,Ethernet,subnet mask,IPv4,IPv6,互联网协议的通信过程","date":"2022-03-27","objectID":"/net-protocol-glance/","tags":["network"],"title":"互联网协议简述","uri":"/net-protocol-glance/"},{"categories":["理解计算机"],"content":"概述 ","date":"2022-03-27","objectID":"/net-protocol-glance/:1:0","tags":["network"],"title":"互联网协议简述","uri":"/net-protocol-glance/"},{"categories":["理解计算机"],"content":"五层模型 互联网的实现，分成好几层。每一层都有自己的功能，就像建筑物一样，每一层都靠下一层支持。 用户接触到的，只是最上面的一层，根本没有感觉到下面的层。理解互联网，需要从最下层开始，自下而上理解每一层的功能。 如何分层有不同的模型，有的模型分七层，有的分四层。把互联网分成五层，比较容易解释。 五层模型五层模型 \" 五层模型 如上图所示，最底下的一层叫做\"实体层\"（Physical Layer），最上面的一层叫做\"应用层\"（Application Layer），中间的三层（自下而上）分别是\"链接层\"（Link Layer）、“网络层”（Network Layer）和\"传输层\"（Transport Layer）。越下面的层，越靠近硬件；越上面的层，越靠近用户。 名字只是一个代号，它们叫什么名字，其实并不重要。只需要知道，互联网分成若干层就可以了。 ","date":"2022-03-27","objectID":"/net-protocol-glance/:1:1","tags":["network"],"title":"互联网协议简述","uri":"/net-protocol-glance/"},{"categories":["理解计算机"],"content":"层与协议 每一层都是为了完成一种功能。为了实现这些功能，就需要大家都遵守共同的规则。 大家都遵守的规则，就叫做\"协议\"（protocol）。 互联网的每一层，都定义了很多协议。这些协议的总称，就叫做\"互联网协议\"（Internet Protocol Suite），它们是互联网的核心。 ","date":"2022-03-27","objectID":"/net-protocol-glance/:1:2","tags":["network"],"title":"互联网协议简述","uri":"/net-protocol-glance/"},{"categories":["理解计算机"],"content":"实体层 电脑要组网，第一件事是先把电脑连起来，可以用光缆、电缆、双绞线、无线电波等方式。 这就叫做\"实体层\"，它就是把电脑连接起来的物理手段。它主要规定了网络的一些电气特性，作用是负责传送 0 和 1 的电信号。 实体层实体层 \" 实体层 ","date":"2022-03-27","objectID":"/net-protocol-glance/:2:0","tags":["network"],"title":"互联网协议简述","uri":"/net-protocol-glance/"},{"categories":["理解计算机"],"content":"链接层 单纯的 0 和 1 没有任何意义，必须规定解读方式：多少个电信号算一组？每个信号位有何意义？ 这就是\"链接层\"的功能，它在\"实体层\"的上方，确定了 0 和 1 的分组方式。 ","date":"2022-03-27","objectID":"/net-protocol-glance/:3:0","tags":["network"],"title":"互联网协议简述","uri":"/net-protocol-glance/"},{"categories":["理解计算机"],"content":"以太网协议 早期的时候，每家公司都有自己的电信号分组方式。逐渐地，一种叫做\"以太网\"（Ethernet）的协议，占据了主导地位。 以太网规定，一组电信号构成一个数据包，叫做\"帧\"（Frame）。每一帧分成两个部分：标头（Head）和数据（Data）。 head-datahead-data \" head-data “标头\"包含数据包的一些说明项，比如发送者、接受者、数据类型等等；“数据\"则是数据包的具体内容。 “标头\"的长度，固定为 18 字节。“数据\"的长度，最短为 46 字节，最长为 1500 字节。因此，整个\"帧\"最短为 64 字节，最长为 1518 字节。如果数据很长，就必须分割成多个帧进行发送。 ","date":"2022-03-27","objectID":"/net-protocol-glance/:3:1","tags":["network"],"title":"互联网协议简述","uri":"/net-protocol-glance/"},{"categories":["理解计算机"],"content":"MAC 地址 以太网数据包的\"标头”，包含了发送者和接受者的信息。那么，发送者和接受者是如何标识呢？ 以太网规定，连入网络的所有设备，都必须具有\"网卡\"接口。数据包必须是从一块网卡，传送到另一块网卡。网卡的地址，就是数据包的发送地址和接收地址，这叫做 MAC 地址。 每块网卡出厂的时候，都有一个全世界独一无二的 MAC 地址，长度是 48 个二进制位，通常用 12 个十六进制数表示。 前 6 个十六进制数是厂商编号，后 6 个是该厂商的网卡流水号。有了 MAC 地址，就可以定位网卡和数据包的路径了。 MAC addressMAC address \" MAC address 上图的 MAC 地址的二进制位为 00000000-10110000-11010000-10000110-10111011-11110111。 ","date":"2022-03-27","objectID":"/net-protocol-glance/:3:2","tags":["network"],"title":"互联网协议简述","uri":"/net-protocol-glance/"},{"categories":["理解计算机"],"content":"广播 以太网数据包必须知道接收方的 MAC 地址，然后才能发送，那么问题来了， 一块网卡怎么会知道另一块网卡的MAC地址？ 就算有了 MAC 地址，系统怎样才能把数据包准确送到接收方？ 回答是以太网采用了一种很\"原始\"的方式，它不是把数据包准确送到接收方，而是向本网络内所有计算机发送，让每台计算机自己判断，是否为接收方。 广播广播 \" 广播 上图中，1 号计算机向 2 号计算机发送一个数据包，同一个子网络的 3 号、4 号、5 号计算机都会收到这个包。它们读取这个包的\"标头”，找到接收方的 MAC 地址，然后与自身的 MAC 地址相比较，如果两者相同，就接受这个包，做进一步处理，否则就丢弃这个包。这种发送方式就叫做\"广播”（broadcasting）。 有了数据包的定义、网卡的 MAC 地址、广播的发送方式，“链接层\"就可以在多台计算机之间传送数据了。 ","date":"2022-03-27","objectID":"/net-protocol-glance/:3:3","tags":["network"],"title":"互联网协议简述","uri":"/net-protocol-glance/"},{"categories":["理解计算机"],"content":"网络层 ","date":"2022-03-27","objectID":"/net-protocol-glance/:4:0","tags":["network"],"title":"互联网协议简述","uri":"/net-protocol-glance/"},{"categories":["理解计算机"],"content":"网络层的由来 以太网协议，依靠 MAC 地址发送数据。理论上，单单依靠 MAC 地址，上海的网卡就可以找到洛杉矶的网卡了，技术上是可以实现的。 但是，这样做有一个重大的缺点。以太网采用广播方式发送数据包，所有成员人手一\"包”，不仅效率低，而且局限在发送者所在的子网络。也就是说，如果两台计算机不在同一个子网络，广播是传不过去的 。这种设计是合理的，否则互联网上每一台计算机都会收到所有包，那会引起灾难。 互联网是无数子网络共同组成的一个巨型网络，很像想象上海和洛杉矶的电脑会在同一个子网络，这几乎是不可能的。 子网络子网络 \" 子网络 因此，必须找到一种方法，能够区分哪些 MAC 地址属于同一个子网络，哪些不是。如果是同一个子网络，就采用广播方式发送，否则就采用\"路由\"方式发送。（“路由\"的意思，就是指如何向不同的子网络分发数据包。），MAC 地址本身无法做到这一点，它只与厂商有关，与所处网络无关。 这就导致了\"网络层\"的诞生。它的作用是引进一套新的地址，使得我们能够区分不同的计算机是否属于同一个子网络。这套地址就叫做\"网络地址”，简称\"网址”。 于是，“网络层\"出现以后，每台计算机有了两种地址，一种是 MAC 地址，另一种是网络地址。两种地址之间没有任何联系，MAC 地址是绑定在网卡上的，网络地址则是管理员分配的，它们只是随机组合在一起。 网络地址帮助我们确定计算机所在的子网络，MAC 地址则将数据包送到该子网络中的目标网卡。因此，从逻辑上可以推断，必定是先处理网络地址，然后再处理 MAC 地址。 ","date":"2022-03-27","objectID":"/net-protocol-glance/:4:1","tags":["network"],"title":"互联网协议简述","uri":"/net-protocol-glance/"},{"categories":["理解计算机"],"content":"IP协议和子网掩码 规定网络地址的协议，叫做 IP 协议。它所定义的地址，就被称为 IP 地址。 目前，广泛采用的是 IP 协议第四版，简称 IPv4。这个版本规定，网络地址由 32 个二进制位组成。 IP协议IP协议 \" IP协议 习惯上，我们用分成四段的十进制数表示 IP 地址，从 0.0.0.0 一直到 255.255.255.255。 互联网上的每一台计算机，都会分配到一个 IP 地址。 IP 地址分成两个部分，前一部分代表网络，后一部分代表主机。 比如，IP 地址 172.16.254.1，这是一个 32 位的地址，假定它的网络部分是前 24 位（172.16.254），那么主机部分就是后 8 位（最后的那个 1 ）。处于同一个子网络的电脑，它们 IP 地址的网络部分必定是相同的，也就是说 172.16.254.2 应该与 172.16.254.1 处在同一个子网络。 单单从 IP 地址，我们无法判断网络部分。还是以 172.16.254.1 为例，它的网络部分，到底是前 24 位，还是前 16 位，甚至前 28 位，从 IP 地址上是看不出来的。 那么，怎样才能从IP地址，判断两台计算机是否属于同一个子网络呢？这就要用到另一个参数\"子网掩码”（subnet mask）。 所谓 “子网掩码”，就是表示子网络特征的一个参数。它在形式上等同于 IP 地址，也是一个 32 位二进制数字，它的网络部分全部为 1，主机部分全部为 0 。比如，IP 地址 172.16.254.1 ，如果已知网络部分是前 24 位，主机部分是后 8 位，那么子网络掩码就是 11111111.11111111.11111111.00000000，写成十进制就是 255.255.255.0。 知道\"子网掩码\"，我们就能判断，任意两个 IP 地址是否处在同一个子网络。方法是将两个 IP 地址与子网掩码分别进行 AND 运算（两个数位都为 1 ，运算结果为 1，否则为 0），然后比较结果是否相同，如果是的话，就表明它们在同一个子网络中，否则就不是。 比如，已知IP地址 172.16.254.1 和 172.16.254.233 的子网掩码都是 255.255.255.0，请问它们是否在同一个子网络？两者与子网掩码分别进行 AND 运算，结果都是 172.16.254.0，因此它们在同一个子网络。 10101100.00010000.11111110.00000001 # 172.16.254.1 11111111.11111111.11111111.00000000 # 255.255.255.0 10101100.00010000.11111110.00000000 # AND 结果二进制位 172.16.254.0 # AND 结果转成十进制 所以，IP 协议的作用主要有两个，一个是为每一台计算机分配 IP 地址，另一个是确定哪些地址在同一个子网络。 ","date":"2022-03-27","objectID":"/net-protocol-glance/:4:2","tags":["network"],"title":"互联网协议简述","uri":"/net-protocol-glance/"},{"categories":["理解计算机"],"content":"IP数据包 根据 IP 协议发送的数据，就叫做 IP 数据包。不难想象，其中必定包括 IP 地址信息。 但是前面说过，以太网数据包只包含 MAC 地址，并没有 IP 地址的栏位。那么是否需要修改数据定义，再添加一个栏位呢？ 回答是不需要，我们可以把 IP 数据包直接放进以太网数据包的\"数据\"部分，因此完全不用修改以太网的规格。这就是互联网分层结构的好处：上层的变动完全不涉及下层的结构。 具体来说，IP 数据包也分为\"标头\"和\"数据\"两个部分。 IP数据包1IP数据包1 \" IP数据包1 “标头\"部分主要包括版本、长度、IP 地址等信息，“数据\"部分则是 IP 数据包的具体内容。它放进以太网数据包后，以太网数据包就变成了下面这样。 IP数据包2IP数据包2 \" IP数据包2 IP 数据包的“标头”部分的长度为 20 到 60 字节，整个数据包的总长度最大为 65,535 字节。因此，理论上，一个 IP 数据包的\"数据\"部分，最长为 65,515 字节。前面说过，以太网数据包的\"数据\"部分，最长只有 1500 字节。因此，如果 IP 数据包超过了 1500 字节（上图红色部分），它就需要分割成几个以太网数据包，分开发送了。 ","date":"2022-03-27","objectID":"/net-protocol-glance/:4:3","tags":["network"],"title":"互联网协议简述","uri":"/net-protocol-glance/"},{"categories":["理解计算机"],"content":"ARP协议 由于 IP 数据包是放在以太网数据包里发送的，所以我们必须同时知道两个地址，一个是对方的 MAC 地址，另一个是对方的 IP 地址。通常情况下，对方的 IP 地址是已知的，但是我们不知道它的 MAC 地址。 所以，我们需要一种机制，能够从 IP 地址得到 MAC 地址。 这里又可以分成两种情况。 第一种情况，如果两台主机不在同一个子网络，那么事实上没有办法得到对方的 MAC 地址，只能把数据包传送到两个子网络连接处的\"网关”（gateway），让网关去处理。 第二种情况，如果两台主机在同一个子网络，那么我们可以用 ARP 协议，得到对方的 MAC 地址。ARP 协议也是发出一个数据包（包含在以太网数据包中），其中包含它所要查询主机的 IP 地址，在对方的 MAC 地址这一栏，填的是FF:FF:FF:FF:FF:FF，表示这是一个\"广播” 地址。它所在子网络的每一台主机，都会收到这个数据包，从中取出 IP 地址，与自身的 IP 地址进行比较。如果两者相同，都做出回复，向对方报告自己的 MAC 地址，否则就丢弃这个包。 有了 ARP 协议之后，我们就可以得到同一个子网络内的主机 MAC 地址，可以把数据包发送到任意一台主机之上。 ","date":"2022-03-27","objectID":"/net-protocol-glance/:4:4","tags":["network"],"title":"互联网协议简述","uri":"/net-protocol-glance/"},{"categories":["理解计算机"],"content":"传输层 ","date":"2022-03-27","objectID":"/net-protocol-glance/:5:0","tags":["network"],"title":"互联网协议简述","uri":"/net-protocol-glance/"},{"categories":["理解计算机"],"content":"传输层的由来 有了 MAC 地址和 IP 地址，我们已经可以在互联网上任意两台主机上建立通信。 接下来的问题是，同一台主机上有许多程序都需要用到网络，比如，你一边浏览网页，一边与朋友在线聊天。当一个数据包从互联网上发来的时候，你怎么知道，它是表示网页的内容，还是表示在线聊天的内容？ 也就是说，我们还需要一个参数，表示这个数据包到底供哪个程序（进程）使用。这个参数就叫做\"端口\"（port），它其实是每一个使用网卡的程序的编号。每个数据包都发到主机的特定端口，所以不同的程序就能取到自己所需要的数据。 “端口\"是 0 到 65535 之间的一个整数，正好 16 个二进制位。0 到 1023 的端口被系统占用，用户只能选用大于 1023 的端口。不管是浏览网页还是在线聊天，应用程序会随机选用一个端口，然后与服务器的相应端口联系。 “传输层\"的功能，就是建立\"端口到端口\"的通信。相比之下，“网络层\"的功能是建立\"主机到主机\"的通信。只要确定主机和端口，我们就能实现程序之间的交流。因此，Unix系统就把主机+端口，叫做\"套接字” （socket）。有了它，就可以进行网络应用程序开发了。 ","date":"2022-03-27","objectID":"/net-protocol-glance/:5:1","tags":["network"],"title":"互联网协议简述","uri":"/net-protocol-glance/"},{"categories":["理解计算机"],"content":"UDP 协议 我们必须在数据包中加入端口信息，这就需要新的协议。最简单的实现叫做 UDP 协议，它的格式几乎就是在数据前面，加上端口号。 UDP 数据包，也是由\"标头\"和\"数据\"两部分组成。 UDP数据格式_1UDP数据格式_1 \" UDP数据格式_1 “标头\"部分主要定义了发出端口和接收端口，“数据\"部分就是具体的内容。然后，把整个 UDP 数据包放入 IP 数据包的\"数据\"部分，而前面说过，IP 数据包又是放在以太网数据包之中的，所以整个以太网数据包现在变成了下面这样： UDP数据格式_2UDP数据格式_2 \" UDP数据格式_2 UDP 数据包非常简单，“标头\"部分一共只有 8 个字节，总长度不超过 65,535 字节，正好放进一个IP数据包。 ","date":"2022-03-27","objectID":"/net-protocol-glance/:5:2","tags":["network"],"title":"互联网协议简述","uri":"/net-protocol-glance/"},{"categories":["理解计算机"],"content":"TCP 协议 UDP 协议的优点是比较简单，容易实现，但是缺点是可靠性较差，一旦数据包发出，无法知道对方是否收到。 为了解决这个问题，提高网络可靠性，TCP 协议就诞生了。这个协议非常复杂，但可以近似认为，它就是有确认机制的 UDP 协议，每发出一个数据包都要求确认。如果有一个数据包遗失，就收不到确认，发出方就知道有必要重发这个数据包了。 因此，TCP 协议能够确保数据不会遗失。它的缺点是过程复杂、实现困难、消耗较多的资源。 TCP 数据包和 UDP 数据包一样，都是内嵌在 IP 数据包的“数据”部分。TCP 数据包没有长度限制，理论上可以无限长，但是为了保证网络的效率，通常 TCP 数据包的长度不会超过 IP 数据包的长度，以确保单个 TCP 数据包不必再分割。 ","date":"2022-03-27","objectID":"/net-protocol-glance/:5:3","tags":["network"],"title":"互联网协议简述","uri":"/net-protocol-glance/"},{"categories":["理解计算机"],"content":"应用层 应用程序收到\"传输层\"的数据，接下来就要进行解读。由于互联网是开放架构，数据来源五花八门，必须事先规定好格式，否则根本无法解读。 “应用层”的作用，就是规定应用程序的数据格式。 举例来说，TCP 协议可以为各种各样的程序传递数据，比如 Email、WWW、FTP 等等。那么，必须有不同协议规定电子邮件、网页、FTP 数据的格式，这些应用程序协议就构成了\"应用层”。 这是最高的一层，直接面对用户。它的数据就放在 TCP 数据包的\"数据\"部分。因此，现在的以太网的数据包就变成下面这样。 应用层数据包应用层数据包 \" 应用层数据包 ","date":"2022-03-27","objectID":"/net-protocol-glance/:6:0","tags":["network"],"title":"互联网协议简述","uri":"/net-protocol-glance/"},{"categories":["理解计算机"],"content":"小结 网络通信就是交换数据包。电脑 A 向电脑 B 发送一个数据包，后者收到了，回复一个数据包，从而实现两台电脑之间的通信。数据包的结构，基本上是下面这样： 数据包数据包 \" 数据包 发送这个包，需要知道两个地址： 对方的 MAC 地址 对方的 IP 地址 有了这两个地址，数据包才能准确送到接收者手中。但是，MAC 地址有局限性，如果两台电脑不在同一个子网络，就无法知道对方的 MAC 地址，必须通过网关（gateway）转发。 网关网关 \" 网关 上图中，1 号电脑要向 4 号电脑发送一个数据包。它先判断 4 号电脑是否在同一个子网络，结果发现不是，于是就把这个数据包发到网关 A。网关 A 通过路由协议，发现 4 号电脑位于子网络 B，又把数据包发给网关 B，网关 B 再转发到 4 号电脑。 1 号电脑把数据包发到网关 A，必须知道网关 A 的 MAC 地址。所以，数据包的目标地址，实际上分成两种情况： 场景 数据包地址 同一个子网络 对方的MAC地址，对方的IP地址 非同一个子网络 网关的MAC地址，对方的IP地址 发送数据包之前，电脑必须判断对方是否在同一个子网络，然后选择相应的 MAC 地址。 ","date":"2022-03-27","objectID":"/net-protocol-glance/:7:0","tags":["network"],"title":"互联网协议简述","uri":"/net-protocol-glance/"},{"categories":["理解计算机"],"content":"用户的上网设置 ","date":"2022-03-27","objectID":"/net-protocol-glance/:8:0","tags":["network"],"title":"互联网协议简述","uri":"/net-protocol-glance/"},{"categories":["理解计算机"],"content":"静态IP地址 new computercomputer \" new computer 通常你必须做一些设置。有时，管理员会告诉你下面四个参数，你把它们填入操作系统，计算机就能连上网了： 本机的IP地址 子网掩码 网关的IP地址 DNS的IP地址 下图是Windows系统的设置窗口。 系统设置系统设置 \" 系统设置 这四个参数缺一不可。由于它们是给定的，计算机每次开机，都会分到同样的IP地址，所以这种情况被称作\"静态IP地址上网”。 但是，这样的设置很专业，普通用户望而生畏，而且如果一台电脑的IP地址保持不变，其他电脑就不能使用这个地址，不够灵活。出于这两个原因，大多数用户使用\"动态IP地址上网”。 ","date":"2022-03-27","objectID":"/net-protocol-glance/:8:1","tags":["network"],"title":"互联网协议简述","uri":"/net-protocol-glance/"},{"categories":["理解计算机"],"content":"动态IP地址 所谓\"动态IP地址”，指计算机开机后，会自动分配到一个IP地址，不用人为设定。它使用的协议叫做DHCP协议。 这个协议规定，每一个子网络中，有一台计算机负责管理本网络的所有IP地址，它叫做\"DHCP服务器”。新的计算机加入网络，必须向\"DHCP服务器\"发送一个\"DHCP请求\"数据包，申请IP地址和相关的网络参数。 前面说过，如果两台计算机在同一个子网络，必须知道对方的MAC地址和IP地址，才能发送数据包。但是，新加入的计算机不知道这两个地址，怎么发送数据包呢？ DHCP协议做了一些巧妙的规定。 ","date":"2022-03-27","objectID":"/net-protocol-glance/:8:2","tags":["network"],"title":"互联网协议简述","uri":"/net-protocol-glance/"},{"categories":["理解计算机"],"content":"DHCP协议 首先，它是一种应用层协议，建立在UDP协议之上，所以整个数据包是这样的： HDCP协议数据包HDCP协议数据包 \" HDCP协议数据包 最前面的\"以太网标头\"，设置发出方（本机）的MAC地址和接收方（DHCP服务器）的MAC地址。前者就是本机网卡的MAC地址，后者这时不知道，就填入一个广播地址：FF-FF-FF-FF-FF-FF。 后面的\"IP标头\"，设置发出方的IP地址和接收方的IP地址。这时，对于这两者，本机都不知道。于是，发出方的IP地址就设为0.0.0.0，接收方的IP地址设为255.255.255.255。 最后的\"UDP标头\"，设置发出方的端口和接收方的端口。这一部分是DHCP协议规定好的，发出方是68端口，接收方是67端口。 这个数据包构造完成后，就可以发出了。以太网是广播发送，同一个子网络的每台计算机都收到了这个包。因为接收方的MAC地址是FF-FF-FF-FF-FF-FF ，看不出是发给谁的，所以每台收到这个包的计算机，还必须分析这个包的IP地址，才能确定是不是发给自己的。当看到发出方IP地址是0.0.0.0，接收方是255.255.255.255，于是DHCP服务器知道\" 这个包是发给我的\"，而其他计算机就可以丢弃这个包。 接下来，DHCP服务器读出这个包的数据内容，分配好IP地址，发送回去一个\"DHCP响应\" 数据包。这个响应包的结构也是类似的，以太网标头的MAC地址是双方的网卡地址，IP标头的IP地址是DHCP服务器的IP地址（发出方）和255.255.255.255 （接收方），UDP标头的端口是67（发出方）和68（接收方），分配给请求端的IP地址和本网络的具体参数则包含在Data部分。 新加入的计算机收到这个响应包，于是就知道了自己的IP地址、子网掩码、网关地址、DNS服务器等等参数。 ","date":"2022-03-27","objectID":"/net-protocol-glance/:8:3","tags":["network"],"title":"互联网协议简述","uri":"/net-protocol-glance/"},{"categories":["理解计算机"],"content":"小结 不管是\"静态IP地址\"还是\"动态IP地址\"，电脑上网的首要步骤，是确定四个参数。这四个值很重要，值得重复一遍： 本机的IP地址 子网掩码 网关的IP地址 DNS的IP地址 有了这几个数值，电脑就可以上网\"冲浪\"了。 ","date":"2022-03-27","objectID":"/net-protocol-glance/:8:4","tags":["network"],"title":"互联网协议简述","uri":"/net-protocol-glance/"},{"categories":["理解计算机"],"content":"一个实例 ","date":"2022-03-27","objectID":"/net-protocol-glance/:9:0","tags":["network"],"title":"互联网协议简述","uri":"/net-protocol-glance/"},{"categories":["理解计算机"],"content":"本机参数 我们假定，用户设置好了自己的网络参数： 本机的IP地址：192.168.1.100 子网掩码：255.255.255.0 网关的IP地址：192.168.1.1 DNS的IP地址：8.8.8.8 然后他打开浏览器，想要访问Google，在地址栏输入了网址：www.google.com。 访问google访问google \" 访问google 这意味着，浏览器要向Google发送一个网页请求的数据包。 ","date":"2022-03-27","objectID":"/net-protocol-glance/:9:1","tags":["network"],"title":"互联网协议简述","uri":"/net-protocol-glance/"},{"categories":["理解计算机"],"content":"DNS协议 我们知道，发送数据包，必须要知道对方的IP地址。但是，现在，我们只知道网址www.google.com，不知道它的IP地址。 DNS协议可以帮助我们，将这个网址转换成IP地址。已知DNS服务器为8.8.8.8，于是我们向这个地址发送一个DNS数据包（53端口）。 DNS数据包DNS数据包 \" DNS数据包 然后，DNS服务器做出响应，告诉我们Google的IP地址是172.194.72.105。于是，我们知道了对方的IP地址。 ","date":"2022-03-27","objectID":"/net-protocol-glance/:9:2","tags":["network"],"title":"互联网协议简述","uri":"/net-protocol-glance/"},{"categories":["理解计算机"],"content":"子网掩码 接下来，我们要判断，这个IP地址是不是在同一个子网络，这就要用到子网掩码。 已知子网掩码是255.255.255.0，本机用它对自己的IP地址192.168.1.100，做一个二进制的AND运算（两个数位都为1，结果为1，否则为0），计算结果为192.168.1.0 ；然后对Google的IP地址172.194.72.105也做一个AND运算，计算结果为172.194.72.0。这两个结果不相等，所以结论是，Google与本机不在同一个子网络。 因此，我们要向Google发送数据包，必须通过网关192.168.1.1转发，也就是说，接收方的MAC地址将是网关的MAC地址。 ","date":"2022-03-27","objectID":"/net-protocol-glance/:9:3","tags":["network"],"title":"互联网协议简述","uri":"/net-protocol-glance/"},{"categories":["理解计算机"],"content":"应用层协议 浏览网页用的是HTTP协议，它的整个数据包构造是这样的： HTTP协议数据包HTTP协议数据包 \" HTTP协议数据包 HTTP部分的内容，类似于下面这样： GET / HTTP/1.1 Host: www.google.com Connection: keep-alive User-Agent: Mozilla/5.0 (Windows NT 6.1) ...... Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8 Accept-Encoding: gzip,deflate,sdch Accept-Language: zh-CN,zh;q=0.8 Accept-Charset: GBK,utf-8;q=0.7,*;q=0.3 Cookie: ... ... 我们假定这个部分的长度为 4960 字节，它会被嵌在TCP数据包之中。 ","date":"2022-03-27","objectID":"/net-protocol-glance/:9:4","tags":["network"],"title":"互联网协议简述","uri":"/net-protocol-glance/"},{"categories":["理解计算机"],"content":"TCP协议 TCP数据包需要设置端口，接收方（Google）的HTTP端口默认是80，发送方（本机）的端口是一个随机生成的1024-65535之间的整数，假定为51775。 TCP数据包的标头长度为20字节，加上嵌入HTTP的数据包，总长度变为4980字节。 ","date":"2022-03-27","objectID":"/net-protocol-glance/:9:5","tags":["network"],"title":"互联网协议简述","uri":"/net-protocol-glance/"},{"categories":["理解计算机"],"content":"IP协议 然后，TCP数据包再嵌入IP数据包。IP数据包需要设置双方的IP地址，这是已知的，发送方是192.168.1.100（本机），接收方是172.194.72.105（Google）。 IP数据包的标头长度为20字节，加上嵌入的TCP数据包，总长度变为5000字节。 ","date":"2022-03-27","objectID":"/net-protocol-glance/:9:6","tags":["network"],"title":"互联网协议简述","uri":"/net-protocol-glance/"},{"categories":["理解计算机"],"content":"以太网协议 最后，IP数据包嵌入以太网数据包。以太网数据包需要设置双方的MAC地址，发送方为本机的网卡MAC地址，接收方为网关192.168.1.1的MAC地址（通过ARP协议得到）。 以太网数据包的数据部分，最大长度为1500字节，而现在的IP数据包长度为5000字节。因此，IP数据包必须分割成四个包。因为每个包都有自己的IP标头（20字节），所以四个包的IP数据包的长度分别为1500、1500、1500、560。 以太网协议以太网协议 \" 以太网协议 ","date":"2022-03-27","objectID":"/net-protocol-glance/:9:7","tags":["network"],"title":"互联网协议简述","uri":"/net-protocol-glance/"},{"categories":["理解计算机"],"content":"服务器端响应 经过多个网关的转发，Google的服务器172.194.72.105，收到了这四个以太网数据包。 根据IP标头的序号，Google将四个包拼起来，取出完整的TCP数据包，然后读出里面的\"HTTP请求\"，接着做出\"HTTP响应\"，再用TCP协议发回来。 本机收到HTTP响应以后，就可以将网页显示出来，完成一次网络通信。 服务器相应服务器相应 \" 服务器相应 上面的例子，虽然经过了简化，但它大致上反映了互联网协议的整个通信过程。 ","date":"2022-03-27","objectID":"/net-protocol-glance/:9:8","tags":["network"],"title":"互联网协议简述","uri":"/net-protocol-glance/"},{"categories":["理解计算机"],"content":"参考 互联网协议入门 ","date":"2022-03-27","objectID":"/net-protocol-glance/:10:0","tags":["network"],"title":"互联网协议简述","uri":"/net-protocol-glance/"},{"categories":null,"content":"我们已经在一起 var countDownDate=new Date('2019-09-17T21:21:00').getTime(); window.setInterval(function(){ var distance=new Date().getTime()-countDownDate;var days=Math.floor(distance/(1000*60*60*24)); var hours=Math.floor((distance%(1000*60*60*24))/(1000*60*60)); var minutes=Math.floor((distance%(1000*60*60))/(1000*60)); var seconds=Math.floor((distance%(1000*60))/1000); document.getElementById(\"since\").innerHTML=days+' 天 '+hours+' 时 '+minutes+' 分 '+seconds+' 秒';},1000); ","date":"2022-03-25","objectID":"/love/:0:0","tags":null,"title":"Since 2019/09/17","uri":"/love/"},{"categories":["开发者手册"],"content":"git使用，git，git基本操作，git clone,git push,git remote,.gitignore,git pull,git status,git add,git commit,git log,git diff,git rebase,git merge,git stash,git rebase,git rebase --continue,git rebase --skip,git rebase --abort,git","date":"2022-03-23","objectID":"/git-glance/","tags":["git"],"title":"git 使用笔记","uri":"/git-glance/"},{"categories":["开发者手册"],"content":"基本概念 基本概念基本概念 \" 基本概念 ","date":"2022-03-23","objectID":"/git-glance/:1:0","tags":["git"],"title":"git 使用笔记","uri":"/git-glance/"},{"categories":["开发者手册"],"content":".gitignore文件 # 此为注释 – 将被 Git 忽略 *.a # 忽略所有 .a 结尾的文件 !lib.a # 但 lib.a 除外 /TODO # 仅仅忽略项目根目录下的 TODO 文件，不包括 subdir/TODO build/ # 忽略 build/ 目录下的所有文件 doc/*.txt # 会忽略 doc/notes.txt 但不包括 doc/server/arch.txt ","date":"2022-03-23","objectID":"/git-glance/:2:0","tags":["git"],"title":"git 使用笔记","uri":"/git-glance/"},{"categories":["开发者手册"],"content":"git 常用命令 ","date":"2022-03-23","objectID":"/git-glance/:3:0","tags":["git"],"title":"git 使用笔记","uri":"/git-glance/"},{"categories":["开发者手册"],"content":"git reset 当已经把代码从暂存区提交到版本库了，git rest命令可以恢复到暂存区的状态。 git rest --hard HEAD $commit_id，如果只会退上一个版本就是HEAD^，上上一个版本就是HEAD^^，当然往上100个版本写100个^比较容易数不过来，所以写成HEAD~100。 如果知道 commit id 的话，可以直接用 commit id，commit id 没必要写全，前6位基本就可以用，git会自动去找。 commit id 可以通过git log命令查看，格式化log可以使用git log --pretty=oneline git log --pretty=onelinegit log \u0026ndash;pretty=oneline \" git log --pretty=oneline --hard 参数的作用 当文件被修改过，并且 add 到了暂存区，git reset 命令会把文件状态恢复到最初的状态，也就是从暂存区撤销掉，此时跟git reset HEAD 命令一样。 如果文件从暂存区 commit 了，说明已经生成了最新的版本号了，此时回退，则需要回退到之前的一个版本，如果知道前一个版本的版本号，git reset 版本号这样就可以了，但是一般我们不会去记版本号， 可以执行git log 命令去查看，也可以使用 git reset HEAD^ 命令用于回退到上一个版本，会重新回到工作区，也就是 add 之前的状态。 如果使用了 --hard 参数会连工作区的状态内容也修改了。 以下是同样的 commit 之后，不加 --hard 参数和使用 --hard 参数的区别： 不使用 --hard 参数不使用 \u0026ndash;hard 参数 \" 不使用 --hard 参数 使用 --hard 参数使用 \u0026ndash;hard 参数 \" 使用 --hard 参数 ","date":"2022-03-23","objectID":"/git-glance/:3:1","tags":["git"],"title":"git 使用笔记","uri":"/git-glance/"},{"categories":["开发者手册"],"content":"git diff cmd 说明 git diff [file] 显示暂存区和工作区的差异 git diff --cached [file]/git diff --staged [file] 显示暂存区和上一次提交(commit)的差异 ","date":"2022-03-23","objectID":"/git-glance/:3:2","tags":["git"],"title":"git 使用笔记","uri":"/git-glance/"},{"categories":["开发者手册"],"content":"git reflog git reflog 用来记录你的每一次命令，可以查看你最近执行过的命令，可以用来回退到某一个时刻。所以为了好查记录，commit -m 的提交说明文案尽量写清楚。 git refloggit reflog \" git reflog cmd 说明 git reflog –date=local –all | grep dev 查看 dev 分支是基于哪个分支创建的 Tips markdown 表格中使用 | 可以使用\u0026#124; ","date":"2022-03-23","objectID":"/git-glance/:3:3","tags":["git"],"title":"git 使用笔记","uri":"/git-glance/"},{"categories":["开发者手册"],"content":"git log git log 不传入任何参数的默认情况下，git log 会按时间先后顺序列出所有的提交，最近的更新排在最上面，当记录太多时会出现分页，可以按空格键翻页，按 q 键退出。 git loggit log \" git log git log --pretty=oneline 将每个提交放在一行显示，在浏览大量的提交时非常有用。 git log --pretty=onelinegit log pretty oneline \" git log --pretty=oneline git log --graph --pretty=oneline --abbrev-commit 仅显示 SHA-1 校验和所有 40 个字符中的前几个字符。--oneline 是 --pretty=oneline --abbrev-commit 合用的简写。 所以 git log --graph --pretty=oneline 可以也可以写为 git log --graph --pretty=oneline --abbrev-commit。 --graph 在日志旁以 ASCII 图形显示分支与合并历史。 git graphgit graph \" git graph ","date":"2022-03-23","objectID":"/git-glance/:3:4","tags":["git"],"title":"git 使用笔记","uri":"/git-glance/"},{"categories":["开发者手册"],"content":"git checkout cmd 说明 git checkout dev 切换到dev分支 git checkout -- file 可以丢弃工作区的修改， git checkout -- readme.txt 意思是，把readme.txt文件在工作区的修改全部撤销。 这里有两种情况： 1. readme.txt自修改后还没有被放到暂存区，撤销修改就回到和版本库一模一样的状态。 2. readme.txt已经添加到暂存区后，又作了修改，撤销修改就回到添加到暂存区后的状态 git checkout -b yourbranchname origin/oldbranchname 在本地创建和远程分支对应的分支 ","date":"2022-03-23","objectID":"/git-glance/:3:5","tags":["git"],"title":"git 使用笔记","uri":"/git-glance/"},{"categories":["开发者手册"],"content":"git rm git rm 有 2 个常用命令： git rm \u003cfile\u003e：同时从工作区和索引中删除文件。即本地的文件也被删除了，并把此次删除操作提交到了暂存区。 git rm filegit rm file \" git rm file git rm --cached ：从索引中删除文件。但是本地文件还存在，只是不希望这个文件被版本控制。 git rm --cachedgit rm \u0026ndash;cached \" git rm --cached 如果是文件夹需要加上 -r 参数，比如： git rm -r --cached 文件/文件夹名字 Tips 先手动删除文件，然后使用git rm \u003cfile\u003e和git add\u003cfile\u003e效果是一样的。 ","date":"2022-03-23","objectID":"/git-glance/:3:6","tags":["git"],"title":"git 使用笔记","uri":"/git-glance/"},{"categories":["开发者手册"],"content":"git remote cmd 说明 git remote add 名字 地址 关联一个远程库时必须给远程库指定一个名字，如：git remote add origin git@server-name:path/repo-name.git git remote -v 查看远程库信息 git remote rm \u003cname\u003e 解除了本地和远程的绑定关系，如：git remote rm origin ","date":"2022-03-23","objectID":"/git-glance/:3:7","tags":["git"],"title":"git 使用笔记","uri":"/git-glance/"},{"categories":["开发者手册"],"content":"git push 把本地库的内容推送到远程，用git push命令，比如： git push -u origin master 实际上是把当前分支推送到远程的 master 分支上。 加上了-u参数，git不但会把本地的分支内容推送的远程的master分支，还会把本地的分支和远程的master分支关联起来，在以后的推送或者拉取时就可以简化命令，直接使用 git push。 ","date":"2022-03-23","objectID":"/git-glance/:3:8","tags":["git"],"title":"git 使用笔记","uri":"/git-glance/"},{"categories":["开发者手册"],"content":"git branch cmd 说明 git brahcn -b 分支名 新建并切换到新分支，如新建并切换到dev分支：git branch -b dev git branch 列出所有分支，当前分支前面会标一个*号 git branch -d 分支名 删除某个分支 git branch -a 查看远程分支，远程分支会用红色表示出来（如果开了颜色支持的话） git branch -D \u003cname\u003e 强行删除一个没有被合并过的分支 git branch --set-upstream branch-name origin/branch-name 建立本地分支和远程分支的关联 ","date":"2022-03-23","objectID":"/git-glance/:3:9","tags":["git"],"title":"git 使用笔记","uri":"/git-glance/"},{"categories":["开发者手册"],"content":"git merge git merge命令用于合并指定分支到当前分支。如：git merge dev 合并 dev 分支到当前分支。 ","date":"2022-03-23","objectID":"/git-glance/:3:10","tags":["git"],"title":"git 使用笔记","uri":"/git-glance/"},{"categories":["开发者手册"],"content":"git switch git 2.23+ 版本支持了 switch 命令用来切换分支，实际上，切换分支这个动作，用switch更好理解。 之前切换分支使用git checkout \u003cbranch\u003e，而撤销修改则是git checkout -- \u003cfile\u003e，同一个命令，有两种作用，确实有点令人迷惑。 操作 version 2.23- version 2.23+ 切换分支 git branch dev git switch dev 新建并切换分支 git branch -b dev git switch -c dev ","date":"2022-03-23","objectID":"/git-glance/:3:11","tags":["git"],"title":"git 使用笔记","uri":"/git-glance/"},{"categories":["开发者手册"],"content":"git cherry-pick 在合并代码的时候，有两种情况： 需要另一个分支的所有代码变动，那么就采用合并git merge。 只需要部分代码变动（某几个提交），这时可以采用 cherry pick。 git cherry-pick \u003ccommid_1\u003e \u003ccommit_2\u003e ","date":"2022-03-23","objectID":"/git-glance/:3:12","tags":["git"],"title":"git 使用笔记","uri":"/git-glance/"},{"categories":["开发者手册"],"content":"git stash 新增的文件，直接执行 git stash 是不会被存储的，需要先执行 git add 把文件加到版本控制里。 文件在版本控制里，并不等于就被stash起来了，git add 和 git stash 没有必然的关系，但是执行 git stash 能正确存储的前提是文件必须在 git 版本控制中才行。 可以多次stash，恢复的时候，先用git stash list查看，然后恢复指定的stash。 cmd 说明 git stash save \"save message\" 执行存储时，添加备注，方便查找，只有git stash 也要可以的，但查找时不方便识别 git stash list 查看stash了哪些存储 git stash show 显示做了哪些改动，默认show第一个存储,如果要显示其他存贮，后面加 stash@{$num}，比如第二个 git stash show stash@{1} git stash show -p 显示第一个存储的改动，如果想显示其他存存储，命令：git stash show stash@{$num} -p ，比如第二个：git stash show stash@{1} -p git stash apply 应用某个存储，但不会把存储从存储列表中删除，默认使用第一个存储，即stash@{0}，如果要使用其他个，git stash apply stash@{$num} ， 比如第二个：git stash apply stash@{1} git stash pop 命令恢复之前缓存的工作目录，将缓存堆栈中的对应stash删除，并将对应修改应用到当前的工作目录下，默认为第一个stash，即stash@{0}，如果要应用并删除其他stash，命令：git stash pop stash@{$num} ，比如应用并删除第二个：git stash pop stash@{1} git stash drop stash@{$num} 丢弃stash@{$num}存储，从列表中删除这个存储 git stash clear 删除所有缓存的stash ","date":"2022-03-23","objectID":"/git-glance/:3:13","tags":["git"],"title":"git 使用笔记","uri":"/git-glance/"},{"categories":["开发者手册"],"content":"分支管理 HEAD严格来说不是指向提交，而是指向某个分支，如master分支，master才是指向提交的，所以，HEAD指向的就是当前分支。 HEADHEAD \" HEAD 在合并分支时如果出现冲突，Git用\u003c\u003c\u003c\u003c\u003c\u003c\u003c，=======，\u003e\u003e\u003e\u003e\u003e\u003e\u003e标记出不同分支的内容。 合并分支有冲突merge conflict \" 合并分支有冲突 ","date":"2022-03-23","objectID":"/git-glance/:4:0","tags":["git"],"title":"git 使用笔记","uri":"/git-glance/"},{"categories":["开发者手册"],"content":"Fast forward 通常，合并分支时，如果可能，git会用Fast forward模式，但这种模式下，删除分支后，会丢掉分支信息。 可以使用--no-ff强制禁用Fast forward模式，git就会在merge时生成一个新的commit，这样，从分支历史上就可以看出分支信息。 git merge --no-ffgit merge \u0026ndash;no-ff \" git merge --no-ff 因为本次合并要创建一个新的commit，所以加上-m参数，把commit描述写进去。 分支历史分支历史 \" 分支历史 ","date":"2022-03-23","objectID":"/git-glance/:4:1","tags":["git"],"title":"git 使用笔记","uri":"/git-glance/"},{"categories":["开发者手册"],"content":"标签Tag tag 是基于某个分支下的某次 commit。如只执行 git tag v1.0，那么标签是打在该分支最新提交的 commit 上的。 创建的标签都只存储在本地，不会自动推送到远程，打错的标签可以在本地安全删除。如果标签已经推送到远程，得先删除本地标签，再删除远程标签。 cmd 说明 git tag -a v0.1 -m \"version 0.1 released\" 1094adb 基于某次 commit 打 tag，-a指定标签名，-m指定说明文字 git show \u003ctagname\u003e 显示 tag 的说明文字 git tag 可以查看所有标签 git tag -d v0.1 删除标签 git push origin \u003ctagname\u003e 推送某个标签到远程，如：git push origin v1.0 git push origin --tags 一次性推送全部尚未推送到远程的本地标签 git push origin :refs/tags/\u003ctagname\u003e 删除一个远程标签 ","date":"2022-03-23","objectID":"/git-glance/:5:0","tags":["git"],"title":"git 使用笔记","uri":"/git-glance/"},{"categories":["开发者手册"],"content":"参考 git-fast-version-control Git教程 Git Cheat Sheet git cherry-pick 教程 git stash 用法总结和注意点 ","date":"2022-03-23","objectID":"/git-glance/:6:0","tags":["git"],"title":"git 使用笔记","uri":"/git-glance/"},{"categories":["开发者手册"],"content":"OAuth2.0,第三方登录,令牌,TOKEN,授权码,权限","date":"2022-03-22","objectID":"/oauth2.0/","tags":["web","oauth"],"title":"OAuth2.0的理解与应用","uri":"/oauth2.0/"},{"categories":["开发者手册"],"content":"什么是 OAuth2.0 OAuth 的核心就是向第三方应用颁发令牌，比如网站A想用Github的信息，那么对于Github来说，网站A就是第三方应用。 第三方应用申请令牌之前，都必须先到系统备案，比如申请Github的令牌，得先到github备案登记， 说明自己的身份，然后会拿到两个身份识别码：客户端 ID（client ID）和客户端密钥（client secret）。这是为了防止令牌被滥用，没有备案过的第三方应用，是不会拿到令牌的。 关于 OAuth2.0 是什么可以参考一下文章： OAuth 2.0 的一个简单解释 [简易图解]『 OAuth2.0』 『进阶』 授权模式总结 ","date":"2022-03-22","objectID":"/oauth2.0/:1:0","tags":["web","oauth"],"title":"OAuth2.0的理解与应用","uri":"/oauth2.0/"},{"categories":["开发者手册"],"content":"第三方登录Github 所谓第三方登录，实质就是 OAuth 授权。用户想要登录 A 网站，A 网站让用户提供第三方网站的数据，证明自己的身份。获取第三方网站的身份数据，就需要 OAuth 授权。 比如，A 网站允许 GitHub 登录，背后就是下面的流程： A 网站让用户跳转到 GitHub。 GitHub 要求用户登录，然后询问\"A 网站要求获得 xx 权限，你是否同意？\" 用户同意，GitHub 就会重定向回 A 网站，同时发回一个授权码。 A 网站使用授权码，向 GitHub 请求令牌。 GitHub 返回令牌. A 网站使用令牌，向 GitHub 请求用户数据。 ","date":"2022-03-22","objectID":"/oauth2.0/:2:0","tags":["web","oauth"],"title":"OAuth2.0的理解与应用","uri":"/oauth2.0/"},{"categories":["开发者手册"],"content":"注册 OAuth 应用 现在在 Github 上注册一个 OAuth 应用。 github注册oauth应用 \" 字段 描述 Application name 应用名称 Homepage URL 首页URL，如https://www.xiaobinqt.cn Authorization callback URL 用户在 Github 登录成功后重定向回的 URL 注册成功后会生成 Client ID 和 Client Secret，这两个是用来请求令牌的。 生成的Client信息 \" ","date":"2022-03-22","objectID":"/oauth2.0/:2:1","tags":["web","oauth"],"title":"OAuth2.0的理解与应用","uri":"/oauth2.0/"},{"categories":["开发者手册"],"content":"通过 OAuth 获取用户信息 前端界面 oauth.html \u003c!DOCTYPE html\u003e \u003chtml lang=\"en\"\u003e \u003chead\u003e \u003cmeta charset=\"UTF-8\"\u003e \u003ctitle\u003eTitle\u003c/title\u003e \u003c/head\u003e \u003cbody\u003e \u003ca href=\"https://github.com/login/oauth/authorize?client_id={{.ClientId}}\u0026redirect_uri={{.RedirectUrl}}\"\u003e Github 第三方授权登录\u003c/a\u003e \u003c/body\u003e \u003c/html\u003e go 代码通过OAuth获取用户信息 package main import ( \"encoding/json\" \"flag\" \"fmt\" \"html/template\" \"io/ioutil\" \"log\" \"net/http\" \"os\" ) var ( clientSecret = flag.String(\"cs\", \"\", \"github oauth client secret\") clientID = flag.String(\"ci\", \"\", \"github oauth client id\") ) type Conf struct { ClientId string ClientSecret string RedirectUrl string } type Token struct { AccessToken string `json:\"access_token\"` } // 认证并获取用户信息 func OAuth(w http.ResponseWriter, r *http.Request) { var ( err error ) // 获取 code code := r.URL.Query().Get(\"code\") // 通过 code, 获取 token var tokenAuthUrl = GetTokenAuthURL(code) var token *Token if token, err = GetToken(tokenAuthUrl); err != nil { fmt.Println(err) return } // 通过token，获取用户信息 var userInfo map[string]interface{} if userInfo, err = GetUserInfo(token); err != nil { fmt.Println(\"获取用户信息失败，错误信息为:\", err) return } // 将用户信息返回前端 var userInfoBytes []byte if userInfoBytes, err = json.Marshal(userInfo); err != nil { fmt.Println(\"在将用户信息(map)转为用户信息([]byte)时发生错误，错误信息为:\", err) return } w.Header().Set(\"Content-Type\", \"application/json\") if _, err = w.Write(userInfoBytes); err != nil { fmt.Println(\"在将用户信息([]byte)返回前端时发生错误，错误信息为:\", err) return } } // 通过code获取token认证url func GetTokenAuthURL(code string) string { return fmt.Sprintf( \"https://github.com/login/oauth/access_token?client_id=%s\u0026client_secret=%s\u0026code=%s\", *clientID, *clientSecret, code, ) } // 获取 token func GetToken(url string) (*Token, error) { // 形成请求 var req *http.Request var err error if req, err = http.NewRequest(http.MethodGet, url, nil); err != nil { return nil, err } req.Header.Set(\"accept\", \"application/json\") // 发送请求并获得响应 var ( httpClient = http.Client{} res *http.Response respBody = make([]byte, 0) token Token ) if res, err = httpClient.Do(req); err != nil { return nil, err } respBody, err = ioutil.ReadAll(res.Body) if err != nil { return nil, err } log.Printf(\"token: %s\", string(respBody)) // 将响应体解析为 token，并返回 err = json.Unmarshal(respBody, \u0026token) if err != nil { return nil, err } return \u0026token, nil } // 获取用户信息 func GetUserInfo(token *Token) (map[string]interface{}, error) { // 形成请求 var userInfoUrl = \"https://api.github.com/user\" // github用户信息获取接口 var req *http.Request var err error if req, err = http.NewRequest(http.MethodGet, userInfoUrl, nil); err != nil { return nil, err } req.Header.Set(\"accept\", \"application/json\") req.Header.Set(\"Authorization\", fmt.Sprintf(\"token %s\", token.AccessToken)) // 发送请求并获取响应 var client = http.Client{} var res *http.Response if res, err = client.Do(req); err != nil { return nil, err } // 将响应的数据写入 userInfo 中，并返回 var userInfo = make(map[string]interface{}) if err = json.NewDecoder(res.Body).Decode(\u0026userInfo); err != nil { return nil, err } return userInfo, nil } func Html(w http.ResponseWriter, r *http.Request) { // 解析指定文件生成模板对象 var ( temp *template.Template err error ) dir, _ := os.Getwd() if temp, err = template.ParseFiles(dir + \"/oauth.html\"); err != nil { fmt.Println(\"读取文件失败，错误信息为:\", err) return } // 利用给定数据渲染模板(html页面)，并将结果写入w，返回给前端 if err = temp.Execute(w, Conf{ ClientId: *clientID, ClientSecret: *clientSecret, RedirectUrl: \"http://127.0.0.1:9000/oauth/callback\", }); err != nil { fmt.Println(\"读取渲染html页面失败，错误信息为:\", err) return } } func UserInfo(w http.ResponseWriter, r *http.Request) { token := r.URL.Query().Get(\"token\") log.Printf(\"UserInfo token: %s\", token) var ( err error userInfo map[string]interface{} ) if userInfo, err = GetUserInfo(\u0026Token{AccessToken: token}); err != nil { fmt.Println(\"获取用户信息失败，错误信息为:\", err) return } // 将用户信息返回前端 var userInfoBytes []byte if userInfoBytes, err = json.Marshal(userInfo); err != nil { fmt.Println(\"在将用户信息(map)转为用户信息([]byte)时发生错误，错误信息为:\", err) return } w.Header().Set(\"Content-Type\", \"application/json\") if _, err = w.Write(u","date":"2022-03-22","objectID":"/oauth2.0/:2:2","tags":["web","oauth"],"title":"OAuth2.0的理解与应用","uri":"/oauth2.0/"},{"categories":["开发者手册"],"content":"效果 前端界面前端界面 \" 前端界面 授权页面授权页面 \" 授权页面 github返回的用户信息github返回的用户信息 \" github返回的用户信息 ","date":"2022-03-22","objectID":"/oauth2.0/:3:0","tags":["web","oauth"],"title":"OAuth2.0的理解与应用","uri":"/oauth2.0/"},{"categories":["开发者手册"],"content":"源码 源码地址 ","date":"2022-03-22","objectID":"/oauth2.0/:4:0","tags":["web","oauth"],"title":"OAuth2.0的理解与应用","uri":"/oauth2.0/"},{"categories":["开发者手册"],"content":"参考 Building OAuth Apps OAuth 2.0 的一个简单解释 Go语言实现第三方登录Github (通过OAuth2.0) basics of authentication [简易图解]『 OAuth2.0』 『进阶』 授权模式总结 ","date":"2022-03-22","objectID":"/oauth2.0/:5:0","tags":["web","oauth"],"title":"OAuth2.0的理解与应用","uri":"/oauth2.0/"},{"categories":["hugo"],"content":"HUGO,hugo主题标题支持emoji,emoji表情","date":"2022-03-21","objectID":"/hugo-title-support-emoji/","tags":["hugo","emoji"],"title":"hugo主题标题支持emoji:smile:","uri":"/hugo-title-support-emoji/"},{"categories":["hugo"],"content":"解决方法 hugo 在渲染时默认是不支持标题中的emoji的（有的主题也许是支持的），可以通过修改主题源码来支持。 我用的主题是LoveIt，找到 simple.html 文件，路径为 themes/LoveIt/layouts/posts/single.html 修改标题的渲染方式为 {{ .Title | emojify }}，如下： 修改主题的渲染方式 \" 这样就可以支持 emoji 了。 title support emoji \" 此时列表中还不支持 emoji，同样的修改方式。 list not support emoji \" 修改 themes/LoveIt/layouts/_default/summary.html 文件文件中的 title 的渲染方式为 {{ .Title | emojify }}。 ","date":"2022-03-21","objectID":"/hugo-title-support-emoji/:1:0","tags":["hugo","emoji"],"title":"hugo主题标题支持emoji:smile:","uri":"/hugo-title-support-emoji/"},{"categories":["hugo"],"content":"参考 Hugo should render emojis in page titles if enableEmoji = true ","date":"2022-03-21","objectID":"/hugo-title-support-emoji/:2:0","tags":["hugo","emoji"],"title":"hugo主题标题支持emoji:smile:","uri":"/hugo-title-support-emoji/"},{"categories":["理解计算机"],"content":"tcp, tcp连接管理,三次握手,四次挥手,为什么建立连接需要三次握手,为什么不能用两次握手进行连接,SYN,FIN,ACK,PSH,SYN_SENT,SYN_RECV,ESTABLISHED,FIN_WAIT_1,FIN_WAIT_2,CLOSE_WAIT,LAST_ACK,TIME_WAIT,CLOSE","date":"2022-03-21","objectID":"/tcp-handshark/","tags":["tcp"],"title":"TCP连接管理","uri":"/tcp-handshark/"},{"categories":["理解计算机"],"content":"名词解释 名词 解释 SYN 同步序号，用于建立连接过程，在连接请求中，SYN=1 和 ACK=0 表示该数据段没有使用捎带的确认域，而连接应答捎带一个确认，即 SYN=1 和 ACK=1 FIN finish 标志，用于释放连接，为 1 时表示发送方已经没有数据发送了，即关闭本方数据流 ACK 确认序号标志，为 1 时表示确认号有效，为 0 表示报文中不含确认信息，忽略确认号字段 PSH push 标志，为 1 表示是带有 push 标志的数据，指示接收方在接收到该报文段以后，应尽快将这个报文段交给应用程序，而不是在缓冲区排队 RST 重置连接标志，用于重置由于主机崩溃或其他原因而出现错误的连接。或者用于拒绝非法的报文段和拒绝连接请求 序列号 seq 占 4 个字节，用来标记数据段的顺序，TCP 把连接中发送的所有数据字节都编上一个序号，第一个字节的编号由本地随机产生；给字节编上序号后，就给每一个报文段指派一个序号；序列号 seq 就是这个报文段中的第一个字节的数据编号 确认号 ack 占 4 个字节，期待收到对方下一个报文段的第一个数据字节的序号；序列号表示报文段携带数据的第一个字节的编号；而确认号指的是期望接收到下一个字节的编号；因此当前报文段最后一个字节的编号 +1 （ACK会占一个序号）即为确认号 Info ACK、SYN 和 FIN 这些大写的单词表示标志位，其值要么是 1，要么是 0；ack、seq 小写的单词表示序号。 ACK 是可能与 SYN，FIN 等同时使用的。比如 SYN和ACK可能同时为 1，它表示的就是建立连接之后的响应搜索 如果只是单个的一个SYN，它表示的只是建立连接。 SYN与FIN是不会同时为 1 的，因为前者表示的是建立连接，而后者表示的是断开连接。 RST一般是在FIN之后才会出现为 1 的情况，表示的是连接重置。 一般，当出现FIN包或RST包时，便认为客户端与服务器端断开了连接；而当出现SYN和SYN＋ACK包时，我们认为客户端与服务器建立了一个连接。 PSH为 1 的情况，一般只出现在DATA内容不为 0 的包中，也就是说PSH为1表示的是有真正的 TCP 数据包内容被传递。 ","date":"2022-03-21","objectID":"/tcp-handshark/:1:0","tags":["tcp"],"title":"TCP连接管理","uri":"/tcp-handshark/"},{"categories":["理解计算机"],"content":"三次握手 三次握手三次握手 \" 三次握手 ","date":"2022-03-21","objectID":"/tcp-handshark/:2:0","tags":["tcp"],"title":"TCP连接管理","uri":"/tcp-handshark/"},{"categories":["理解计算机"],"content":"第一次握手 客户端 主动打开（active open），向服务端发送 SYN 报文段SYN=1, SN=client_isn, OPT=client_mss，请求建立连接。 client_isn 是客户端初始序号，动态生成，用于实现可靠传输，client_sn-client_isn 等于客户端已发送字节数。 SYN 报文段虽然不能携带数据，但是会消耗一个序号（相当于发送了1个字节的有效数据），下次客户端再向服务端发送的报文段中 SN=client_isn+1。 除了 SYN 报文段和 ACK-SYN 报文段，其他所有后续报文段的序号 SN 值都等于上次接收的 ACK 报文段中的确认号 AN 值。 client_mss 是客户端最大报文段长度，在 TCP 首部的选项和填充部分，会在客户端与服务端的 MSS 中选择一个较小值使用。 客户端变为 SYN_SENT 状态，然后等待服务端 ACK 报文段。 ","date":"2022-03-21","objectID":"/tcp-handshark/:2:1","tags":["tcp"],"title":"TCP连接管理","uri":"/tcp-handshark/"},{"categories":["理解计算机"],"content":"第二次握手 服务端 接收来自客户端的 SYN 报文段，得知客户端发送能力正常。 被动打开passive open，向客户端发送 SYN-ACK 报文段ACK=1, AN=client_isn+1, SYN=1, SN=server_isn, OPT=server_mss ，应答来自客户端的建立连接请求并向客户端发起建立连接请求。 SN=server_isn 是服务端初始序号，ACK-SYN 报文段虽然不能携带数据，但是会消耗一个序号（相当于发送了1个字节的有效数据），下次服务端再向客户端发送的报文中 SN=server_isn+1 。 OPT=server_mss 是服务端最大报文段长度。 AN=client_isn+1 是确认号，表明服务端接下来要开始接收来自客户端的第 client_isn+1 个字节的有效数据。 服务端变为 SYN_RCVD 状态，并等待客户端 ACK 报文段。 ","date":"2022-03-21","objectID":"/tcp-handshark/:2:2","tags":["tcp"],"title":"TCP连接管理","uri":"/tcp-handshark/"},{"categories":["理解计算机"],"content":"第三次握手 客户端 接收来自服务端的 SYN-ACK 报文段，得知服务端发送能力和接收能力都正常。 向客户端发送 ACK 报文段ACK=1, AN=server_isn+1, SN=client_isn+1, MESSAGE=message，应答来自服务端的建立连接请求。 SN=client_isn+1 是序号，表明当前报文段发送的有效数据首字节是从请求建立连接到现在为止客户端向服务端发送的第 (client_isn+1)-clien_isn+1=2 个字节的有效数据。 有效数据：一般有效数据指的是应用层的报文数据，不过 SYN 报文段、 ACK-SYN 报文段和 FIN 报文段虽然没有携带报文数据，但认为发送了1个字节的有效数据。 AN=server_isn+1 是确认号，表明客户端接下来要开始接收来自服务端的第 server_isn+1 个字节的有效数据。 MESSAGE=message 此时可以在报文段中携带客户端到服务端的报文数据；该 ACK 报文段消耗的序号个数等于 message_length（注意 message_length 可以等于0，即不携带有效数据，此时 ACK报文段不消耗序号），下次客户端再向服务端发送的报文段中 SN=client_isn+1+message_length 。 客户端变为 ESTABLISHED 状态，client——\u003eserver 数据流建立。 服务端 接收来自客户端的 ACK 报文段，得知客户端接收能力正常。 变为 ESTABLISHED 状态，server——\u003eclient 数据流也建立。 ","date":"2022-03-21","objectID":"/tcp-handshark/:2:3","tags":["tcp"],"title":"TCP连接管理","uri":"/tcp-handshark/"},{"categories":["理解计算机"],"content":"四次挥手 TCP四次挥手TCP四次挥手 \" TCP四次挥手 断开连接前，客户端和服务端都处于 ESTABLISHED 状态，两者谁都可以先发起断开连接请求。以下假设客户端先发起断开连接请求。 ","date":"2022-03-21","objectID":"/tcp-handshark/:3:0","tags":["tcp"],"title":"TCP连接管理","uri":"/tcp-handshark/"},{"categories":["理解计算机"],"content":"第一次挥手 客户端 向服务端发送 FIN 报文段FIN=1, SN=client_sn，请求断开连接。 SN=client_sn是序号，表明当前报文段发送的有效数据首字节是从请求建立连接到现在为止客户端向服务端发送的第 client_sn-clien_isn+1 个字节的有效数据。 FIN 报文段虽然不能携带数据，但是会消耗一个序号（相当于发送了1个字节的有效数据），下次客户端再向服务端发送的报文中 SN=client_isn+1 。 客户端变为 FIN_WAIT1 状态，等待服务端 ACK 报文段。 ","date":"2022-03-21","objectID":"/tcp-handshark/:3:1","tags":["tcp"],"title":"TCP连接管理","uri":"/tcp-handshark/"},{"categories":["理解计算机"],"content":"第二次挥手 服务端 接收来自客户端的 FIN 报文段。 向客户端发送 ACK 报文段ACK=1, AN=client_sn+1, SN=server_sn_wave2，应答客户端的断开连接请求。 SN=server_sn_wave2 是序号，表明当前报文段发送的有效数据首字节是从请求建立连接到现在为止服务端向客户端发送的第 server_sn_wave2-client_isn+1 个字节的有效数据。 AN=client_sn+1 是确认号，表明服务端接下来要开始接收来自客户端的第 client_sn+1 个字节的有效数据。 此时服务端变为 CLOSE_WAIT 状态。 客户端 接收来自服务端的 ACK 包。 变为 FIN_WAIT2 状态，等待服务端关闭连接请求FIN报文段。 ","date":"2022-03-21","objectID":"/tcp-handshark/:3:2","tags":["tcp"],"title":"TCP连接管理","uri":"/tcp-handshark/"},{"categories":["理解计算机"],"content":"第三次挥手 服务端 （服务端想断开连接时）向客户端发送 FIN 报文段FIN=1, SN=server_sn，请求断开连接。 SN=server_sn 是序号，表明当前报文段发送的有效数据首字节是从请求建立连接到现在为止服务端向客户端发送的第 server_sn-clien_isn+1 个字节的有效数据。 FIN 报文段虽然不能携带数据，但是会消耗一个序号（相当于发送了1个字节的有效数据），下次服务端再向客户端发送的报文中 SN=client_isn+2 （若断开连接成功，则服务端不会再向客户端发送下一个报文段）。 第二次挥手和第三次挥手之间，服务端又向客户端发送了 server_sn - server_sn_wave2 个字节的有效数据。 服务端变为 LAST_ACK 状态，等待客户端的 ACK 报文段。 ","date":"2022-03-21","objectID":"/tcp-handshark/:3:3","tags":["tcp"],"title":"TCP连接管理","uri":"/tcp-handshark/"},{"categories":["理解计算机"],"content":"第四次挥手 客户端 接收来自服务端的 FIN 报文段。 向服务端发送 ACK 报文段ACK=1, AN=server_sn+1, SN=client_sn+1，应答服务端断开连接请求。 client_sn+1 是序号，表明当前报文段发送的有效数据首字节是从请求建立连接到现在为止客户端向客户端发送的第 client_isn+1)-clien_isn+1 个字节的有效数据。AN=server_sn+1 是确认号，表明服务端接下来要开始接收来自客户端的第 client_sn+1 个字节的有效数据。 客户端变为 TIME_WAIT 状态，等待2MSL时间后进入 CLOSED 状态，至此 client——\u003eserver 数据流被关闭。 服务端 接收来自客户端的 ACK 报文段。 变为 CLOSED 状态，至此 server——\u003eclient 数据流被关闭。 Tips 当收到对方的FIN报文时，仅仅表示对方不再发送数据了但是还能接收数据。 ","date":"2022-03-21","objectID":"/tcp-handshark/:3:4","tags":["tcp"],"title":"TCP连接管理","uri":"/tcp-handshark/"},{"categories":["理解计算机"],"content":"常见问题 ❓ 为什么建立连接需要“三次”握手 客户端和服务端之间建立的TCP是全双工通信，双方都要确保对方发送能力和接收能力正常。 一次握手后，服务端得知客户端发送能力正常。 二次握手后，客户端得知服务端接收能力和发送能力正常。 三次握手后，服务端得知客户端接收能力正常。 ❓ 为什么第四次挥手时要等待2MSL的时间再进入CLOSED状态 MSL（Maximum Segment Lifetime，报文段最大生存时间）是一个未被接受的报文段在网络中被丢弃前存活的最大时间。 保证建立新连接时网络中不存在上次连接时发送的数据包，进入 CLOSED 状态意味着可以建立新连接，等待 \u003eMSL 的时间再进入 CLOSED 状态可以保证建立新连接后，网络中不会存在上次连接时发送出去的数据包。若网络中同时存在发送端在两次连接中发出的数据包，对接收端接收数据可能会有影响。 保证第四次挥手发送的 ACK 能到达接收端，第四次挥手发送的 ACK 可能会出现丢包，另一端接收不到 ACK 会重新发送 FIN。等待 2MSL 的时间可以应对该情况，重发 ACK ，保证另一端能正常关闭连接。 ❓ 已经建立了连接，客户端突然出现故障怎么办 TCP 设有一个保活计时器，客户端如果出现故障，服务器不能一直等下去，白白浪费资源。服务器每收到一次客户端的请求后都会重新复位这个计时器，时间通常是设置为 2 小时，若两小时还没有收到客户端的任何数据，服务器就会发送一个探测报文段，以后每隔 75 秒钟发送一次。若一连发送 10 个探测报文仍然没反应， 服务器就认为客户端出了故障，接着就关闭连接。 ❓ 为什么不能用两次握手进行连接 三次握手完成两个重要的功能，既要双方做好发送数据的准备工作（双方都知道彼此已准备好），也要允许双方就初始序列号进行协商，这个序列号在握手过程中被发送和确认。 现在把三次握手改成仅需要两次握手，死锁是可能发生的。 比如，计算机 S 和 C 之间的通信，假定 C 给 S 发送一个连接请求分组，S 收到了这个分组，并发送了确认应答分组。按照两次握手的协定，S 认为连接已经成功地建立了，可以开始发送数据分组。 可是，C 在 S 的应答分组在传输中被丢失的情况下，将不知道 S 是否已准备好，不知道 S 建立什么样的序列号，C 甚至怀疑 S 是否收到自己的连接请求分组。在这种情况下，C 认为连接还未建立成功，将忽略 S 发来的任何数据分 组，只等待连接确认应答分组，而 S 在发出的分组超时后，重复发送同样的分组，这样就形成了死锁。 ","date":"2022-03-21","objectID":"/tcp-handshark/:4:0","tags":["tcp"],"title":"TCP连接管理","uri":"/tcp-handshark/"},{"categories":["理解计算机"],"content":"参考 计算机网络——TCP连接管理（三次握手和四次挥手） “三次握手，四次挥手”你真的懂吗？ TCP的三次握手与四次挥手理解及面试题（很全面） TCP报文格式详解 面试官，不要再问我三次握手和四次挥手 ","date":"2022-03-21","objectID":"/tcp-handshark/:5:0","tags":["tcp"],"title":"TCP连接管理","uri":"/tcp-handshark/"},{"categories":[""],"content":"前小端 ","date":"2022-03-19","objectID":"/links/:1:0","tags":[""],"title":"友情链接","uri":"/links/"},{"categories":[""],"content":"MakerLi ","date":"2022-03-19","objectID":"/links/:2:0","tags":[""],"title":"友情链接","uri":"/links/"},{"categories":[""],"content":"西瓜 ","date":"2022-03-19","objectID":"/links/:3:0","tags":[""],"title":"友情链接","uri":"/links/"},{"categories":[""],"content":"liupray ","date":"2022-03-19","objectID":"/links/:4:0","tags":[""],"title":"友情链接","uri":"/links/"},{"categories":[""],"content":"xiaowuneng ","date":"2022-03-19","objectID":"/links/:5:0","tags":[""],"title":"友情链接","uri":"/links/"},{"categories":["web"],"content":"JS运行机制,javascript异步运行机制,js异步同步,js Promise,js catch reject,js执行顺讯,async/await,js微任务和宏任务","date":"2022-03-18","objectID":"/js-cb-asyn/","tags":["js"],"title":"JS运行机制","uri":"/js-cb-asyn/"},{"categories":["web"],"content":"执行模式 JS的执行模式是单线程的，当有多个任务时必须排队执行，优点是执行环境简单，缺点是性能低下，当有多个任务时，需要等待上一个任务执行完成才能执行下一个任务， 如果某个任务出现了死循环，那么就会导致程序崩溃。 所以JS出现了同步和异步的概念。 ","date":"2022-03-18","objectID":"/js-cb-asyn/:1:0","tags":["js"],"title":"JS运行机制","uri":"/js-cb-asyn/"},{"categories":["web"],"content":"同步 后一个任务等待前一个任务结束，然后再执行，程序的执行顺序与任务的排列顺序是一致的。 ","date":"2022-03-18","objectID":"/js-cb-asyn/:1:1","tags":["js"],"title":"JS运行机制","uri":"/js-cb-asyn/"},{"categories":["web"],"content":"异步 每一个任务有一个或多个回调函数（callback），前一个任务结束后，不是执行后一个任务，而是执行回调函数，后一个任务则是不等前一个任务结束就执行，所以程序的执行顺序与任务的排列顺序可能是不一致的。 ","date":"2022-03-18","objectID":"/js-cb-asyn/:1:2","tags":["js"],"title":"JS运行机制","uri":"/js-cb-asyn/"},{"categories":["web"],"content":"Event Loop // TODO ","date":"2022-03-18","objectID":"/js-cb-asyn/:2:0","tags":["js"],"title":"JS运行机制","uri":"/js-cb-asyn/"},{"categories":["web"],"content":"Promise Promise 对象代表一个异步操作，then() 第一个参数是成功resolve的回调函数，第二个参数是失败reject的回调函数，当不写第二个 then() 参数时，可以用 catch() 捕获 reject 异常。 ","date":"2022-03-18","objectID":"/js-cb-asyn/:3:0","tags":["js"],"title":"JS运行机制","uri":"/js-cb-asyn/"},{"categories":["web"],"content":"使用 var p1 = new Promise(function (resolve, reject) { // resolve('成功'); reject(\"失败\") }); p1.then(function (res) { console.log(\"第一个fn: \", res) }, function (res) { console.log(\"第二个 fn: \", res) }); resolve和reject除了正常的值外，还可能是另一个promise实例。 const p1 = new Promise(function (resolve, reject) { resolve(1) }); const p2 = new Promise(function (resolve, reject) { // ... resolve(p1); }) p2.then(function (res) { console.log(res) }, function (res) { }) 用 catch 捕获 reject 异常 var p1 = new Promise(function (resolve, reject) { // todo... reject(111111) }); p1.then(function (res) { console.log(\"第一个fn: \", res) }).catch(function (err) { console.log(\"err :\", err) }).finally(function () { console.log(\"finally exec...\") }) ","date":"2022-03-18","objectID":"/js-cb-asyn/:3:1","tags":["js"],"title":"JS运行机制","uri":"/js-cb-asyn/"},{"categories":["web"],"content":"执行顺序 ","date":"2022-03-18","objectID":"/js-cb-asyn/:3:2","tags":["js"],"title":"JS运行机制","uri":"/js-cb-asyn/"},{"categories":["web"],"content":"async/await的用法和理解 async 函数是非常新的语法功能，在 ES7 中可用。 async 函数返回一个 Promise 对象，可以使用 then 方法添加回调函数。await 作为修饰符，只能放在 async 内部使用。 当函数执行的时候，一旦遇到 await 就会先返回，等到触发的异步操作完成，再接着执行函数体内后面的语句。 await 等待右侧表达式的结果。 如果等到的不是一个 promise 对象，那 await 表达式的运算结果就是它等到的东西。 如果它等到的是一个 promise 对象，它会阻塞后面的代码，等着 promise 对象 resolve，然后得到 resolve 的值，作为 await 表达式的运算结果。 async function test() { let promise = new Promise(resolve =\u003e { setTimeout(() =\u003e resolve(\"test\"), 2000); }); await promise.then((ret) =\u003e { console.log(ret) }) let test1Ret = await test1() console.log(test1Ret) console.log(\"test end...\") } function test1() { return \"test1_return\" } test(); console.log('end') 运行结果 \" ","date":"2022-03-18","objectID":"/js-cb-asyn/:4:0","tags":["js"],"title":"JS运行机制","uri":"/js-cb-asyn/"},{"categories":["web"],"content":"宏任务和微任务 // TODO ","date":"2022-03-18","objectID":"/js-cb-asyn/:5:0","tags":["js"],"title":"JS运行机制","uri":"/js-cb-asyn/"},{"categories":["web"],"content":"参考 Javascript异步编程的4种方法 JavaScript 运行机制详解：再谈Event Loop async 函数的含义和用法 JS执行——Promise 你真的了解回调? 回调地狱 js中微任务和宏任务的区别 ","date":"2022-03-18","objectID":"/js-cb-asyn/:6:0","tags":["js"],"title":"JS运行机制","uri":"/js-cb-asyn/"},{"categories":["理解计算机"],"content":"HTTP,HTTP协议,超文本传输协议,互联网,TCP/IP,Transmission Control Protocol,传输控制协议,ISO","date":"2022-03-17","objectID":"/http-glance/","tags":["http"],"title":"http入门笔记","uri":"/http-glance/"},{"categories":["理解计算机"],"content":"该笔记是在学习《透视 HTTP 协议》时整理，还参考了网上的其他资料。鄙人只是网络世界的搬运整理工😂。 ","date":"2022-03-17","objectID":"/http-glance/:0:0","tags":["http"],"title":"http入门笔记","uri":"/http-glance/"},{"categories":["理解计算机"],"content":"总览 http总览 \" ","date":"2022-03-17","objectID":"/http-glance/:1:0","tags":["http"],"title":"http入门笔记","uri":"/http-glance/"},{"categories":["理解计算机"],"content":"http 协议 http（超文本传输协议）是一个用在计算机世界里的协议。它使用计算机能够理解的语言确立了一种计算机之间交流通信的规范，以及相关的各种控制和错误处理方式。 http 是一个在计算机世界里专门在两点之间传输文字、图片、音频、视频等超文本数据的约定和规范。 http 不是编程语言，但是可以用编程语言去实现 HTTP，告诉计算机如何用 HTTP 来与外界通信。 在互联网世界里，HTTP 通常跑在 TCP/IP 协议栈之上，依靠 IP 协议实现寻址和路由、TCP 协议实现可靠数据传输、DNS 协议实现域名查找、SSL/TLS 协议实现安全通信。此外，还有一些协议依赖于 HTTP，例如 WebSocket、HTTPDNS 等。这些协议相互交织，构成了一个协议网，而 HTTP 则处于中心地位。 HTTP 传输的不是 TCP/UDP 这些底层协议里被切分的杂乱无章的二进制包（datagram），而是完整的、有意义的数据，可以被浏览器、服务器这样的上层应用程序处理。 ","date":"2022-03-17","objectID":"/http-glance/:2:0","tags":["http"],"title":"http入门笔记","uri":"/http-glance/"},{"categories":["理解计算机"],"content":"互联网和万维网的区别 我们通常所说的“上网”实际上访问的只是互联网的一个子集“万维网”（World Wide Web），它基于 HTTP 协议，传输 HTML 等超文本资源，能力被限制在 HTTP 协议之内。 互联网上还有许多万维网之外的资源，例如常用的电子邮件、BT 和 Magnet 点对点下载、FTP 文件下载、SSH 安全登录、各种即时通信服务等等，它们需要用各自的专有协议来访问。 不过由于 HTTP 协议非常灵活、易于扩展，而且“超文本”的表述能力很强，所以很多其他原本不属于 HTTP 的资源也可以“包装”成 HTTP 来访问，这就是我们为什么能够总看到各种“网页应用”——例如“微信网页版”“邮箱网页版”——的原因。 ","date":"2022-03-17","objectID":"/http-glance/:2:1","tags":["http"],"title":"http入门笔记","uri":"/http-glance/"},{"categories":["理解计算机"],"content":"TCP/IP TCP/IP 协议实际上是一系列网络通信协议的统称， 其中最核心的两个协议是TCP（Transmission Control Protocol/传输控制协议）和IP（Internet Protocol），其他的还有 UDP、ICMP、ARP 等等，共同构成了一个复杂但有层次的协议栈。 HTTP 是超文本传输协议，TCP 是传输控制协议，都是传输，区别是，HTTP 传输的是完整的、有意义的数据，可以被浏览器、 服务器这样的上层应用程序处理，HTTP 不关心寻址、路由、数据完整性等传输细节，而要求这些工作都由下层（基本都由 TCP）来处理。 TCP 传输的是可靠的、字节流和二进制包。 TCP 是 HTTP 得以实现的基础，HTTP 协议运行在 TCP/IP 上，HTTP 可以更准确地称为 “HTTP over TCP/IP”。 ","date":"2022-03-17","objectID":"/http-glance/:2:2","tags":["http"],"title":"http入门笔记","uri":"/http-glance/"},{"categories":["理解计算机"],"content":"URI/URL URI（Uniform Resource Identifier），中文名称是 统一资源标识符，使用它就能够唯一地标记互联网上资源。 URI 另一个更常用的表现形式是 URL（Uniform Resource Locator）， 统一资源定位符，也就是我们俗称的“网址”，它实际上是 URI 的一个子集，这两者几乎是相同的，差异不大，除非写论文，否则不用特意区分。 ","date":"2022-03-17","objectID":"/http-glance/:2:3","tags":["http"],"title":"http入门笔记","uri":"/http-glance/"},{"categories":["理解计算机"],"content":"SSL/TSL SSL 的全称是“Secure Socket Layer”，网景公司发明，当发展到 3.0 时被标准化，改名为 TLS，即“Transport Layer Security”。 所以 TLS 跟 SSL 是一个东西，相当于张君宝的 2.0 版本是张三丰。 SSL 是一个负责加密通信的安全协议，建立在 TCP/IP 之上，在 HTTP 协议之下。 ","date":"2022-03-17","objectID":"/http-glance/:2:4","tags":["http"],"title":"http入门笔记","uri":"/http-glance/"},{"categories":["理解计算机"],"content":"Proxy 代理 匿名代理：完全“隐匿”了被代理的机器，外界看到的只是代理服务器； 透明代理：顾名思义，它在传输过程中是“透明开放”的，外界既知道代理，也知道客户端； 正向代理：靠近客户端，代表客户端向服务器发送请求； 正向代理正向代理 \" 正向代理 反向代理：靠近服务器端，代表服务器响应客户端的请求； 反向代理反向代理 \" 反向代理 Tip 如何理解反向代理服务器 ","date":"2022-03-17","objectID":"/http-glance/:2:5","tags":["http"],"title":"http入门笔记","uri":"/http-glance/"},{"categories":["理解计算机"],"content":"http 版本 万维网关键技术 URI：即统一资源标识符，作为互联网上资源的唯一身份； HTML：即超文本标记语言，描述超文本文档； HTTP：即超文本传输协议，用来传输超文本。 基于这三项关键技术就可以把超文本系统完美地运行在互联网上，让各地的人们能够自由地共享信息，这个系统称为“万维网”（World Wide Web），也就是我们现在所熟知的 Web。 ","date":"2022-03-17","objectID":"/http-glance/:3:0","tags":["http"],"title":"http入门笔记","uri":"/http-glance/"},{"categories":["理解计算机"],"content":"http/0.9 结构简单，设置之初设想系统里的文档都是只读的，所以只允许用 GET 动作从服务器上获取 HTML 纯文本格式的文档，并且在响应请求之后立即关闭连接，功能非常有限。 ","date":"2022-03-17","objectID":"/http-glance/:3:1","tags":["http"],"title":"http入门笔记","uri":"/http-glance/"},{"categories":["理解计算机"],"content":"http/1.0 HTTP/1.0 并不是一个标准，只是记录已有实践和模式的一份参考文档，不具有实际的约束力，相当于一个备忘录。 在多方面增强了 0.9 版，形式上已经和我们现在的 HTTP 差别不大了，例如： 增加了 HEAD、POST 等新方法； 增加了响应状态码，标记可能的错误原因； 引入了协议版本号概念； 引入了 HTTP Header（头部）的概念，让 HTTP 处理请求和响应更加灵活； 传输的数据不再仅限于文本。 ","date":"2022-03-17","objectID":"/http-glance/:3:2","tags":["http"],"title":"http入门笔记","uri":"/http-glance/"},{"categories":["理解计算机"],"content":"http/1.1 是一个正式的标准，而不是一份可有可无的参考文档，只要用到 HTTP 协议，就必须严格遵守这个标准。 主要变更： 增加了 PUT、DELETE 等新的方法； 增加了缓存管理和控制； 明确了连接管理，允许持久连接； 允许响应数据分块（chunked），利于传输大文件； 强制要求 Host 头，让互联网主机托管成为可能。 ","date":"2022-03-17","objectID":"/http-glance/:3:3","tags":["http"],"title":"http入门笔记","uri":"/http-glance/"},{"categories":["理解计算机"],"content":"http/2 由 google 主导，基于 google 的 SPDY 协议为基础开始制定新版本的 HTTP 协议，最终在 2015 年发布了 HTTP/2。 主要特点： 二进制协议，不再是纯文本； 可发起多个请求，废弃了 1.1 里的管道； 使用专用算法压缩头部，减少数据传输量； 允许服务器主动向客户端推送数据； 增强了安全性，“事实上”要求加密通信。 ","date":"2022-03-17","objectID":"/http-glance/:3:4","tags":["http"],"title":"http入门笔记","uri":"/http-glance/"},{"categories":["理解计算机"],"content":"http/3 由 google 主导，基于 google 的 QUIC 协议为基础开始制定新版本的 HTTP 协议。 ","date":"2022-03-17","objectID":"/http-glance/:3:5","tags":["http"],"title":"http入门笔记","uri":"/http-glance/"},{"categories":["理解计算机"],"content":"网络分层模型 ","date":"2022-03-17","objectID":"/http-glance/:4:0","tags":["http"],"title":"http入门笔记","uri":"/http-glance/"},{"categories":["理解计算机"],"content":"TCP/IP TCP/IP分层模型tcp/ip分层模型 \" TCP/IP分层模型 这里的层次顺序是“从下往上”数的，所以第一层就是最下面的一层。 链接层 第一层叫“链接层”（link layer），负责在以太网、WiFi 这样的底层网络上发送原始数据包，工作在网卡这个层次，使用 MAC 地址来标记网络上的设备，所以有时候也叫 MAC 层。 网络互联层 第二层叫“网际层”或者“网络互连层”（internet layer），IP 协议就处在这一层。因为 IP 协议定义了“IP 地址”的概念，所以就可以在“链接层”的基础上，用 IP 地址取代 MAC 地址，把许许多多的局域网、广域网连接成一个虚拟的巨大网络，在这个网络里找设备时只要把 IP 地址再“翻译”成 MAC 地址就可以了。 传输层 第三层叫“传输层”（transport layer），这个层次协议的职责是保证数据在 IP 地址标记的两点之间“可靠”地传输，是 TCP 协议工作的层次，另外还有它的一个“小伙伴”UDP。 TCP 是一个有状态的协议，需要先与对方建立连接然后才能发送数据，而且保证数据不丢失不重复。而 UDP 则比较简单，它无状态，不用事先建立连接就可以任意发送数据，但不保证数据一定会发到对方。两个协议的另一个重要区别在于数据的形式。TCP 的数据是连续的“字节流”，有先后顺序，而 UDP 则是分散的小数据包，是顺序发，乱序收。 应用层 协议栈的第四层叫“应用层”（application layer），由于下面的三层把基础打得非常好，所以在这一层就“百花齐放”了，有各种面向具体应用的协议。例如 Telnet、SSH、FTP、SMTP，HTTP 等等。 Tip MAC 层（链接层）的传输单位是帧（frame），IP 层（网络互联层）的传输单位是包（packet），TCP 层传输层的传输单位是段（segment）， HTTP （应用层）的传输单位则是消息或报文（message）。这些名词并没有什么本质的区分，可以统称为数据包。 ","date":"2022-03-17","objectID":"/http-glance/:4:1","tags":["http"],"title":"http入门笔记","uri":"/http-glance/"},{"categories":["理解计算机"],"content":"OSI 网络分层模型 OSI 分层模型在发布的时候就明确地表明是一个“参考”，不是强制标准。这是因为 TCP/IP 等协议已经在许多网络上实际运行，不可能推翻重来。 OSI网络模型OSI模型 \" OSI网络模型 第一层：物理层，网络的物理形式，例如电缆、光纤、网卡、集线器等等； 第二层：数据链路层，它基本相当于 TCP/IP 的链接层； 第三层：网络层，相当于 TCP/IP 里的网际层； 第四层：传输层，相当于 TCP/IP 里的传输层； 第五层：会话层，维护网络中的连接状态，即保持会话和同步； 第六层：表示层，把数据转换为合适、可理解的语法和语义； 第七层：应用层，面向具体的应用传输数据。 对比一下就可以发现，TCP/IP 是一个纯软件的栈，没有网络应有的最根基的电缆、网卡等物理设备的位置。而 OSI 则补足了这个缺失， 在理论层面上描述网络更加完整。 OSI 还为每一层标记了明确了编号，最底层是一层，最上层是七层，而 TCP/IP 的层次从来只有名字而没有编号。 ","date":"2022-03-17","objectID":"/http-glance/:4:2","tags":["http"],"title":"http入门笔记","uri":"/http-glance/"},{"categories":["理解计算机"],"content":"两个分层模型的对应关系 两个分层模型的对应关系对应关系 \" 两个分层模型的对应关系 所谓的“四层负载均衡”就是指工作在传输层上，基于 TCP/IP 协议的特性，例如 IP 地址、端口号等实现对后端服务器的负载均衡。 所谓的“七层负载均衡”就是指工作在应用层上，看到的是 HTTP 协议，解析 HTTP 报文里的 URI、主机名、资源类型等数据，再用适当的策略转发给后端服务器。 有一个辨别四层和七层比较好的（但不是绝对的）小窍门，“两个凡是”：凡是由操作系统负责处理的就是四层或四层以下，否则，凡是需要由应用程序（也就是你自己写代码）负责处理的就是七层。 ","date":"2022-03-17","objectID":"/http-glance/:4:3","tags":["http"],"title":"http入门笔记","uri":"/http-glance/"},{"categories":["理解计算机"],"content":"http协议核心 由于 HTTP 是在 TCP/IP 协议之上的，而 TCP/IP 协议负责底层的具体传输工作，所以 http 在传输方面不用太操心，TCP/IP 会去解决，所以 HTTP 关心的就只有他所传输的报文内容，又因为 HTTP 是“纯文本”的，包括头信息都是 ASCII 码的文本，不用借助程序解析可以直接阅读。 http报文 \" ","date":"2022-03-17","objectID":"/http-glance/:5:0","tags":["http"],"title":"http入门笔记","uri":"/http-glance/"},{"categories":["理解计算机"],"content":"常用头字段 注意事项 字段名不区分大小写，例如“Host”也可以写成“host”，但首字母大写的可读性更好； 字段名里不允许出现空格，可以使用连字符“-”，但不能使用下划线“_”。例如，“test-name”是合法的字段名，而“test name”“test_name”是不正确的字段名； 字段名后面必须紧接着“:”，不能有空格，而“:”后的字段值前可以有多个空格； 分类 通用字段：在请求头和响应头里都可以出现； 请求字段：仅能出现在请求头里，进一步说明请求信息或者额外的附加条件； 响应字段：仅能出现在响应头里，补充说明响应报文的信息； 实体字段：它实际上属于通用字段，但专门描述 body 的额外信息。 字段 类型 说明 Host 请求字段 唯一一个 HTTP/1.1 规范里要求必须出现的字段，如果请求头里没有 Host，那这就是一个错误的报文。Host 字段告诉服务器这个请求应该由哪个主机来处理 User-Agent 请求字段 描述发起 HTTP 请求的客户端，服务器可以依据它来返回最合适此浏览器显示的页面 Date 通用字段 表示 HTTP 报文创建的时间，客户端可以使用这个时间再搭配其他字段决定缓存策略 Server 响应字段 告诉客户端当前正在提供 Web 服务的软件名称和版本号 Content-Length 实体字段 报文里 body 的长度，也就是请求头或响应头空行后面数据的长度。服务器看到这个字段，就知道了后续有多少数据，可以直接接收。如果没有这个字段，那么 body 就是不定长的，需要使用 chunked 方式分段传输 ","date":"2022-03-17","objectID":"/http-glance/:5:1","tags":["http"],"title":"http入门笔记","uri":"/http-glance/"},{"categories":["理解计算机"],"content":"请求方式 请求方式 \" 方式 说明 GET 获取资源，可以理解为读取或者下载数据 HEAD 获取资源的元信息，不会返回请求的实体数据，只会传回响应头 POST 向资源提交数据，相当于写入或上传数据 PUT 类似 POST DELETE 删除资源 CONNECT 建立特殊的连接隧道 OPTIONS 列出可对资源实行的方法 TRACE 追踪请求 - 响应的传输路径 ","date":"2022-03-17","objectID":"/http-glance/:5:2","tags":["http"],"title":"http入门笔记","uri":"/http-glance/"},{"categories":["理解计算机"],"content":"状态码 状态码 含义 1×x 提示信息，表示目前是协议处理的中间状态，还需要后续的操作 2×× 成功，报文已经收到并被正确处理 3×× 重定向，资源位置发生变动，需要客户端重新发送请求 4×× 客户端错误，请求报文有误，服务器无法处理 5×× 服务器错误，服务器在处理请求时内部发生了错误 一些常用状态码说明 status code 说明 301 永久重定向，含义是此次请求的资源已经不存在了，需要改用改用新的 URI 再次访问 302 临时重定向，意思是请求的资源还在，但需要暂时用另一个 URI 来访问。比如，你的网站升级到了 HTTPS，原来的 HTTP 不打算用了，这就是“永久”的，所以要配置 301 跳转，把所有的 HTTP 流量都切换到 HTTPS。 再比如，今天夜里网站后台要系统维护，服务暂时不可用，这就属于“临时”的，可以配置成 302 跳转，把流量临时切换到一个静态通知页面，浏览器看到这个 302 就知道这只是暂时的情况，不会做缓存优化，第二天还会访问原来的地址。 304 Not Modified，它用于 If-Modified-Since 等条件请求，表示资源未修改，用于缓存控制。它不具有通常的跳转含义，但可以理解成“重定向已到缓存的文件”（即“缓存重定向”） 405 不允许使用某些方法操作资源，例如不允许 POST 只能 GET 406 Not Acceptable 资源无法满足客户端请求的条件，例如请求中文但只有英文 408 Request Timeout：请求超时，服务器等待了过长的时间 409 Conflict：多个请求发生了冲突，可以理解为多线程并发时的竞态 413 Request Entity Too Large：请求报文里的 body 太大 414 Request-URI Too Long：请求行里的 URI 太大 429 Too Many Requests 客户端发送了太多的请求，通常是由于服务器的限连策略 431 Request Header Fields Too Large 请求头某个字段或总体太大 500 Internal Server Error 与 400 类似，也是一个通用的错误码，服务器究竟发生了什么错误我们是不知道的。不过对于服务器来说这应该算是好事，通常不应该把服务器内部的详细信息，例如出错的函数调用栈告诉外界。虽然不利于调试，但能够防止黑客的窥探或者分析 501 Not Implemented 表示客户端请求的功能还不支持，这个错误码比 500 要温和一些，和“即将开业，敬请期待”的意思差不多，不过具体什么时候“开业”就不好说了 502 Bad Gateway”通常是服务器作为网关或者代理时返回的错误码，表示服务器自身工作正常，访问后端服务器时发生了错误，但具体的错误原因也是不知道的 503 Service Unavailable 表示服务器当前很忙，暂时无法响应服务，我们上网时有时候遇到的“网络服务正忙，请稍后重试”的提示信息就是状态码 503 ","date":"2022-03-17","objectID":"/http-glance/:5:3","tags":["http"],"title":"http入门笔记","uri":"/http-glance/"},{"categories":["golang"],"content":"golang GMP 模型,go 数学模型,GMP,进程,线程,协程,goroutine,go 调度器,golang调度器,go协程调度模型","date":"2022-03-16","objectID":"/gmp-model/","tags":["golang"],"title":"go GMP 模型","uri":"/gmp-model/"},{"categories":["golang"],"content":"进程、线程、协程的区别 ","date":"2022-03-16","objectID":"/gmp-model/:1:0","tags":["golang"],"title":"go GMP 模型","uri":"/gmp-model/"},{"categories":["golang"],"content":"进程 进程是操作系统对一个正在运行的程序的一种抽象，进程是资源分配的最小单位。 进程在操作系统中的抽象表现进程在操作系统中的抽象表现 \" 进程在操作系统中的抽象表现 进程存在的意义是为了合理压榨 CPU 的性能和分配运行的时间片，不能 “闲着“。 在计算机中，其计算核心是 CPU，负责所有计算相关的工作和资源。单个 CPU 一次只能运行一个任务。如果一个进程跑着，就把唯一一个 CPU 给完全占住，那是非常不合理的。 如果总是在运行一个进程上的任务，就会出现一个现象。就是任务不一定总是在执行 ”计算型“ 的任务，会有很大可能是在执行网络调用，阻塞了，CPU 岂不就浪费了？ 进程上下文切换进程上下文切换 \" 进程上下文切换 所以出现了多进程，多个 CPU，多个进程。多进程就是指计算机系统可以同时执行多个进程，从一个进程到另外一个进程的转换是由操作系统内核管理的，一般是同时运行多个软件。 ","date":"2022-03-16","objectID":"/gmp-model/:1:1","tags":["golang"],"title":"go GMP 模型","uri":"/gmp-model/"},{"categories":["golang"],"content":"线程 有了多进程，在操作系统上可以同时运行多个进程。那么为什么有了进程，还要线程呢？这是因为， 进程间的信息难以共享数据，父子进程并未共享内存，需要通过进程间通信（IPC），在进程间进行信息交换，性能开销较大。 创建进程（一般是调用 fork 方法）的性能开销较大。 大家又把目光转向了进程内，能不能在进程里做点什么呢？ 进程由多个线程组成进程由多个线程组成 \" 进程由多个线程组成 一个进程可以由多个称为线程的执行单元组成。每个线程都运行在进程的上下文中，共享着同样的代码和全局数据。 多个进程，就可以有更多的线程。多线程比多进程之间更容易共享数据，在上下文切换中线程一般比进程更高效。这是因为， 线程之间能够非常方便、快速地共享数据。 只需将数据复制到进程中的共享区域就可以了，但需要注意避免多个线程修改同一份内存。 创建线程比创建进程要快 10 倍甚至更多。 线程都是同一个进程下自家的孩子，像是内存页、页表等就不需要了。 ","date":"2022-03-16","objectID":"/gmp-model/:1:2","tags":["golang"],"title":"go GMP 模型","uri":"/gmp-model/"},{"categories":["golang"],"content":"协程 协程（Coroutine）是用户态的线程。通常创建协程时，会从进程的堆中分配一段内存作为协程的栈。 线程的栈有 8 MB，而协程栈的大小通常只有 KB，而 Go 语言的协程更夸张，只有 2-4KB，非常的轻巧。 协程有以下优势👋： 👉节省 CPU：避免系统内核级的线程频繁切换，造成的 CPU 资源浪费。好钢用在刀刃上。而协程是用户态的线程，用户可以自行控制协程的创建于销毁，极大程度避免了系统级线程上下文切换造成的资源浪费。 👉节约内存：在 64 位的Linux中，一个线程需要分配 8MB 栈内存和 64MB 堆内存，系统内存的制约导致我们无法开启更多线程实现高并发。而在协程编程模式下，可以轻松有十几万协程，这是线程无法比拟的。 👉稳定性：前面提到线程之间通过内存来共享数据，这也导致了一个问题，任何一个线程出错时，进程中的所有线程都会跟着一起崩溃。 👉开发效率：使用协程在开发程序之中，可以很方便的将一些耗时的IO操作异步化，例如写文件、耗时 IO 请求等。 ","date":"2022-03-16","objectID":"/gmp-model/:1:3","tags":["golang"],"title":"go GMP 模型","uri":"/gmp-model/"},{"categories":["golang"],"content":"goroutine 是什么 Goroutine 是一个由 Go 运行时管理的轻量级线程，我们称为 “协程”。 go f(x, y, z) 操作系统本身是无法明确感知到 Goroutine 的存在的，Goroutine 的操作和切换归属于 “用户态” 中。 Goroutine 由特定的调度模式来控制，以 “多路复用” 的形式运行在操作系统为 Go 程序分配的几个系统线程上。 同时创建 Goroutine 的开销很小，初始只需要 2-4k 的栈空间。Goroutine 本身会根据实际使用情况进行自伸缩，非常轻量。 Tips Go程序中没有语言级的关键字让你去创建一个内核线程，你只能创建 goroutine，内核线程只能由 runtime 根据实际情况去创建。 Go运行时系统并没有内核调度器的中断能力，内核调度器会发起抢占式调度将长期运行的线程中断并让出CPU资源，让其他线程获得执行机会。 ","date":"2022-03-16","objectID":"/gmp-model/:2:0","tags":["golang"],"title":"go GMP 模型","uri":"/gmp-model/"},{"categories":["golang"],"content":"什么是调度 用户态的 Goroutine，操作系统看不到它。必然需要有某个东西去管理他，才能更好的运作起来。 这就是 Go 语言中的调度，也就是 GMP 模型。 Go scheduler /ˈskedʒuːlər/ 的主要功能是针对在处理器上运行的 OS 线程分发可运行的 Goroutine，而我们一提到调度器，就离不开三个经常被提到的缩写，分别是： G：Goroutine，实际上我们每次调用 go func 就是生成了一个 G。 P：Processor，处理器，一般 P 的数量就是处理器的核数，可以通过 GOMAXPROCS 进行修改。 M：Machine，系统线程。 这三者交互实际来源于 Go 的 M: N 调度模型。也就是 M 必须与 P 进行绑定，然后不断地在 M 上循环寻找可运行的 G 来执行相应的任务。 ","date":"2022-03-16","objectID":"/gmp-model/:3:0","tags":["golang"],"title":"go GMP 模型","uri":"/gmp-model/"},{"categories":["golang"],"content":"调度流程 调度流程调度流程 \" 调度流程 当我们执行 go func() 时，实际上就是创建一个全新的 Goroutine，我们称它为 G。 新创建的 G 会被放入 P 的本地队列（Local Queue）或全局队列（Global Queue）中，准备下一步的动作。需要注意的一点，这里的 P 指的是创建 G 的 P。 唤醒或创建 M 以便执行 G。 不断地进行事件循环 寻找在可用状态下的 G 进行执行任务 清除后，重新进入事件循环 在描述中有提到全局和本地这两类队列，其实在功能上来讲都是用于存放正在等待运行的 G，但是不同点在于，本地队列有数量限制，不允许超过 256 个。 并且在新建 G 时，会优先选择 P 的本地队列，如果本地队列满了，则将 P 的本地队列的一半的 G 移动到全局队列。 可以理解为调度资源的共享和再平衡。 ","date":"2022-03-16","objectID":"/gmp-model/:4:0","tags":["golang"],"title":"go GMP 模型","uri":"/gmp-model/"},{"categories":["golang"],"content":"窃取行为 可以看到图上有 steal 行为，这是用来做什么的呢，我们都知道当你创建新的 G 或者 G 变成可运行状态时，它会被推送加入到当前 P 的本地队列中。 其实当 P 执行 G 完毕后，它也会 “干活”，它会将其从本地队列中弹出 G，同时会检查当前本地队列是否为空，如果为空会随机的从其他 P 的本地队列中尝试窃取一半可运行的 G 到自己的名下。 窃取行为窃取行为 \" 窃取行为 上图中👆，P2 在本地队列中找不到可以运行的 G，它会执行 work-stealing 调度算法，随机选择其它的处理器 P1，并从 P1 的本地队列中窃取了三个 G 到它自己的本地队列中去。 至此，P1、P2 都拥有了可运行的 G，P1 多余的 G 也不会被浪费，调度资源将会更加平均的在多个处理器中流转。 ","date":"2022-03-16","objectID":"/gmp-model/:5:0","tags":["golang"],"title":"go GMP 模型","uri":"/gmp-model/"},{"categories":["golang"],"content":"限制条件 ","date":"2022-03-16","objectID":"/gmp-model/:6:0","tags":["golang"],"title":"go GMP 模型","uri":"/gmp-model/"},{"categories":["golang"],"content":"M 的限制 在协程的执行中，真正干活的是 GPM 中的 M（系统线程） ，因为 G 是用户态上的东西，最终执行都是得映射，对应到 M 这一个系统线程上去运行。 那么 M 有没有限制呢？ 答案是：有的。在 Go 语言中，M 的默认数量限制是 10000，如果超出则会报错： GO: runtime: program exceeds 10000-thread limit 但是通常只有在 Goroutine 出现阻塞操作的情况下，才会遇到这种情况。这可能也预示着你的程序有问题。 若确切是需要那么多，还可以通过 debug.SetMaxThreads 方法进行设置。 ","date":"2022-03-16","objectID":"/gmp-model/:6:1","tags":["golang"],"title":"go GMP 模型","uri":"/gmp-model/"},{"categories":["golang"],"content":"G 的限制 Goroutine 的创建数量是否有限制？ 答案是：没有。但理论上会受内存的影响，假设一个 Goroutine 创建需要 4k 的连续的内存块： 4k * 80,000 = 320,000k ≈ 0.3G内存 4k * 1,000,000 = 4,000,000k ≈ 4G内存 以此就可以相对计算出来一台单机在通俗情况下，所能够创建 Goroutine 的大概数量级别。 ","date":"2022-03-16","objectID":"/gmp-model/:6:2","tags":["golang"],"title":"go GMP 模型","uri":"/gmp-model/"},{"categories":["golang"],"content":"P 的限制 P 的数量是否有限制，受什么影响？ 答案是：有限制。P 的数量受环境变量 GOMAXPROCS 的直接影响。 环境变量 GOMAXPROCS 又是什么？在 Go 语言中，通过设置 GOMAXPROCS，用户可以调整调度中 P（Processor）的数量。 另一个重点在于，与 P 相关联的的 M（系统线程），是需要绑定 P 才能进行具体的任务执行的，因此 P 的多少会影响到 Go 程序的运行表现。 P 的数量基本是受本机的核数影响，没必要太过度纠结他。 那 P 的数量是否会影响 Goroutine 的数量创建呢？ 答案是：不影响。且 Goroutine 多了少了，P 也该干嘛干嘛，不会带来灾难性问题。 ","date":"2022-03-16","objectID":"/gmp-model/:6:3","tags":["golang"],"title":"go GMP 模型","uri":"/gmp-model/"},{"categories":["golang"],"content":"小结 M：有限制，默认数量限制是 10000，可调整。 G：没限制，但受内存影响。 P：受本机的核数影响，可大可小，不影响 G 的数量创建。 所以Goroutine 数量怎么预算，才叫合理？ 在真实的应用场景中，如果你 Goroutine： 在频繁请求 HTTP，MySQL，打开文件等，那假设短时间内有几十万个协程在跑，那肯定就不大合理了（可能会导致 too many files open）。 常见的 Goroutine 泄露所导致的 CPU、Memory 上涨等，还是得看你的 Goroutine 里具体在跑什么东西。 跑的如果是 “资源怪兽”，只运行几个 Goroutine 都可以跑死。 ","date":"2022-03-16","objectID":"/gmp-model/:6:4","tags":["golang"],"title":"go GMP 模型","uri":"/gmp-model/"},{"categories":["golang"],"content":"为什么要有 P // TODO ","date":"2022-03-16","objectID":"/gmp-model/:7:0","tags":["golang"],"title":"go GMP 模型","uri":"/gmp-model/"},{"categories":["golang"],"content":"参考 Go 为什么这么“快” 让你很快就能理解-go的协程调度原理 Goroutine 数量控制在多少合适，会影响 GC 和调度？ Golang goroutine与调度器 进程与线程的一个简单解释 [典藏版] Golang 调度器 GMP 原理与调度全分析 ","date":"2022-03-16","objectID":"/gmp-model/:8:0","tags":["golang"],"title":"go GMP 模型","uri":"/gmp-model/"},{"categories":["golang"],"content":"go build 常用命令,golang,编译,go 编译","date":"2022-03-16","objectID":"/go-build-args/","tags":["golang"],"title":"go 常用命令","uri":"/go-build-args/"},{"categories":["golang"],"content":"常用编译参数 参数 说明 -o 指定输出可执行文件名 -v 编译时显示包名，可以理解成输出详细编译信息 -race 开启竞态检测 *.go 编译当前目录下的所有go文件，也可以写成 f2.go f2.go … -a 强制重新构建 -w 去掉DWARF调试信息，得到的程序就不能用gdb调试了 -s 去掉符号表,panic时候的stack trace就没有任何文件名/行号信息了，这个等价于普通C/C++程序被strip的效果 -X 设置包中的变量值 -gcflags \"-N -l\" 编译目标程序的时候会嵌入运行时(runtime)的二进制，禁止优化和内联可以让运行时(runtime)中的函数变得更容易调试。gcflags 其实是给go编译器传入参数，也就是传给go tool compile的参数，因此可以用go tool compile --help查看所有可用的参数 -ldflags 给go链接器传入参数，实际是给go tool link的参数，可以用go tool link --help查看可用的参数。 -ldflags '-extldflags \"-static\"' 静态编译 ","date":"2022-03-16","objectID":"/go-build-args/:1:0","tags":["golang"],"title":"go 常用命令","uri":"/go-build-args/"},{"categories":["golang"],"content":"交叉编译 参数 说明 GOOS GOARCH linux 386 / amd64 / arm darwin 386 / amd64 feedbsd 386 / amd64 windows 386 / amd64 对于编译给ARM使用的Go程序，需要根据实际情况配置$GOARM，这是用来控制CPU的浮点协处理器的参数。 $GOARM默认是6，对于不支持VFP使用软件运算的老版本ARM平台要设置成5，支持VFPv1的设置成6，支持VFPv3的设置成7。 示例 GOARM=7 GOARCH=arm GOOS=linux go build -v -o fca ","date":"2022-03-16","objectID":"/go-build-args/:2:0","tags":["golang"],"title":"go 常用命令","uri":"/go-build-args/"},{"categories":["golang"],"content":"go mod // TODO ","date":"2022-03-16","objectID":"/go-build-args/:3:0","tags":["golang"],"title":"go 常用命令","uri":"/go-build-args/"},{"categories":["golang"],"content":"参考 golang编译时的参数传递（gcflags, ldflags） Golang交叉编译（跨平台编译）简述 交叉编译Go程序 ARM flags GOARM go mod使用 ","date":"2022-03-16","objectID":"/go-build-args/:4:0","tags":["golang"],"title":"go 常用命令","uri":"/go-build-args/"},{"categories":["web"],"content":"node,nodejs, heap out of memory","date":"2022-03-16","objectID":"/node-oom/","tags":["web","node"],"title":"JavaScript heap out of memory","uri":"/node-oom/"},{"categories":["web"],"content":"刚在打包项目时执行 yarn run build 时出现了 oom 的情况，具体报错信息如下： JavaScript heap out of memory \" 我的环境是 win10 专业版 WSL。 解决办法，设置 export NODE_OPTIONS=--max_old_space_size=4096，设置完之后重新执行 yarn run build 即可。 ","date":"2022-03-16","objectID":"/node-oom/:0:0","tags":["web","node"],"title":"JavaScript heap out of memory","uri":"/node-oom/"},{"categories":["web"],"content":"参考 Node.js heap out of memory ","date":"2022-03-16","objectID":"/node-oom/:1:0","tags":["web","node"],"title":"JavaScript heap out of memory","uri":"/node-oom/"},{"categories":["开发者手册"],"content":"Google,浏览器插件,插件下载","date":"2022-03-16","objectID":"/googe-plugin-download/","tags":["chrome"],"title":"将google浏览器插件下载到本地","uri":"/googe-plugin-download/"},{"categories":["开发者手册"],"content":"国内的网络太复杂了，在不能访问 google 的情况下，甚至都不能打开网上应用商店，所以我们需要一个方便的方式来下载google浏览器插件并分享 给需要的小伙伴。 我们打开任意一个浏览器插件，如： 浏览器插件 \" URL 地址栏中有一串字符串，这是唯一的，通过这个字符串可以获取到插件的下载地址，如： 插件UUID \" 下载地址为： https://clients2.google.com/service/update2/crx?response=redirect\u0026os=win\u0026arch=x64\u0026os_arch=x86_64\u0026nacl_arch=x86-64\u0026prod=chromecrx\u0026prodchannel=\u0026prodversion=77.0.3865.90\u0026lang=zh-CN\u0026acceptformat=crx2,crx3\u0026x=id%3D{XXXX}%26installsource%3Dondemand%26uc 将以上的 {XXXX} 替换为插件的 ID，就可以下载到本地了。 以下这个地址是Mote：语音笔记和反馈插件的下载地址，成功下载的插件是 .crx 结尾的文件。直接拖到浏览器中就会自动安装。 https://clients2.google.com/service/update2/crx?response=redirect\u0026os=win\u0026arch=x64\u0026os_arch=x86_64\u0026nacl_arch=x86-64\u0026prod=chromecrx\u0026prodchannel=\u0026prodversion=77.0.3865.90\u0026lang=zh-CN\u0026acceptformat=crx2,crx3\u0026x=id%3Dajphlblkfpppdpkgokiejbjfohfohhmk%26installsource%3Dondemand%26uc ","date":"2022-03-16","objectID":"/googe-plugin-download/:0:0","tags":["chrome"],"title":"将google浏览器插件下载到本地","uri":"/googe-plugin-download/"},{"categories":null,"content":"xiaobinqt's personal website,xiaobinqt,程序员,程序猿,xiaobinqt@163.com","date":"2022-03-06","objectID":"/about/","tags":null,"title":"About Me","uri":"/about/"},{"categories":null,"content":"缘起 很喜欢电影《五亿探长雷洛传》，电影一开头，由潮州迁居香港的青年雷洛，为了生计，投考香港警察，面试官问他，为什么要当警察，他回答，为了吃饭。 为了吃饭为了吃饭 \" 为了吃饭 大学毕业后，为了吃饭，便利用自己了解的一点编程知识开始码农之路。大学学的是通信工程，非计算机专业，编程之路困难重重，但好歹自己有自知之明，笨人多努力，相信通过自己的努力，可以让自己的编程技术更加完善。 好记性不如烂笔头，想着把自己工作期间遇到的问题，平时看到的好的文章，记录下来，方便查找和温习，也是记录自己的不足和成长，便有了这个网站。 建站的初衷不是为了炫耀所知，而是记录无知。 人知道得越多，就会发现无知的越多。有更广袤的世界可以探索，是莫大的快乐呀！ ","date":"2022-03-06","objectID":"/about/:1:0","tags":null,"title":"About Me","uri":"/about/"},{"categories":null,"content":"关于作者 👨‍💻 半路出家的程序猿，技术不精，但有一个成为技术大拿的梦想。 🤪 拖延症患者，持续性混吃等死，间接性踌躇满志。 💕 爱好读书，但总是边读边忘 😢。 ","date":"2022-03-06","objectID":"/about/:2:0","tags":null,"title":"About Me","uri":"/about/"},{"categories":null,"content":"职业生涯 2017/4 - 2019/3 在西安一家科技公司从事 PHP 开发。 2019/4 - 2021/3 在北京腾讯外包从事 PHP 和 Go 开发。 2021/4 - 至今 版权说明 本站图片和文字，除原创作品之外，部分来自互联网。 此类资源的原版权所有者可在任何时候、以任何理由要求本站停止使用，其中包括被本站编辑（比如加注说明）过的资源， 联系方式见下文。 ","date":"2022-03-06","objectID":"/about/:3:0","tags":null,"title":"About Me","uri":"/about/"},{"categories":null,"content":"联系方式 邮箱：xiaobinqt@163.com Github：@xiaobinqt 微信： 个人微信\" 个人微信 ","date":"2022-03-06","objectID":"/about/:4:0","tags":null,"title":"About Me","uri":"/about/"},{"categories":["golang"],"content":"golang grpc,golang,rpc,grpc,grpc 入门","date":"2022-03-05","objectID":"/grpc-demo/","tags":["golang"],"title":"grpc 入门应用","uri":"/grpc-demo/"},{"categories":["golang"],"content":"RPC 是一种跨语言的协议，它可以让我们在不同的语言之间进行通信。 远程过程调用（英语：Remote Procedure Call，缩写为 RPC）是一个计算机通信协议。该协议允许运行于一台计算机的程序调用另一个 地址空间（通常为一个开放网络的一台计算机）的子程序，而程序员就像调用本地程序一样，无需额外地为这个交互作用编程（无需关注细节）。 RPC是一种服务器-客户端（Client/Server）模式，经典实现是一个通过发送请求-接受回应进行信息交互的系统。 ","date":"2022-03-05","objectID":"/grpc-demo/:0:0","tags":["golang"],"title":"grpc 入门应用","uri":"/grpc-demo/"},{"categories":["golang"],"content":"安装 go install github.com/golang/protobuf/protoc-gen-go@v1.4.0 go install google.golang.org/grpc/cmd/protoc-gen-go-grpc@v1.1 不推荐使用 google.golang.org/protobuf/cmd/protoc-gen-go@v1.26 这个版本太高了，可能会遇到以下这个问题， --go_out: protoc-gen-go: plugins are not supported; use 'protoc --go-grpc_out=...' to generate gRPC See https://grpc.io/docs/languages/go/quickstart/#regenerate-grpc-code for more information. 生成代码遇到的问题 \" 参考解决方案记一次奇妙的go-protobuf包升级之旅 protoc 工具安装 下载地址，下载解压将 bin 目录添加到环境变量中。 protoc \" ","date":"2022-03-05","objectID":"/grpc-demo/:1:0","tags":["golang"],"title":"grpc 入门应用","uri":"/grpc-demo/"},{"categories":["golang"],"content":"定义 proto 文件 syntax = \"proto3\"; // 使用protobuf版本3 option go_package = \"./protobuf\"; // 这个影响生成的目录及go的package命名 // 定义一个计算服务, 输入为CalcRequest, 输出为CalcResponse service CalculatorService { rpc calc(CalcRequest) returns (CalcResponse) {};}// 计算两个数某种运算(如加法)的参数 message CalcRequest { double a = 1; double b = 2; string op = 3;}// 计算结果 message CalcResponse { double r = 1;} ","date":"2022-03-05","objectID":"/grpc-demo/:2:0","tags":["golang"],"title":"grpc 入门应用","uri":"/grpc-demo/"},{"categories":["golang"],"content":"生成 .pb.go 文件 protoc --go_out=plugins=grpc:. calculator.proto 整体目录结构 \" ","date":"2022-03-05","objectID":"/grpc-demo/:3:0","tags":["golang"],"title":"grpc 入门应用","uri":"/grpc-demo/"},{"categories":["golang"],"content":"rpc server package main import ( \"context\" \"fmt\" \"net\" \"go.src/grpc/calculator/protobuf\" \"google.golang.org/grpc\" ) // 实现: CalculatorServiceServer接口, 在calculator.pb.go中定义 type server struct{} func (s server) Calc(ctx context.Context, req *protobuf.CalcRequest) (resp *protobuf.CalcResponse, err error) { a := req.GetA() b := req.GetB() op := req.GetOp() resp = \u0026protobuf.CalcResponse{} switch op { case \"+\": resp.R = a + b case \"-\": resp.R = a - b case \"*\": resp.R = a * b case \"/\": if b == 0 { err = fmt.Errorf(\"divided by zero\") return } resp.R = a / b } return } // 启动rpc server func main() { listener, err := net.Listen(\"tcp\", \"localhost:3233\") if err != nil { panic(err) } s := grpc.NewServer() protobuf.RegisterCalculatorServiceServer(s, \u0026server{}) fmt.Println(\"server start\") err = s.Serve(listener) if err != nil { panic(err) } } ","date":"2022-03-05","objectID":"/grpc-demo/:4:0","tags":["golang"],"title":"grpc 入门应用","uri":"/grpc-demo/"},{"categories":["golang"],"content":"rpc client package main import ( \"context\" \"fmt\" \"log\" \"go.src/grpc/calculator/protobuf\" \"google.golang.org/grpc\" \"google.golang.org/grpc/credentials/insecure\" ) func main() { // 连上grpc server //conn, err := grpc.Dial(\"localhost:3233\", grpc.WithInsecure()) conn, err := grpc.Dial(\"localhost:3233\", grpc.WithTransportCredentials(insecure.NewCredentials())) if err != nil { log.Fatalf(\"did not connect: %v\", err) } defer conn.Close() c := protobuf.NewCalculatorServiceClient(conn) // 调用远程方法 resp, err := c.Calc(context.Background(), \u0026protobuf.CalcRequest{ A: 1, B: 2, Op: \"+\", }) if err != nil { fmt.Println(\"calc err: \", err.Error()) return } fmt.Println(\"calc success,respR: \", resp.GetR()) // 3 } ","date":"2022-03-05","objectID":"/grpc-demo/:5:0","tags":["golang"],"title":"grpc 入门应用","uri":"/grpc-demo/"},{"categories":["golang"],"content":"运行测试 serverserver \" server clientclient \" client ","date":"2022-03-05","objectID":"/grpc-demo/:6:0","tags":["golang"],"title":"grpc 入门应用","uri":"/grpc-demo/"},{"categories":["golang"],"content":"示例下载 示例源码地址 ","date":"2022-03-05","objectID":"/grpc-demo/:7:0","tags":["golang"],"title":"grpc 入门应用","uri":"/grpc-demo/"},{"categories":["web"],"content":"Ajax 在请求时携带 cookie 信息,cookie 信息会被添加到请求头中,Cookie","date":"2022-03-01","objectID":"/ajax-req-add-cookie/","tags":["web"],"title":"ajax 在请求时携带 cookie 信息","uri":"/ajax-req-add-cookie/"},{"categories":["web"],"content":"最近有个需求在使用 $.ajax 时需要把 cookie 信息也带着，google 下发现可以这么写： $.ajax({ url: \"/nodered/nodes\", headers: { Accept: \"text/html\", }, xhrFields: { withCredentials: true // 携带 cookie 信息 }, success: function (data) { console.log(data) $(\"#red-ui-palette-container\").html(data) }, error: function (jqXHR) { console.log(jqXHR) } }); ","date":"2022-03-01","objectID":"/ajax-req-add-cookie/:0:0","tags":["web"],"title":"ajax 在请求时携带 cookie 信息","uri":"/ajax-req-add-cookie/"},{"categories":["开发者手册"],"content":"C语言定义字符串的方法,C语言，字符串","date":"2022-02-17","objectID":"/c-define-string/","tags":["c语言"],"title":"C语言定义字符串的方法","uri":"/c-define-string/"},{"categories":["开发者手册"],"content":" #include \u003cstdio.h\u003e int main(void) { char a[6] = {'F', 'i', 's', 'h', 'C', '\\0'}; // 需要主动加上 \\0 char a1[] = {'F', 'i', 's', 'h', 'C', '\\0'}; // 需要主动加上 \\0 char a2[] = {\"FishC\"}; char a3[] = \"FishC\"; printf(\"a: %s \\n\", a); printf(\"a1: %s \\n\", a1); printf(\"a2: %s \\n\", a2); printf(\"a3: %s \\n\", a3); return 0; } 运行结果： c语言定义字符串 \" ","date":"2022-02-17","objectID":"/c-define-string/:0:0","tags":["c语言"],"title":"C语言定义字符串的方法","uri":"/c-define-string/"},{"categories":["golang"],"content":"go,continue,break,goto label的区别,Golang","date":"2022-02-16","objectID":"/break-continue-goto-label/","tags":["golang"],"title":"golang break，continue，goto label 的区别","uri":"/break-continue-goto-label/"},{"categories":["golang"],"content":"在 php 中可以直接在 break 和 continue 后加 num ，比如 break 2或 continue 2。 break num 是结束外层第 num 层整个循环体，continue num 是结束外层第 num 层单次循环。 类比 php ，go 中不能直接在关键字后加 num ，但是可以用 label 关键字代替 num。 ","date":"2022-02-16","objectID":"/break-continue-goto-label/:0:0","tags":["golang"],"title":"golang break，continue，goto label 的区别","uri":"/break-continue-goto-label/"},{"categories":["golang"],"content":"continue label package main import ( \"fmt\" \"math\" ) func main() { // 找出 int 切片的最小值 var matrix = []int{10, 2, 4, 0} var min = math.MinInt64 next: for _, v := range matrix { for _, v1 := range matrix { if v \u003e v1 { continue next // 终止当前循环，跳到 label 继续下一次循环 } } min = v } fmt.Println(\"最小值为: \", min) } ","date":"2022-02-16","objectID":"/break-continue-goto-label/:1:0","tags":["golang"],"title":"golang break，continue，goto label 的区别","uri":"/break-continue-goto-label/"},{"categories":["golang"],"content":"break label package main import ( \"fmt\" \"math\" ) func main() { // 获取 index 2 的值，这里使用 2 层循环主要是为了说明问题 var matrix = []int{10, 2, 4, 0} var index2Val = math.MinInt64 next: for _, v := range matrix { fmt.Println(v) for index, v1 := range matrix { index2Val = v1 if index == 2 { break next // 跳出循环到 label 处 } } } fmt.Println(\"index 3 值为: \", index2Val) } ","date":"2022-02-16","objectID":"/break-continue-goto-label/:2:0","tags":["golang"],"title":"golang break，continue，goto label 的区别","uri":"/break-continue-goto-label/"},{"categories":["golang"],"content":"goto label 非必要不使用，可以跳到任何地方。 package main import ( \"fmt\" \"math\" ) func main() { var matrix = []int{10, 2, 4, 0} var index2Val = math.MinInt64 for _, v := range matrix { fmt.Println(v) for index, v1 := range matrix { index2Val = v1 if index == 2 { goto next } } } fmt.Println(\"index 3 值为: \", index2Val) next: fmt.Println(\"goto this....\") } ","date":"2022-02-16","objectID":"/break-continue-goto-label/:3:0","tags":["golang"],"title":"golang break，continue，goto label 的区别","uri":"/break-continue-goto-label/"},{"categories":["golang"],"content":"running gcc failed: exit status 1","date":"2022-02-10","objectID":"/build-running-gcc-failed/","tags":["golang","build"],"title":"running gcc failed: exit status 1","uri":"/build-running-gcc-failed/"},{"categories":["golang"],"content":"今天在编译 go 项目时出现了如下错误： /usr/local/go/pkg/tool/linux_amd64/link: running gcc failed: exit status 1 /usr/bin/ld: cannot find -lpthread /usr/bin/ld: cannot find -lc collect2: error: ld returned 1 exit status 解决办法： yum install glibc-static.x86_64 -y ","date":"2022-02-10","objectID":"/build-running-gcc-failed/:0:0","tags":["golang","build"],"title":"running gcc failed: exit status 1","uri":"/build-running-gcc-failed/"},{"categories":["算法与数学"],"content":"一致性Hash,hash算法,数据倾斜","date":"2022-01-15","objectID":"/consistent-hash/","tags":["算法"],"title":"一致性 hash","uri":"/consistent-hash/"},{"categories":["算法与数学"],"content":"存在的意义 一致性哈希算法解决了普通余数 Hash 算法伸缩性差的问题，可以保证在上线、下线服务器的情况下尽量有多的请求命中原来路由到的服务器。 ","date":"2022-01-15","objectID":"/consistent-hash/:1:0","tags":["算法"],"title":"一致性 hash","uri":"/consistent-hash/"},{"categories":["算法与数学"],"content":"优化 一致性哈希算法在服务节点太少时，容易因为节点分部不均匀而造成数据倾斜问题。可以通过通过增加虚拟节点来解决数据倾斜问题。 如果存在大量的虚拟节点，节点的查找性能就成为必须考虑的因数。可以使用红黑树 来加快查找速度， ","date":"2022-01-15","objectID":"/consistent-hash/:2:0","tags":["算法"],"title":"一致性 hash","uri":"/consistent-hash/"},{"categories":["算法与数学"],"content":"参考 一致性Hash(Consistent Hashing)原理剖析及Java实现 图解一致性哈希算法 golang实现一致性hash环及优化方法 一致性哈希 ","date":"2022-01-15","objectID":"/consistent-hash/:3:0","tags":["算法"],"title":"一致性 hash","uri":"/consistent-hash/"},{"categories":["收藏"],"content":"在线文档 build-web-application-with-golang Mastering_Go golang 修养之路 Go语言101 PHP扩展开发及内核应用 JavaScript 标准参考教程 ES6 入门教程 JavaScript 教程 网道 PHP编程之道 gairuo Kubernetes 文档 Uber Go 语言编码规范 地鼠文档 面向信仰编程 煎鱼 xargin go Standard library alblue 刘丹冰aceld ","date":"2021-10-17","objectID":"/memo/:1:0","tags":["备忘录"],"title":"书籍/工具收藏","uri":"/memo/"},{"categories":["收藏"],"content":"工具收藏 navicat premium15破解教程 ","date":"2021-10-17","objectID":"/memo/:2:0","tags":["备忘录"],"title":"书籍/工具收藏","uri":"/memo/"},{"categories":["收藏"],"content":"文章收藏 go1.16 embed 用法 ","date":"2021-10-17","objectID":"/memo/:3:0","tags":["备忘录"],"title":"书籍/工具收藏","uri":"/memo/"},{"categories":["golang"],"content":"go构造函数,go初始化函数,go函数式选项模式,golang函数式编程","date":"2021-08-23","objectID":"/functional-options-pattern/","tags":["golang"],"title":"go 函数式选项模式","uri":"/functional-options-pattern/"},{"categories":["golang"],"content":"Go 语言没有构造函数，一般通过定义 New 函数来充当构造函数。但是，如果结构有较多字段，要初始化这些字段，就有很多种方式，有一种方式被认为是最优雅的，就是函数式选项模式（Functional Options Pattern）。 函数式选项模式用于构造函数和其他公共 API 中的可选参数，你预计这些参数需要扩展，尤其是在这些函数上已经有三个或更多参数的情况下。 ","date":"2021-08-23","objectID":"/functional-options-pattern/:0:0","tags":["golang"],"title":"go 函数式选项模式","uri":"/functional-options-pattern/"},{"categories":["golang"],"content":"常规方式 我们有如下结构体： type Server struct { host string // 必填 port int // 必填 timeout time.Duration // 可选 maxConn int // 可选 } host 和 port 字段是必须的，timeout 和 maxConn 字段是可选的。 之前我的做法是这样处理的，定义一个 New 函数，初始化必填字段，对每个可选字段都定义了一个 SetXXX 函数，如下： package main import \"time\" type Server struct { host string // 必填 port int // 必填 timeout time.Duration // 可选 maxConn int // 可选 } func New(host string, port int) *Server { return \u0026Server{ host: host, port: port, timeout: 0, maxConn: 0, } } func (s *Server) SetTimeout(timeout time.Duration) { s.timeout = timeout } func (s *Server) SetMaxConn(maxConn int) { s.maxConn = maxConn } func main() { } 个人觉得这种方式其实已经很优雅了，一般情况下也是够用的。 ","date":"2021-08-23","objectID":"/functional-options-pattern/:1:0","tags":["golang"],"title":"go 函数式选项模式","uri":"/functional-options-pattern/"},{"categories":["golang"],"content":"Functional Option Pattern package main import ( \"log\" \"time\" ) type Server struct { host string // 必填 port int // 必填 timeout time.Duration // 可选 maxConn int // 可选 } type Option func(*Server) func New(options ...Option) *Server { svr := \u0026Server{} for _, f := range options { f(svr) } return svr } func WithHost(host string) Option { return func(s *Server) { s.host = host } } func WithPort(port int) Option { return func(s *Server) { s.port = port } } func WithTimeout(timeout time.Duration) Option { return func(s *Server) { s.timeout = timeout } } func WithMaxConn(maxConn int) Option { return func(s *Server) { s.maxConn = maxConn } } func (s *Server) Run() error { // ... return nil } func main() { svr := New( WithHost(\"localhost\"), WithPort(8080), WithTimeout(time.Minute), WithMaxConn(120), ) if err := svr.Run(); err != nil { log.Fatal(err) } } 在这个模式中，我们定义一个 Option 函数类型，它接收一个参数：*Server。然后，Server 的构造函数接收一个 Option 类型的不定参数。 func New(options ...Option) *Server { svr := \u0026Server{} for _, f := range options { f(svr) } return svr } 选项的定义需要定义一系列相关返回 Option 的函数，如： func WithPort(port int) Option { return func(s *Server) { s.port = port } } 如果增加选项，只需要增加对应的 WithXXX 函数即可。 ","date":"2021-08-23","objectID":"/functional-options-pattern/:2:0","tags":["golang"],"title":"go 函数式选项模式","uri":"/functional-options-pattern/"},{"categories":["golang"],"content":"参考 Golang Functional Options Pattern ","date":"2021-08-23","objectID":"/functional-options-pattern/:3:0","tags":["golang"],"title":"go 函数式选项模式","uri":"/functional-options-pattern/"},{"categories":["golang"],"content":"go make 和 new 的区别,golang make,golang new,defference with golang make and new","date":"2021-06-21","objectID":"/new-make-difference/","tags":["golang"],"title":"golang make 和 new 的区别","uri":"/new-make-difference/"},{"categories":["golang"],"content":" make 的作用是初始化内置的数据结构，也就是 slice、map和 channel。 new 的作用是根据传入的类型分配一片内存空间并返回指向这片内存空间的指针。 ","date":"2021-06-21","objectID":"/new-make-difference/:0:0","tags":["golang"],"title":"golang make 和 new 的区别","uri":"/new-make-difference/"},{"categories":["golang"],"content":"make 内置函数 make 仅支持 slice、map、channel 三种数据类型的内存创建，其返回值是所创建类型的本身，而不是新的指针引用。 func make(t Type, size ...IntegerType) Type func main() { v1 := make([]int, 1, 5) v2 := make(map[int]bool, 5) v3 := make(chan int, 1) fmt.Println(v1, v2, v3) } 在☝️代码中，我们分别对三种类型调用了 make 函数进行了初始化。会发现有的入参是有多个长度指定，有的没有。 这里的区别主要是长度（len）和容量（cap）的指定，有的类型是没有容量这一说法。 输出结果： [0] map[] 0xc000044070 调用 make函数去初始化切片（slice）的类型时，会带有零值。 ","date":"2021-06-21","objectID":"/new-make-difference/:1:0","tags":["golang"],"title":"golang make 和 new 的区别","uri":"/new-make-difference/"},{"categories":["golang"],"content":"new 内置函数 new 可以对任意类型进行内存创建和初始化。其返回值是所创建类型的指针引用。 func new(Type) *Type new(T) 和 \u0026T{} 效果是一样的。 ","date":"2021-06-21","objectID":"/new-make-difference/:2:0","tags":["golang"],"title":"golang make 和 new 的区别","uri":"/new-make-difference/"},{"categories":["golang"],"content":"区别 make 函数在初始化时，会初始化 slice、chan、map 类型的内部数据结构，new 函数并不会。 例如，在 map 类型中，合理的长度（len）和容量（cap）可以提高效率和减少开销。 make 函数： 能够分配并初始化类型所需的内存空间和结构，返回引用类型的本身。 具有使用范围的局限性，仅支持 channel、map、slice 三种类型。 具有独特的优势，make 函数会对三种类型的内部数据结构（长度、容量等）赋值。 new 函数： 能够分配类型所需的内存空间，返回指针引用（指向内存的指针），同时把分配的内存置为零，也就是类型的零值。 可被替代，其实不常用，我们通常都是采用短语句声明以及结构体的字面量达到我们的目的，比如： i := 0 u := user{} ","date":"2021-06-21","objectID":"/new-make-difference/:3:0","tags":["golang"],"title":"golang make 和 new 的区别","uri":"/new-make-difference/"},{"categories":["golang"],"content":"参考 make、new操作 Go make 和 new的区别 ","date":"2021-06-21","objectID":"/new-make-difference/:4:0","tags":["golang"],"title":"golang make 和 new 的区别","uri":"/new-make-difference/"},{"categories":["开发者手册"],"content":"入职新公司，就在 git 的使用上被各种虐。整理一篇文档，对这个问题梳理总结下。 之前用 git 都是直接新建分支，然后 PR review 后合到主分支，现在是先 fork 下，之前没用过 fork 😢 ，其实就是多了一步，从自己仓库的分支提 PR 。 ","date":"2021-04-29","objectID":"/pull-request/:0:0","tags":["git"],"title":"github PR 简单使用","uri":"/pull-request/"},{"categories":["开发者手册"],"content":"clone 代码 forkfork \" fork fork 代码后 clone 到本地。 git clone git@github.com:xxxxx/dev-git.git cloneclone \" clone 我们可以用 git remote -v 看下远程仓库情况： git remote -vgit remote -v \" git remote -v ","date":"2021-04-29","objectID":"/pull-request/:1:0","tags":["git"],"title":"github PR 简单使用","uri":"/pull-request/"},{"categories":["开发者手册"],"content":"添加远程仓库 用 git remote add 添加远程仓库，这里的远程就是我 fork 的那个仓库。 git remote add upstream git@github.xxxxx/dev-git.git 这里的 upstream 是远程仓库的别名，类似 origin 。 git remoteadd upstream \" git remote 现在我们可以看到已经有 2 个远程仓库地址了，origin 是我自己的远程仓库，upstream 是别人的，也就是真实项目的远程仓库。 ","date":"2021-04-29","objectID":"/pull-request/:2:0","tags":["git"],"title":"github PR 简单使用","uri":"/pull-request/"},{"categories":["开发者手册"],"content":"PR 我们现在可以 upstream 远程仓库中提交一个 PR。先 fetch 一下 upstream 远程仓库的代码。确保我们的代码是最新的。 fetch \" 接下来就可以在 ide 上操作了。 ide operate \" 我们可以看到远程分支了 upstream/main 和 origin/main ，upstream 是真正的项目地址，origin 是 fork 到我们仓库的分支。 checkout 下 upstream/main ： ide operate \" \" 再拉下最新的代码 ide operate \" 再切回到我们的 origin/main 分支 从我们的分支 checkout 一个新的开发分支 dev origin main \" dev branch \" rebase 下远程分支的代码 \" 我们简单修改一行，提下代码 add \" push push1 \" push2 \" push 完成后我们的仓库会出现提示 \" 现在我们就可以提一个 PR 了。 \" 成功提了一个 PR \" ","date":"2021-04-29","objectID":"/pull-request/:3:0","tags":["git"],"title":"github PR 简单使用","uri":"/pull-request/"},{"categories":["开发者手册"],"content":"更新代码 \" PR 合并之后我们需要更新下代码： checkout 到 upstream-main 分支，拉下代码 \" 再切到 origin/dev 分支 rebase 下 upstream-main \" \" 以上，一个闭环结束。 ","date":"2021-04-29","objectID":"/pull-request/:4:0","tags":["git"],"title":"github PR 简单使用","uri":"/pull-request/"},{"categories":["golang"],"content":"golang upd 简单使用,UDP,HTTP","date":"2021-04-01","objectID":"/upd-demo/","tags":["golang"],"title":"golang udp 简单使用","uri":"/upd-demo/"},{"categories":["golang"],"content":"server package main import ( \"fmt\" \"net\" \"time\" ) func main() { // 创建监听 socket, err := net.ListenUDP(\"udp4\", \u0026net.UDPAddr{ IP: []byte{127, 0, 0, 1}, Port: 8080, }) if err != nil { fmt.Println(\"监听失败!\", err) return } defer socket.Close() for { // 读取数据 data := make([]byte, 4096) read, remoteAddr, err := socket.ReadFromUDP(data) if err != nil { fmt.Println(\"读取数据失败!\", err) continue } fmt.Println(read, remoteAddr) fmt.Printf(\"接收到客户端数据，%s\\n\\n\", data) // 发送数据 senddata := []byte(\"server send data，hello client!\" + time.Now().Format(\"2006-01-02 15:04:05\")) _, err = socket.WriteToUDP(senddata, remoteAddr) if err != nil { fmt.Println(\"发送数据失败!\", err.Error()) return } } } ","date":"2021-04-01","objectID":"/upd-demo/:1:0","tags":["golang"],"title":"golang udp 简单使用","uri":"/upd-demo/"},{"categories":["golang"],"content":"client package main import ( \"fmt\" \"net\" \"time\" ) func main() { // 创建连接 socket, err := net.DialUDP(\"udp4\", nil, \u0026net.UDPAddr{ IP: []byte{127, 0, 0, 1}, Port: 8080, }) if err != nil { fmt.Println(\"连接失败!\", err) return } defer socket.Close() // 发送数据 senddata := []byte(\"client send message，hello server!\" + time.Now().Format(\"2006-01-02 15:04:05\")) _, err = socket.Write(senddata) if err != nil { fmt.Println(\"发送数据失败!\", err) return } // 接收数据 data := make([]byte, 4096) read, remoteAddr, err := socket.ReadFromUDP(data) if err != nil { fmt.Println(\"读取数据失败!\", err) return } fmt.Println(read, remoteAddr) fmt.Printf(\"接收到服务器端数据，%s\\n\", data) } ","date":"2021-04-01","objectID":"/upd-demo/:2:0","tags":["golang"],"title":"golang udp 简单使用","uri":"/upd-demo/"},{"categories":["golang"],"content":"源码 源码地址 ","date":"2021-04-01","objectID":"/upd-demo/:3:0","tags":["golang"],"title":"golang udp 简单使用","uri":"/upd-demo/"},{"categories":["golang"],"content":"Linux 环境下安装 Go,Linux Platform Install Go,如何在 Linux 环境下安装 Go,go,golang","date":"2020-08-12","objectID":"/linux-platform-install-go/","tags":["golang"],"title":"Linux 环境下安装 Go","uri":"/linux-platform-install-go/"},{"categories":["golang"],"content":"安装 在官网 https://go.dev/dl/，根据自己的环境下载对应的安装包： 官网安装包列表官网安装包列表 \" 官网安装包列表 可以直接用 wget 下载 下载安装包下载安装包 \" 下载安装包 执行 tar 解压到 /usr/loacl目录下（官方推荐），得到 go 文件夹等。 tar -C /usr/local -zxvf go1.17.7.linux-amd64.tar.gz go1.17.7.linux-amd64.tar.gz 换成你自己的 go 版本。 添加 /usr/loacl/go/bin 目录到 PATH 变量中。添加到 /etc/profile 或 $HOME/.profile 都可以。 vim /etc/profile # 在最后一行添加 export GOROOT=/usr/local/go export PATH=$PATH:$GOROOT/bin 添加环境变量添加环境变量 \" 添加环境变量 保存退出后source一下 source /etc/profile go envgo env \" go env ","date":"2020-08-12","objectID":"/linux-platform-install-go/:1:0","tags":["golang"],"title":"Linux 环境下安装 Go","uri":"/linux-platform-install-go/"},{"categories":["golang"],"content":"Go环境变量 $GOROOT 表示 Go 在你的电脑上的安装位置，值一般都是 $HOME/go，当然，也可以安装在别的地方。 $GOARCH 表示目标机器的处理器架构，它的值可以是 386、amd64 或 arm。 $GOOS 表示目标机器的操作系统，它的值可以是 darwin、freebsd、linux 或 windows。 $GOBIN 表示编译器和链接器的安装位置，默认是 $GOROOT/bin，如果使用的是 Go 1.0.3 及以后的版本，一般情况下你可以将它的值设置为空，Go 将会使用默认值。 $GOPATH 默认采用和 $GOROOT 一样的值，但从 Go 1.1 版本开始，你必须修改为其它路径。它可以包含多个包含 Go 语言源码文件、包文件和可执行文件的路径，而这些路径下又必须分别包含三个规定的目录：src、pkg 和 bin，这三个目录分别用于存放源码文件、包文件和可执行文件。 $GOARM 专门针对基于 arm 架构的处理器，它的值可以是 5~7，默认为 6。 $GOMAXPROCS 用于设置应用程序可使用的处理器个数与核数。 ","date":"2020-08-12","objectID":"/linux-platform-install-go/:2:0","tags":["golang"],"title":"Linux 环境下安装 Go","uri":"/linux-platform-install-go/"},{"categories":["算法与数学"],"content":"常见缓存淘汰策略，淘汰策略的实现，FIFO，LRU，LFU","date":"2020-03-05","objectID":"/common-cache-strategies/","tags":["算法"],"title":"常见缓存淘汰策略","uri":"/common-cache-strategies/"},{"categories":["算法与数学"],"content":"常见缓存淘汰策略 ","date":"2020-03-05","objectID":"/common-cache-strategies/:0:0","tags":["算法"],"title":"常见缓存淘汰策略","uri":"/common-cache-strategies/"},{"categories":["算法与数学"],"content":"FIFO First In First Out(FIFO)，先进先出，也就是淘汰缓存中最老(最早添加)的记录。FIFO 认为，最早添加的记录，其不再被使用的可能性比刚添加的可能性大。这种算法的实现也非常简单，创建一个队列，新增记录添加到队尾， 每次内存不够时，淘汰队首。但是很多场景下，部分记录虽然是最早添加但也最常被访问，而不得不因为呆的时间太长而被淘汰。这类数据会被频繁地添加进缓存，又被淘汰出去，导致缓存命中率降低。 ","date":"2020-03-05","objectID":"/common-cache-strategies/:1:0","tags":["算法"],"title":"常见缓存淘汰策略","uri":"/common-cache-strategies/"},{"categories":["算法与数学"],"content":"LFU Least Frequently Used(LFU)，最少使用，也就是淘汰缓存中访问频率最低的记录。LFU 认为，如果数据过去被访问多次， 那么将来被访问的频率也更高。LFU 的实现需要维护一个按照访问次数排序的队列，每次访问，访问次数加1，队列重新排序， 淘汰时选择访问次数最少的即可。LFU 算法的命中率是比较高的，但缺点也非常明显，维护每个记录的访问次数，对内存的消耗是很高的； 另外，如果数据的访问模式发生变化，LFU 需要较长的时间去适应，也就是说 LFU 算法受历史数据的影响比较大。例如某个数据历史上访问次数奇高，但在某个时间点之后几乎不再被访问，但因为历史访问次数过高，而迟迟不能被淘汰。 ","date":"2020-03-05","objectID":"/common-cache-strategies/:2:0","tags":["算法"],"title":"常见缓存淘汰策略","uri":"/common-cache-strategies/"},{"categories":["算法与数学"],"content":"LRU Least Recently Used(LRU)，最近最少使用，相对于仅考虑时间因素的 FIFO 和仅考虑访问频率的 LFU，LRU 算法可以认为是相对平衡的 一种淘汰算法。LRU 认为，如果数据最近被访问过，那么将来被访问的概率也会更高。LRU 算法的实现非常简单，维护一个队列，如果某条记录被访问了， 则移动到队尾，那么队首则是最近最少访问的数据，淘汰该条记录即可。 ","date":"2020-03-05","objectID":"/common-cache-strategies/:3:0","tags":["算法"],"title":"常见缓存淘汰策略","uri":"/common-cache-strategies/"},{"categories":["开发者手册"],"content":"阿里云,SSL,免费证书使用,aliyun,ali,证书,TLS","date":"2019-06-07","objectID":"/ali-ssl/","tags":["ssl","aliyun"],"title":"阿里云 SSL 免费证书使用","uri":"/ali-ssl/"},{"categories":["开发者手册"],"content":"申请 证书申请地址 在这里插入图片描述 \" 申请完成页面 在这里插入图片描述 \" 将主机记录解析 在这里插入图片描述 \" 在这里插入图片描述 \" 在这里插入图片描述 \" 将主机记录和记录值填写 在这里插入图片描述 \" 解析成功后下载证书 在这里插入图片描述 \" 我用的是 Apache ,所以下载的是 Apache 在这里插入图片描述 \" ","date":"2019-06-07","objectID":"/ali-ssl/:1:0","tags":["ssl","aliyun"],"title":"阿里云 SSL 免费证书使用","uri":"/ali-ssl/"},{"categories":["开发者手册"],"content":"上传证书 由于本人使用的是 apache ,以下配置是 apache 的通用配置,具体可参看官方 文档 在 apache 的路径下新建一个 cert 目录,其实该目录建在哪里都可以,但是放在 apache 下方便管理。 \" 在 cert 目录下可以建不同的文件夹放在不同域名或子域名的 ssl 文件。 \" 把我们刚才下载的证书上传到服务器上 \" ","date":"2019-06-07","objectID":"/ali-ssl/:2:0","tags":["ssl","aliyun"],"title":"阿里云 SSL 免费证书使用","uri":"/ali-ssl/"},{"categories":["开发者手册"],"content":"配置 这是基本的配置语句 # 添加 SSL 协议支持协议，去掉不安全的协议 SSLProtocol all -SSLv2 -SSLv3 # 修改加密套件如下 SSLCipherSuite HIGH:!RC4:!MD5:!aNULL:!eNULL:!NULL:!DH:!EDH:!EXP:+MEDIUM SSLHonorCipherOrder on # 证书公钥配置 SSLCertificateFile cert/a_public.crt # 证书私钥配置 SSLCertificateKeyFile cert/a.key # 证书链配置，如果该属性开头有 '#'字符，请删除掉 SSLCertificateChainFile cert/a_chain.crt 我们将默认的配置 copy 一份出来,取一个跟域名有关的文件名 cp /etc/apache2/sites-available/000-default.conf /etc/apache2/sites-available/www.xiaobinqt.cn.conf 具体配置可参考 \u003cVirtualHost *:80\u003e ServerName www.xiaobinqt.cn Redirect permanent / https://www.xiaobinqt.cn/ \u003c/VirtualHost\u003e \u003cVirtualHost *:443\u003e SSLEngine On # 添加 SSL 协议支持协议，去掉不安全的协议 SSLProtocol all -SSLv2 -SSLv3 # 修改加密套件如下 SSLCipherSuite HIGH:!RC4:!MD5:!aNULL:!eNULL:!NULL:!DH:!EDH:!EXP:+MEDIUM SSLHonorCipherOrder on # 证书公钥配置 SSLCertificateFile cert/xiaobinqt.cn/2324042_www.xiaobinqt.cn_public.crt # 证书私钥配置 SSLCertificateKeyFile cert/xiaobinqt.cn/2324042_www.xiaobinqt.cn.key # 证书链配置，如果该属性开头有 '#'字符，请删除掉 SSLCertificateChainFile cert/xiaobinqt.cn/2324042_www.xiaobinqt.cn_chain.crt # etc ServerName www.xiaobinqt.cn ProxyPreserveHost On ProxyRequests Off ProxyPass / http://localhost:30007/ ProxyPassReverse / http://localhost:30007/ \u003c/VirtualHost\u003e 我用的是 docker 服务,如果你的只是项目文件夹可以参考这样配置 \u003cVirtualHost *:80\u003e # The ServerName directive sets the request scheme, hostname and port that # the server uses to identify itself. This is used when creating # redirection URLs. In the context of virtual hosts, the ServerName # specifies what hostname must appear in the request's Host: header to # match this virtual host. For the default virtual host (this file) this # value is not decisive as it is used as a last resort host regardless. # However, you must set it for any further virtual host explicitly. #ServerName www.example.com #ServerAdmin webmaster@localhost ServerName www.xiaobinqt.cn DocumentRoot /var/www/html Redirect permanent / https://www.xiaobinqt.cn/ # Available loglevels: trace8, ..., trace1, debug, info, notice, warn, # error, crit, alert, emerg. # It is also possible to configure the loglevel for particular # modules, e.g. #LogLevel info ssl:warn ErrorLog ${APACHE_LOG_DIR}/error.log CustomLog ${APACHE_LOG_DIR}/access.log combined # For most configuration files from conf-available/, which are # enabled or disabled at a global level, it is possible to # include a line for only one particular virtual host. For example the # following line enables the CGI configuration for this host only # after it has been globally disabled with \"a2disconf\". #Include conf-available/serve-cgi-bin.conf \u003c/VirtualHost\u003e \u003cVirtualHost *:443\u003e SSLEngine On # 添加 SSL 协议支持协议，去掉不安全的协议 SSLProtocol all -SSLv2 -SSLv3 # 修改加密套件如下 SSLCipherSuite HIGH:!RC4:!MD5:!aNULL:!eNULL:!NULL:!DH:!EDH:!EXP:+MEDIUM SSLHonorCipherOrder on # 证书公钥配置 SSLCertificateFile cert/xiaobinqt.cn/public.pem # 证书私钥配置 SSLCertificateKeyFile cert/xiaobinqt.cn/214792197160511.key # 证书链配置，如果该属性开头有 '#'字符，请删除掉 SSLCertificateChainFile cert/xiaobinqt.cn/chain.pem # etc ServerName www.xiaobinqt.cn \u003c/VirtualHost\u003e 以上配置全部基于 apache ,如果你用的不是 apache ,以上配置可能不适合你. 关于 apache 服务的一些其他知识可以参考这篇文章,该文章可能需要翻~墙访问. 配置完成后重启服务,可以利用 curl 命令查看是否配置成功. curl -I localhost:xxx \" 对于 ssl 是否配置成功可以通过浏览器查看. \" 可以看到这是我们最新申请的一年的 ssl 证书. \" ","date":"2019-06-07","objectID":"/ali-ssl/:3:0","tags":["ssl","aliyun"],"title":"阿里云 SSL 免费证书使用","uri":"/ali-ssl/"},{"categories":["开发者手册"],"content":"Windows,系统,重做系统,win,win10,U盘安装系统","date":"2018-10-07","objectID":"/redo-system/","tags":["windows"],"title":"windows 重做系统","uri":"/redo-system/"},{"categories":["开发者手册"],"content":"下载系统 首先我们需要一个最小 4G 大的 U 盘 image \" 进入大白菜网站下载大白菜装机版安装到电脑 image \" image \" 将 U 盘插到电脑上,双击打开大白菜装机版,它会自动读到我们插入的 U 盘，自动匹配默认模式,不需要手动选择。 image \" 点击开始制作 –\u003e 确认 image \" 等待写入数据包完成和格式化完成后关掉大白菜软件 image \" image \" image \" 制作完 U 盘启动盘后我们的 U 盘会变成这样说明启动盘已经制作成功 ! image去itellyou下载需要安装的操作系统 ! image \" 比如我们要安装这个版本的 win10 image \" 通过百度网盘下载 ed2k 文件资源,然后再通过百度网盘下载到电脑本地,可以放在除 C 盘外的其他盘中 image \" 下载到本地的文件是这样的光盘映像文件 ! image \" 将我们下载到电脑本地的光盘映像文件复制到刚制作完成的 U 盘启动盘中,复制完成后我们 U 盘启动盘就全部制作完成了 image \" ","date":"2018-10-07","objectID":"/redo-system/:1:0","tags":["windows"],"title":"windows 重做系统","uri":"/redo-system/"},{"categories":["开发者手册"],"content":"重做系统 将我们制作好的 U 盘启动盘插到需要重做系统的电脑上,重启电脑一直按 F12 进入 bios 界面(不同的电脑可能按键不同,可以百度) image \" 选择 usb 方式,回车进入大白菜启动方式,选择 02 方式进入 image \" 进入 u 盘驱动界面,系统默认会选择 C 盘为系统盘,直接点击确定 image \" 确定后进入格式化 C 盘阶段,所有配置为默认配置,直接确定,等待格式化完成! image \" 格式化完成后选择 是 重启电脑,拔出 u 盘 等待电脑重启 ","date":"2018-10-07","objectID":"/redo-system/:2:0","tags":["windows"],"title":"windows 重做系统","uri":"/redo-system/"},{"categories":["开发者手册"],"content":"安装系统完成 image \" image \" ","date":"2018-10-07","objectID":"/redo-system/:3:0","tags":["windows"],"title":"windows 重做系统","uri":"/redo-system/"}]