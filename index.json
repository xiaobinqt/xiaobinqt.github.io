[{"categories":["essays"],"content":"几年前，一位好朋友去世了，九零后，跟我年纪一样。我跟他从小就认识，我们一起上的小学，一起上的初中，高中之后便联系的少了，后来我去外地读书，联系的就更少了。 那还是二零一九，那时我刚从西安来北京。一天夜里，都很晚了，我妈打电话跟我说，他去世了，好像是心梗，让我在外面多注意身体。天啊，当我听到这个消息的时候，我简直不敢相信，我反复确认了几次，无疑的确是他。 那晚我很难过，因为我不久之前还见过他。二零一九的春节，那天应该是初二的早晨，我骑着电瓶车去外公家拜年，外公家跟他老家离的不远，就几步路，那天早晨我在路边看到了他，我没有停下来，心想就几步路，我回来的时候再去找他，但是等我再往回走的时候他就不在家了。如今听到噩耗，再想起这件事，我真的特别后悔当时应该停下来见他一面。后来，我把这件事说给我女朋友听，她也特别感慨的说，想做什么事一定要赶紧去做。是啊，一定要赶紧去做，毕竟世事无常。 我跟他太久没有联系了，没有他的电话，也没有他的微信，后来在QQ 里找到他的联系方式。我尝试着发了一条消息过去，QQ 的那边，他媳妇回了一条消息，说他人已经不在了。后来有个初中同学联系到了我，是他班上的，建了一个微信群，想尽点绵薄之力，我们一人凑了点钱，由一个在老家的同学给他家里送了去，但他妈妈只是领了我们的心意。他实在是太年轻了，而且新婚不久，孩子才一岁。 这张照片是上初中时我们一起去皖南事变烈士陵园拍的，也是我跟他唯一的一张合影。 2020 年时家里发大水，家里的东西都泡水了，这张照片后来也不知所踪。 左三是他\" 左三是他 有一次我回家，我爸还跟我说在一次婚宴上见过他。他过世后，一次在我大舅家吃饭的时候，他家的一个亲戚也在，在聊起他的时候，直夸他在外面干活能吃苦，人不错。 我跟他从小相识，一起在村小学读书，一起在田埂上疯跑，他教我掏鸟窝，网知了，在我眼里，他好像什么都会，他教了我很多技能，带给我很多快乐。上初中的时候，我跟他一起骑车上学，放学也一起回家。他每天早上都是骑着车来我外婆家等我，等我吃完早饭一起走，一路上我们有好几个同学都一起。下午放学他有时也在我外婆家跟我一起做完作业才回家，这些事如今历历在目，但是他却永远不在了。 也许是年纪大了，不知不觉对有些事越来越伤感。几次提笔想写点什么，但是每次都写不出来，心里总记挂这件事，可能是那次我没有停下来见他吧。 2021年10月15日完 ","date":"2022-03-16","objectID":"/old_pal/:0:0","tags":["随笔"],"title":"纪念一位老友","uri":"/old_pal/"},{"categories":["leetcode"],"content":"LeetCode 热题 HOT 100,Leetcode,两数之和","date":"2022-03-25","objectID":"/hot100/","tags":["leetcode"],"title":"LeetCode 热题 HOT 100","uri":"/hot100/"},{"categories":["leetcode"],"content":"1. 两数之和 题目地址：https://leetcode-cn.com/problems/two-sum/ ","date":"2022-03-25","objectID":"/hot100/:1:0","tags":["leetcode"],"title":"LeetCode 热题 HOT 100","uri":"/hot100/"},{"categories":["leetcode"],"content":"解题思路 嵌套遍历数组，外层遍历的值和内层遍历的值相加，如果相加等于目标值，则返回结果，否则继续遍历。内层遍历开始的位置是外层遍历的位置加 1，结束的位置是数组长度。 ","date":"2022-03-25","objectID":"/hot100/:1:1","tags":["leetcode"],"title":"LeetCode 热题 HOT 100","uri":"/hot100/"},{"categories":["leetcode"],"content":"go 实现 package main import \"fmt\" func twoSum(nums []int, target int) []int { for index, value := range nums { for i := index + 1; i \u003c len(nums); i++ { if (value + nums[i]) == target { return []int{index, i} } } } return nil } func main() { fmt.Println(twoSum([]int{3, 2, 4}, 6)) } ","date":"2022-03-25","objectID":"/hot100/:1:2","tags":["leetcode"],"title":"LeetCode 热题 HOT 100","uri":"/hot100/"},{"categories":["leetcode"],"content":"20. 有效的括号 题目地址：https://leetcode-cn.com/problems/valid-parentheses/ ","date":"2022-03-25","objectID":"/hot100/:2:0","tags":["leetcode"],"title":"LeetCode 热题 HOT 100","uri":"/hot100/"},{"categories":["leetcode"],"content":"解题思路 判断括号的有效性可以使用「栈」这一数据结构来解决。 我们遍历给定的字符串 s。当我们遇到一个左括号时，我们会期望在后续的遍历中，有一个相同类型的右括号将其闭合。由于后遇到的左括号要先闭合，因此我们可以将这个左括号放入栈顶。 当我们遇到一个右括号时，我们需要将一个相同类型的左括号闭合。此时，我们可以取出栈顶的左括号并判断它们是否是相同类型的括号。如果不是相同的类型，或者栈中并没有左括号，那么字符串 s 无效，返回 False。为了快速判断括号的类型，我们可以使用哈希表存储每一种括号。哈希表的键为右括号，值为相同类型的左括号。 在遍历结束后，如果栈中没有左括号，说明我们将字符串 s 中的所有左括号闭合，返回 True，否则返回 False。 注意到有效字符串的长度一定为偶数，因此如果字符串的长度为奇数，我们可以直接返回 False，省去后续的遍历判断过程。 ","date":"2022-03-25","objectID":"/hot100/:2:1","tags":["leetcode"],"title":"LeetCode 热题 HOT 100","uri":"/hot100/"},{"categories":["leetcode"],"content":"go 实现 package main import \"fmt\" func isValid(s string) bool { n := len(s) if n%2 != 0 { // 奇数直接退出 return false } pairs := map[byte]byte{ ')': '(', ']': '[', '}': '{', } stack := []byte{} for i := 0; i \u003c n; i++ { if pairs[s[i]] \u003e 0 { // 如果是右括号,判断栈顶是否是对应的左括号,果然有对应的左括号,则弹出栈顶元素,否则直接退出 if len(stack) == 0 || stack[len(stack)-1] != pairs[s[i]] { return false } stack = stack[:len(stack)-1] } else { stack = append(stack, s[i]) } } return len(stack) == 0 } func main() { fmt.Println(isValid(\"()[]{}\")) } 版权信息 作者：LeetCode-Solution 链接：https://leetcode-cn.com/problem-list/2cktkvj 来源：力扣（LeetCode） ","date":"2022-03-25","objectID":"/hot100/:2:2","tags":["leetcode"],"title":"LeetCode 热题 HOT 100","uri":"/hot100/"},{"categories":["hugo"],"content":"Gitalk 初始化 issue,Gitalk,自动化,init issue,python 脚本自动初始 gitalk issue,hugo 主题,hugo theme","date":"2022-04-01","objectID":"/gitalk-init-issue/","tags":["gitalk","python","hugo"],"title":"Gitalk 初始化 issue","uri":"/gitalk-init-issue/"},{"categories":["hugo"],"content":"在用 Gitalk 作为个人博客评论系统时，发现有个恶心的点是，每篇文章必须手动初始化一个 issue 或是登录 github 后，把文章一个一个点开界面去初始化 issue，不然就会出现以下的提示 no issusno issus \" no issus 个人觉得这件事情非常麻烦，看了下 Gitalk 在初始化评论时发出的网络请求后，写了一个用于自动化初始评论的 python 脚本。 创建 issue 的请求创建 issue 的请求 \" 创建 issue 的请求 ","date":"2022-04-01","objectID":"/gitalk-init-issue/:0:0","tags":["gitalk","python","hugo"],"title":"Gitalk 初始化 issue","uri":"/gitalk-init-issue/"},{"categories":["hugo"],"content":"分析 我们要做的事其实就是给每篇新文章初始化一个 issue，可以用 github Actions 来做这件事。 初始化 issue 大致逻辑初始化 issue 大致逻辑 \" 初始化 issue 大致逻辑 这里有几个稍微麻烦的地方，以下是我的实现方案，仅仅是提供一个思路。 ","date":"2022-04-01","objectID":"/gitalk-init-issue/:1:0","tags":["gitalk","python","hugo"],"title":"Gitalk 初始化 issue","uri":"/gitalk-init-issue/"},{"categories":["hugo"],"content":"获取所有文章信息 怎么获取所有的文章❓，我用的 LoveIt 主题在 build 时在 public 目录里会有一个 index.json 文件，里面包含了所有的文章的信息。 public index.jsonpublic index.json \" public index.json 其他的主题可以使用 sitemap.xml 来获取所有的文章信息，hugo 在 build 时会生成 sitemap.xml 文件。 sitemap.xmlsitemap.xml \" sitemap.xml ","date":"2022-04-01","objectID":"/gitalk-init-issue/:1:1","tags":["gitalk","python","hugo"],"title":"Gitalk 初始化 issue","uri":"/gitalk-init-issue/"},{"categories":["hugo"],"content":"issue 如何初始化 我分析了下我使用的 LoveIt 主题默认创建的 issue 内容，如上截图👆。body 是文章的 URL，title 是文章标题，labels 有 Gitalk 和文章的发布时间两个。那么问题就简单了，我们只需要给每篇文章初始化一个这样的 issue 就可以了。 固定文章的 URL 为唯一标识，组成两个 map ，map 键就是文章的 URL。一个 map 是 github 已存在的 issue 暂定为 issue_map，一个 map 是我们所有文章的 map 暂定为 posts_map ，URL 在 posts_map 中存在但是 issue_map 不存在的就是新增 。URL 在 posts_map 和 issue_map 中都存在但是 posts_map 中的标题跟 issue_map 中的标题不相同可能就是文章标题被修改了。 对于新的 URL 我的做法是承认它是新文章，或是旧文章的 URL 被修改了那只能去 github 手动修改 issue body 为新的 URL。 ","date":"2022-04-01","objectID":"/gitalk-init-issue/:1:2","tags":["gitalk","python","hugo"],"title":"Gitalk 初始化 issue","uri":"/gitalk-init-issue/"},{"categories":["hugo"],"content":"python 脚本实现 import json import sys import time import requests site_url = \"https://xiaobinqt.github.io\" if len(sys.argv) != 4: print(\"Usage:\") print(sys.argv[0], \"token username repo_name\") sys.exit(1) # issue 的 body 就是文章的 URL token = sys.argv[1] username = sys.argv[2] repo_name = sys.argv[3] issue_map = dict() ## [issue_body] = {\"issue_number\": issue_number, \"issue_title\": issue_title} posts_map = dict() # [post_url] = {\"post_uri\":uri,\"post_date\":date,\"post_title\":title} def get_all_gitalk_issues(token, username, repo_name): for i in range(1, 150): # 15000 个 issue 基本够用了,不够可以再加 _, ret = get_issues_page(i) time.sleep(5) if ret == -1: break ## 删除的文章不管.... ## 文章 title 修改了的文章该怎么处理？ 标题可能修改,但是 uri 不变,issue 的 body 是文章地址,只要文章地址不变，就可以直接 update issue title ## uri 如果也变了，相当于是文件的重命名了，这时只能去手动 update issue title 了?..... def update_issue(issue_number, title): if title == \"\": return url = 'https://api.github.com/repos/%s/%s/issues/%d' % (username, repo_name, issue_number) print(\"update_issue url: %s\" % url) data = { 'title': title, } print(\"create_issue req json: %s\" % json.dumps(data)) r = requests.patch(url, data=json.dumps(data), headers={ \"Authorization\": \"token %s\" % token, }, verify=False) if r.status_code == 200: print(\"update_issue success\") else: print(\"update_issue fail, status_code: %d,title: %s,issue_number: %d\" % (r.status_code, title, issue_number)) # 获取所有 label 为 gitalk 的 issue def get_issues_page(page=1): url = 'https://api.github.com/repos/%s/%s/issues?labels=Gitalk\u0026per_page=100\u0026page=%d' % (username, repo_name, page) print(\"get_issues url: %s\" % url) r = requests.get(url, headers={ \"Authorization\": \"token %s\" % token, \"Accept\": \"application/vnd.github.v3+json\" }) if r.status_code != 200: print(\"get_issues_page fail, status_code: %d\" % r.status_code) sys.exit(2) if r.json() == []: return (issue_map, -1) for issue in r.json(): if issue['body'] not in issue_map and issue[\"body\"] != \"\": issue_map[issue['body']] = { \"issue_number\": issue['number'], \"issue_title\": issue['title'] } return (issue_map, 0) # 通过 public/index.json 获取所有的文章 def get_post_titles(): with open(file='public/index.json', mode='r', encoding='utf-8') as f: file_data = f.read() if file_data == \"\" or file_data == [] or file_data == {}: return posts_map file_data = json.loads(file_data) for data in file_data: key = \"%s%s\" % (site_url, data['uri']) if key not in posts_map: posts_map[key] = { \"post_uri\": data['uri'], \"post_date\": data['date'], \"post_title\": data['title'] } return posts_map def create_issue(title=\"\", uri=\"\", date=\"\"): if title == \"\": return url = 'https://api.github.com/repos/%s/%s/issues' % (username, repo_name) print(\"create_issue title: %suri: %sdate: %s\" % (title, uri, date)) data = { 'title': title, 'body': '%s%s' % (site_url, uri), 'labels': [ 'Gitalk', \"%sT00:00:00Z\" % date ] } print(\"create_issue req json: %s\" % json.dumps(data)) r = requests.post(url, data=json.dumps(data), headers={ \"Authorization\": \"token %s\" % token, }) if r.status_code == 201: print(\"create_issue success\") else: print(\"create_issue fail, status_code: %d,title: %s,req url: %s\\n\" % (r.status_code, title, url)) # 创建 gitalk 创建 issue,如果 issue 已经存在，则不创建 def init_gitalk(): for post_url, item in posts_map.items(): ## 标题被修改了 if post_url in issue_map and item['post_title'] != issue_map[post_url]['issue_title']: update_issue(issue_map[post_url][\"issue_number\"], item['post_title']) elif post_url not in issue_map: # 新增的文章 print(\"title: [%s] , body [%s] issue 不存在,创建...\" % (item[\"post_title\"], post_url)) create_issue(item[\"post_title\"], item[\"post_uri\"], item[\"post_date\"]) # 延迟 5 秒，防止 github api 请求过于频繁： https://docs.github.com/en/rest/guides/best-practices-for-integrators#dealing-with-secondary-rate-limits time.sleep(5) if __name__ == \"__main__\": # create_issue(\"禁止Google浏览器强制跳转https\", \"/stop_chrome_auto_redirect_2_https/\", \"2022-03-29\") # get_all_gitalk_issues(token, username, repo_name) # print(issue_titles_map) ## 执行.... get_all_gitalk_issues(token, username, repo_name) get_post_titles()","date":"2022-04-01","objectID":"/gitalk-init-issue/:2:0","tags":["gitalk","python","hugo"],"title":"Gitalk 初始化 issue","uri":"/gitalk-init-issue/"},{"categories":["hugo"],"content":"参考 自动初始化 Gitalk 和 Gitment 评论 ","date":"2022-04-01","objectID":"/gitalk-init-issue/:3:0","tags":["gitalk","python","hugo"],"title":"Gitalk 初始化 issue","uri":"/gitalk-init-issue/"},{"categories":["node-red"],"content":"Node-red,Low-code,自定义nodered节点,nodered,节点开发,how to create node-red node","date":"2022-04-01","objectID":"/node-red-glance/","tags":["low-code","node-red"],"title":"Node-RED 节点开发","uri":"/node-red-glance/"},{"categories":["node-red"],"content":"概述 Node-RED 是构建物联网 (IOT,Internet of Things) 应用程序的一个强大工具，其重点是简化代码块的“连接\"以执行任务。它使用可视 化编程方法，允许开发人员将预定义的代码块（称为“节点”，Node) 连接起来执行任务。连接的节点，通常是输入节点、处理节点和输出节点的组合，当它们连接在一起时，构成一个“流”(Flows)。 ","date":"2022-04-01","objectID":"/node-red-glance/:1:0","tags":["low-code","node-red"],"title":"Node-RED 节点开发","uri":"/node-red-glance/"},{"categories":["node-red"],"content":"安装node-red 安装 node-red 的方式大致有 2 种，使用 docker 和 npm ，docker 安装可以参考。这里使用 npm 安装。个人觉得在本地调试 npm 比 docker 更方便一点，源码都在本地，docker 的话还需要把目录映射出来。 npm 安装直接一行命令就可以搞定，具体可以参考 npm i node-red 安装成功后，会在用户目录下生成一个 .node-red 目录，我用的是 Windows 系统，所以这里的目录是 C:\\Users\\weibin\\.node-red，这个目录下有配置文件 settings.js，里面有一些 node-red 配置项，比如默认端口等。 node-red 目录node-red 目录 \" node-red 目录 ","date":"2022-04-01","objectID":"/node-red-glance/:2:0","tags":["low-code","node-red"],"title":"Node-RED 节点开发","uri":"/node-red-glance/"},{"categories":["node-red"],"content":"启动 安装完成后，直接执行 node-red 就可以启动服务。 cmd 启动 node-redcmd 启动 node-red \" cmd 启动 node-red node-red 的默认端口是 1880，直接用浏览器访问 http://127.0.0.1:1880 就可以看到 node-red 的页面。 node-red 界面node-red 界面 \" node-red 界面 ","date":"2022-04-01","objectID":"/node-red-glance/:3:0","tags":["low-code","node-red"],"title":"Node-RED 节点开发","uri":"/node-red-glance/"},{"categories":["node-red"],"content":"创建自定义节点 每一个 node-red 节点都是一个 npm 包，开发 npm 节点跟开发 npm 组件包是一样。 一个 node-red 节点主要包括两个文件，一个是 html 文件，一个是 js 文件。html 是界面配置，js 处理逻辑，加上 npm 的 package.json 文件，正常三个文件就可以实现一个 node-red 节点。 ","date":"2022-04-01","objectID":"/node-red-glance/:4:0","tags":["low-code","node-red"],"title":"Node-RED 节点开发","uri":"/node-red-glance/"},{"categories":["node-red"],"content":"加法器节点开发 我们创建一个自定义节点实现一个加法器，输入两个数字，输出两个数字的和。 ","date":"2022-04-01","objectID":"/node-red-glance/:4:1","tags":["low-code","node-red"],"title":"Node-RED 节点开发","uri":"/node-red-glance/"},{"categories":["node-red"],"content":"新建项目 我们新建一个节点项目 node-sum，这个项目随便放在那个目录下都行，这里我的目录是 D:\\tmp\\node-sum。 新建项目新建项目 \" 新建项目 ","date":"2022-04-01","objectID":"/node-red-glance/:4:2","tags":["low-code","node-red"],"title":"Node-RED 节点开发","uri":"/node-red-glance/"},{"categories":["node-red"],"content":"npm 初始化 切到项目目录下，执行 npm init 将项目进行 npm 初始化，然后根据提示填写即可。 npm initnpm init \" npm init 用 IDE 打开 node-sum 项目就可以看到已经给我们初始化好了 package.json 文件。 package.jsonpackage.json \" package.json ","date":"2022-04-01","objectID":"/node-red-glance/:4:3","tags":["low-code","node-red"],"title":"Node-RED 节点开发","uri":"/node-red-glance/"},{"categories":["node-red"],"content":"功能实现 sum.html \u003cscript type=\"text/javascript\"\u003e RED.nodes.registerType('sum', { // 这个值 必须和 js 中 RED.nodes.registerType 的值一致 category: '自定义节点', // 分类 color: '#a6bbcf', // 节点颜色 defaults: { name: {value: \"\"}, // name 默认是空 add1: {value: 0}, // add1 默认值 0 add2: {value: 0}, // add2 默认值 0 }, inputs: 0, // 节点有多少输入 0 或者多个 outputs: 1, // 节点有多少输出 0 或者多个 icon: \"file.png\", // 节点使用的图标 paletteLabel: \"加法器\", // 节点显示的名称 label: function () { // 节点的工作区的标签 return this.name || \"加法器\"; }, // 钩子函数,双节节点调出 template 时触发 oneditprepare: function () { console.log(\"oneditprepare 被调用\"); }, // 钩子函数,点击 template 中的完成按钮时触发 oneditsave: function () { console.log(\"oneditsave 被调用\"); } }); \u003c/script\u003e \u003c!--data-template-name 必须和 js 中 RED.nodes.registerType 的值一致 --\u003e \u003c!--template 是模板，可以理解成表单，节点需要的信息可以从这里输入--\u003e \u003cscript type=\"text/html\" data-template-name=\"sum\"\u003e \u003cdiv class=\"form-row\"\u003e \u003clabel for=\"node-input-name\"\u003e\u003ci class=\"fa fa-tag\"\u003e\u003c/i\u003e Name\u003c/label\u003e \u003cinput type=\"text\" id=\"node-input-name\" placeholder=\"Name\"\u003e \u003c/div\u003e \u003cdiv class=\"form-row\"\u003e \u003clabel for=\"node-input-add1\"\u003e\u003ci class=\"fa fa-tag\"\u003e\u003c/i\u003e加数1\u003c/label\u003e \u003cinput type=\"text\" id=\"node-input-add1\" placeholder=\"加数1\"\u003e \u003c/div\u003e \u003cdiv class=\"form-row\"\u003e \u003clabel for=\"node-input-add2\"\u003e\u003ci class=\"fa fa-tag\"\u003e\u003c/i\u003e加数2\u003c/label\u003e \u003cinput type=\"text\" id=\"node-input-add2\" placeholder=\"加数2\"\u003e \u003c/div\u003e \u003c/script\u003e \u003c!--data-help-name 必须和 js 中 RED.nodes.registerType 的值一致 --\u003e \u003c!--help 是节点的帮助文档--\u003e \u003cscript type=\"text/html\" data-help-name=\"sum\"\u003e \u003cp\u003e一个简单的加法器\u003c/p\u003e \u003c/script\u003e sum.js module.exports = function (RED) { function Sum(config) { RED.nodes.createNode(this, config); var node = this; // 获取输入的参数 let add1 = parseInt(config.add1) let add2 = parseInt(config.add2) node.send({ // 向下一个节点输出信息 payload: `${add1}+ ${add2}结果为 ` + (add1 + add2) }); node.on('input', function (msg) { // 接收上游节点接收消息 }); } // 注册一个节点 sum,注册的节点不能重复也就是说同一个 node-red 项目不能有 2 个 registerType sum 节点 RED.nodes.registerType(\"sum\", Sum); } 需要在 package.json 文件里添加 node-red 信息，完整的 package.json 如下： { \"name\": \"node-sum\", \"version\": \"1.0.0\", \"description\": \"node-red 加法器\", \"main\": \"index.js\", \"scripts\": { \"test\": \"echo \\\"Error: no test specified\\\" \u0026\u0026 exit 1\" }, \"keywords\": [ \"node-red\", \"add\" ], \"author\": \"xiaobinqt@163.com\", \"license\": \"ISC\", \"node-red\": { \"nodes\": { \"sum\": \"sum.js\" } } } 在 package.json 中添加的 node-red 信息是固定写法，可以理解成向 node-red 中注册了 nodes 的名称为 sum，注册的 js 文件为 sum.js。 \"node-red\": { \"nodes\": { \"sum\": \"sum.js\" } } ","date":"2022-04-01","objectID":"/node-red-glance/:4:4","tags":["low-code","node-red"],"title":"Node-RED 节点开发","uri":"/node-red-glance/"},{"categories":["node-red"],"content":"本地安装 可以通过 npm i 安装刚才的 sum 节点到 node-red 中。切到.node-red 目录下，执行 npm i d:\\tmp\\node-sum 安转本地节点并重启安转本地节点并重启 \" 安转本地节点并重启 然后重启 node-red 就可以看到刚才安装的节点了。 节点安装成功节点安装成功 \" 节点安装成功 ","date":"2022-04-01","objectID":"/node-red-glance/:4:5","tags":["low-code","node-red"],"title":"Node-RED 节点开发","uri":"/node-red-glance/"},{"categories":["node-red"],"content":"测试功能 把节点拖到工作区，双击节点（会触发oneditprepare函数）打开编辑区 双节节点填写编辑区双节节点填写编辑区 \" 双节节点填写编辑区 填写完编辑区内容后点击完成（会触发oneditsave函数），点击部署就会在调试窗口输出 node.send 信息。 部署部署 \" 部署 ","date":"2022-04-01","objectID":"/node-red-glance/:4:6","tags":["low-code","node-red"],"title":"Node-RED 节点开发","uri":"/node-red-glance/"},{"categories":["node-red"],"content":"参考 Creating your first node Design: i18n ","date":"2022-04-01","objectID":"/node-red-glance/:5:0","tags":["low-code","node-red"],"title":"Node-RED 节点开发","uri":"/node-red-glance/"},{"categories":["开发者手册"],"content":"https,google强制跳到https,ERR_SSL_PROTOCOL_ERROR,How to Stop Chrome from Automatically Redirecting to https","date":"2022-03-29","objectID":"/stop_chrome_auto_redirect_2_https/","tags":["chrome"],"title":"禁止Google浏览器强制跳转https","uri":"/stop_chrome_auto_redirect_2_https/"},{"categories":["开发者手册"],"content":"这几天在使用 google 浏览器打开公司的一个网站时，发现总是自动跳转到 https，以至于出现下面这个页面： ERR_SSL_PROTOCOL_ERRORERR_SSL_PROTOCOL_ERROR \" ERR_SSL_PROTOCOL_ERROR 有时候浏览器太智能了也不是一件好事🤣。 ","date":"2022-03-29","objectID":"/stop_chrome_auto_redirect_2_https/:0:0","tags":["chrome"],"title":"禁止Google浏览器强制跳转https","uri":"/stop_chrome_auto_redirect_2_https/"},{"categories":["开发者手册"],"content":"解决方法 用 Google 浏览器打开chrome://net-internals/#hsts 这个页面，在最下面的 Delete domain security policies 填上需要禁止跳转的网站，然后点击Delete。 Delete domain security policiesDelete domain security policies \" Delete domain security policies 这里有个需要注意的地方是，如果我们的网址是 http://g.xiaobinqt.cn:8000，那么Domain 的值填的是 xiaobinqt.cn。 ","date":"2022-03-29","objectID":"/stop_chrome_auto_redirect_2_https/:1:0","tags":["chrome"],"title":"禁止Google浏览器强制跳转https","uri":"/stop_chrome_auto_redirect_2_https/"},{"categories":["开发者手册"],"content":"参考 How to Stop Chrome from Automatically Redirecting to https ","date":"2022-03-29","objectID":"/stop_chrome_auto_redirect_2_https/:2:0","tags":["chrome"],"title":"禁止Google浏览器强制跳转https","uri":"/stop_chrome_auto_redirect_2_https/"},{"categories":["hugo"],"content":"hugo,algolia,algoliasearch,exceptions.AlgoliaUnreachableHostException: Unreachable hosts, algolia索引","date":"2022-03-28","objectID":"/hugo_algolia/","tags":["hugo","algolia"],"title":"hugo algolia Unreachable hosts","uri":"/hugo_algolia/"},{"categories":["hugo"],"content":"最近在使用 hugo algolia 时，在 github actions 同步索引到 algolia 时总是出现这样的错误： action error listaction error list \" action error list Unreachable hostsUnreachable hosts \" Unreachable hosts 我用的 action 插件是Algolia Index Uploader，找了半天发现是参数 algolia_index_id 写的有问题😥： algolia_index_id 填的值algolia_index_id 填的值 \" algolia_index_id 填的值 上传成功后可以去 algolia 官网查看效果： Settings -\u003e Applications -\u003e 进入到应用 -\u003e Search -\u003e Browse 上传索引效果上传索引效果 \" 上传索引效果 ","date":"2022-03-28","objectID":"/hugo_algolia/:0:0","tags":["hugo","algolia"],"title":"hugo algolia Unreachable hosts","uri":"/hugo_algolia/"},{"categories":["hugo"],"content":"参考 Algolia Hosts unreachable ","date":"2022-03-28","objectID":"/hugo_algolia/:1:0","tags":["hugo","algolia"],"title":"hugo algolia Unreachable hosts","uri":"/hugo_algolia/"},{"categories":["理解计算机"],"content":"TCP,UDP,网络模型,实体层,链接层,网络层,传输层,应用层,网络数据包,以太网协议,MAC地址,广播,Physical Layer,Application Layer,Transport Layer,Network Layer,Internet Protocol Suite,Ethernet,subnet mask,IPv4,IPv6,互联网协议的通信过程","date":"2022-03-27","objectID":"/net_protocol_glance/","tags":["network"],"title":"互联网协议简述","uri":"/net_protocol_glance/"},{"categories":["理解计算机"],"content":"概述 ","date":"2022-03-27","objectID":"/net_protocol_glance/:1:0","tags":["network"],"title":"互联网协议简述","uri":"/net_protocol_glance/"},{"categories":["理解计算机"],"content":"五层模型 互联网的实现，分成好几层。每一层都有自己的功能，就像建筑物一样，每一层都靠下一层支持。 用户接触到的，只是最上面的一层，根本没有感觉到下面的层。理解互联网，需要从最下层开始，自下而上理解每一层的功能。 如何分层有不同的模型，有的模型分七层，有的分四层。把互联网分成五层，比较容易解释。 五层模型五层模型 \" 五层模型 如上图所示，最底下的一层叫做\"实体层\"（Physical Layer），最上面的一层叫做\"应用层\"（Application Layer），中间的三层（自下而上）分别是\"链接层\"（Link Layer）、“网络层”（Network Layer）和\"传输层\"（Transport Layer）。越下面的层，越靠近硬件；越上面的层，越靠近用户。 名字只是一个代号，它们叫什么名字，其实并不重要。只需要知道，互联网分成若干层就可以了。 ","date":"2022-03-27","objectID":"/net_protocol_glance/:1:1","tags":["network"],"title":"互联网协议简述","uri":"/net_protocol_glance/"},{"categories":["理解计算机"],"content":"层与协议 每一层都是为了完成一种功能。为了实现这些功能，就需要大家都遵守共同的规则。 大家都遵守的规则，就叫做\"协议\"（protocol）。 互联网的每一层，都定义了很多协议。这些协议的总称，就叫做\"互联网协议\"（Internet Protocol Suite），它们是互联网的核心。 ","date":"2022-03-27","objectID":"/net_protocol_glance/:1:2","tags":["network"],"title":"互联网协议简述","uri":"/net_protocol_glance/"},{"categories":["理解计算机"],"content":"实体层 电脑要组网，第一件事是先把电脑连起来，可以用光缆、电缆、双绞线、无线电波等方式。 这就叫做\"实体层\"，它就是把电脑连接起来的物理手段。它主要规定了网络的一些电气特性，作用是负责传送 0 和 1 的电信号。 实体层实体层 \" 实体层 ","date":"2022-03-27","objectID":"/net_protocol_glance/:2:0","tags":["network"],"title":"互联网协议简述","uri":"/net_protocol_glance/"},{"categories":["理解计算机"],"content":"链接层 单纯的 0 和 1 没有任何意义，必须规定解读方式：多少个电信号算一组？每个信号位有何意义？ 这就是\"链接层\"的功能，它在\"实体层\"的上方，确定了 0 和 1 的分组方式。 ","date":"2022-03-27","objectID":"/net_protocol_glance/:3:0","tags":["network"],"title":"互联网协议简述","uri":"/net_protocol_glance/"},{"categories":["理解计算机"],"content":"以太网协议 早期的时候，每家公司都有自己的电信号分组方式。逐渐地，一种叫做\"以太网\"（Ethernet）的协议，占据了主导地位。 以太网规定，一组电信号构成一个数据包，叫做\"帧\"（Frame）。每一帧分成两个部分：标头（Head）和数据（Data）。 head-datahead-data \" head-data “标头\"包含数据包的一些说明项，比如发送者、接受者、数据类型等等；“数据\"则是数据包的具体内容。 “标头\"的长度，固定为 18 字节。“数据\"的长度，最短为 46 字节，最长为 1500 字节。因此，整个\"帧\"最短为 64 字节，最长为 1518 字节。如果数据很长，就必须分割成多个帧进行发送。 ","date":"2022-03-27","objectID":"/net_protocol_glance/:3:1","tags":["network"],"title":"互联网协议简述","uri":"/net_protocol_glance/"},{"categories":["理解计算机"],"content":"MAC 地址 以太网数据包的\"标头”，包含了发送者和接受者的信息。那么，发送者和接受者是如何标识呢？ 以太网规定，连入网络的所有设备，都必须具有\"网卡\"接口。数据包必须是从一块网卡，传送到另一块网卡。网卡的地址，就是数据包的发送地址和接收地址，这叫做 MAC 地址。 每块网卡出厂的时候，都有一个全世界独一无二的 MAC 地址，长度是 48 个二进制位，通常用 12 个十六进制数表示。 前 6 个十六进制数是厂商编号，后 6 个是该厂商的网卡流水号。有了 MAC 地址，就可以定位网卡和数据包的路径了。 MAC addressMAC address \" MAC address 上图的 MAC 地址的二进制位为 00000000-10110000-11010000-10000110-10111011-11110111。 ","date":"2022-03-27","objectID":"/net_protocol_glance/:3:2","tags":["network"],"title":"互联网协议简述","uri":"/net_protocol_glance/"},{"categories":["理解计算机"],"content":"广播 以太网数据包必须知道接收方的 MAC 地址，然后才能发送，那么问题来了， 一块网卡怎么会知道另一块网卡的MAC地址？ 就算有了 MAC 地址，系统怎样才能把数据包准确送到接收方？ 回答是以太网采用了一种很\"原始\"的方式，它不是把数据包准确送到接收方，而是向本网络内所有计算机发送，让每台计算机自己判断，是否为接收方。 广播广播 \" 广播 上图中，1 号计算机向 2 号计算机发送一个数据包，同一个子网络的 3 号、4 号、5 号计算机都会收到这个包。它们读取这个包的\"标头”，找到接收方的 MAC 地址，然后与自身的 MAC 地址相比较，如果两者相同，就接受这个包，做进一步处理，否则就丢弃这个包。这种发送方式就叫做\"广播”（broadcasting）。 有了数据包的定义、网卡的 MAC 地址、广播的发送方式，“链接层\"就可以在多台计算机之间传送数据了。 ","date":"2022-03-27","objectID":"/net_protocol_glance/:3:3","tags":["network"],"title":"互联网协议简述","uri":"/net_protocol_glance/"},{"categories":["理解计算机"],"content":"网络层 ","date":"2022-03-27","objectID":"/net_protocol_glance/:4:0","tags":["network"],"title":"互联网协议简述","uri":"/net_protocol_glance/"},{"categories":["理解计算机"],"content":"网络层的由来 以太网协议，依靠 MAC 地址发送数据。理论上，单单依靠 MAC 地址，上海的网卡就可以找到洛杉矶的网卡了，技术上是可以实现的。 但是，这样做有一个重大的缺点。以太网采用广播方式发送数据包，所有成员人手一\"包”，不仅效率低，而且局限在发送者所在的子网络。也就是说，如果两台计算机不在同一个子网络，广播是传不过去的 。这种设计是合理的，否则互联网上每一台计算机都会收到所有包，那会引起灾难。 互联网是无数子网络共同组成的一个巨型网络，很像想象上海和洛杉矶的电脑会在同一个子网络，这几乎是不可能的。 子网络子网络 \" 子网络 因此，必须找到一种方法，能够区分哪些 MAC 地址属于同一个子网络，哪些不是。如果是同一个子网络，就采用广播方式发送，否则就采用\"路由\"方式发送。（“路由\"的意思，就是指如何向不同的子网络分发数据包。），MAC 地址本身无法做到这一点，它只与厂商有关，与所处网络无关。 这就导致了\"网络层\"的诞生。它的作用是引进一套新的地址，使得我们能够区分不同的计算机是否属于同一个子网络。这套地址就叫做\"网络地址”，简称\"网址”。 于是，“网络层\"出现以后，每台计算机有了两种地址，一种是 MAC 地址，另一种是网络地址。两种地址之间没有任何联系，MAC 地址是绑定在网卡上的，网络地址则是管理员分配的，它们只是随机组合在一起。 网络地址帮助我们确定计算机所在的子网络，MAC 地址则将数据包送到该子网络中的目标网卡。因此，从逻辑上可以推断，必定是先处理网络地址，然后再处理 MAC 地址。 ","date":"2022-03-27","objectID":"/net_protocol_glance/:4:1","tags":["network"],"title":"互联网协议简述","uri":"/net_protocol_glance/"},{"categories":["理解计算机"],"content":"IP协议和子网掩码 规定网络地址的协议，叫做 IP 协议。它所定义的地址，就被称为 IP 地址。 目前，广泛采用的是 IP 协议第四版，简称 IPv4。这个版本规定，网络地址由 32 个二进制位组成。 IP协议IP协议 \" IP协议 习惯上，我们用分成四段的十进制数表示 IP 地址，从 0.0.0.0 一直到 255.255.255.255。 互联网上的每一台计算机，都会分配到一个 IP 地址。 IP 地址分成两个部分，前一部分代表网络，后一部分代表主机。 比如，IP 地址 172.16.254.1，这是一个 32 位的地址，假定它的网络部分是前 24 位（172.16.254），那么主机部分就是后 8 位（最后的那个 1 ）。处于同一个子网络的电脑，它们 IP 地址的网络部分必定是相同的，也就是说 172.16.254.2 应该与 172.16.254.1 处在同一个子网络。 单单从 IP 地址，我们无法判断网络部分。还是以 172.16.254.1 为例，它的网络部分，到底是前 24 位，还是前 16 位，甚至前 28 位，从 IP 地址上是看不出来的。 那么，怎样才能从IP地址，判断两台计算机是否属于同一个子网络呢？这就要用到另一个参数\"子网掩码”（subnet mask）。 所谓 “子网掩码”，就是表示子网络特征的一个参数。它在形式上等同于 IP 地址，也是一个 32 位二进制数字，它的网络部分全部为 1，主机部分全部为 0 。比如，IP 地址 172.16.254.1 ，如果已知网络部分是前 24 位，主机部分是后 8 位，那么子网络掩码就是 11111111.11111111.11111111.00000000，写成十进制就是 255.255.255.0。 知道\"子网掩码\"，我们就能判断，任意两个 IP 地址是否处在同一个子网络。方法是将两个 IP 地址与子网掩码分别进行 AND 运算（两个数位都为 1 ，运算结果为 1，否则为 0），然后比较结果是否相同，如果是的话，就表明它们在同一个子网络中，否则就不是。 比如，已知IP地址 172.16.254.1 和 172.16.254.233 的子网掩码都是 255.255.255.0，请问它们是否在同一个子网络？两者与子网掩码分别进行 AND 运算，结果都是 172.16.254.0，因此它们在同一个子网络。 10101100.00010000.11111110.00000001 # 172.16.254.1 11111111.11111111.11111111.00000000 # 255.255.255.0 10101100.00010000.11111110.00000000 # AND 结果二进制位 172.16.254.0 # AND 结果转成十进制 所以，IP 协议的作用主要有两个，一个是为每一台计算机分配 IP 地址，另一个是确定哪些地址在同一个子网络。 ","date":"2022-03-27","objectID":"/net_protocol_glance/:4:2","tags":["network"],"title":"互联网协议简述","uri":"/net_protocol_glance/"},{"categories":["理解计算机"],"content":"IP数据包 根据 IP 协议发送的数据，就叫做 IP 数据包。不难想象，其中必定包括 IP 地址信息。 但是前面说过，以太网数据包只包含 MAC 地址，并没有 IP 地址的栏位。那么是否需要修改数据定义，再添加一个栏位呢？ 回答是不需要，我们可以把 IP 数据包直接放进以太网数据包的\"数据\"部分，因此完全不用修改以太网的规格。这就是互联网分层结构的好处：上层的变动完全不涉及下层的结构。 具体来说，IP 数据包也分为\"标头\"和\"数据\"两个部分。 IP数据包1IP数据包1 \" IP数据包1 “标头\"部分主要包括版本、长度、IP 地址等信息，“数据\"部分则是 IP 数据包的具体内容。它放进以太网数据包后，以太网数据包就变成了下面这样。 IP数据包2IP数据包2 \" IP数据包2 IP 数据包的“标头”部分的长度为 20 到 60 字节，整个数据包的总长度最大为 65,535 字节。因此，理论上，一个 IP 数据包的\"数据\"部分，最长为 65,515 字节。前面说过，以太网数据包的\"数据\"部分，最长只有 1500 字节。因此，如果 IP 数据包超过了 1500 字节（上图红色部分），它就需要分割成几个以太网数据包，分开发送了。 ","date":"2022-03-27","objectID":"/net_protocol_glance/:4:3","tags":["network"],"title":"互联网协议简述","uri":"/net_protocol_glance/"},{"categories":["理解计算机"],"content":"ARP协议 由于 IP 数据包是放在以太网数据包里发送的，所以我们必须同时知道两个地址，一个是对方的 MAC 地址，另一个是对方的 IP 地址。通常情况下，对方的 IP 地址是已知的，但是我们不知道它的 MAC 地址。 所以，我们需要一种机制，能够从 IP 地址得到 MAC 地址。 这里又可以分成两种情况。 第一种情况，如果两台主机不在同一个子网络，那么事实上没有办法得到对方的 MAC 地址，只能把数据包传送到两个子网络连接处的\"网关”（gateway），让网关去处理。 第二种情况，如果两台主机在同一个子网络，那么我们可以用 ARP 协议，得到对方的 MAC 地址。ARP 协议也是发出一个数据包（包含在以太网数据包中），其中包含它所要查询主机的 IP 地址，在对方的 MAC 地址这一栏，填的是FF:FF:FF:FF:FF:FF，表示这是一个\"广播” 地址。它所在子网络的每一台主机，都会收到这个数据包，从中取出 IP 地址，与自身的 IP 地址进行比较。如果两者相同，都做出回复，向对方报告自己的 MAC 地址，否则就丢弃这个包。 有了 ARP 协议之后，我们就可以得到同一个子网络内的主机 MAC 地址，可以把数据包发送到任意一台主机之上。 ","date":"2022-03-27","objectID":"/net_protocol_glance/:4:4","tags":["network"],"title":"互联网协议简述","uri":"/net_protocol_glance/"},{"categories":["理解计算机"],"content":"传输层 ","date":"2022-03-27","objectID":"/net_protocol_glance/:5:0","tags":["network"],"title":"互联网协议简述","uri":"/net_protocol_glance/"},{"categories":["理解计算机"],"content":"传输层的由来 有了 MAC 地址和 IP 地址，我们已经可以在互联网上任意两台主机上建立通信。 接下来的问题是，同一台主机上有许多程序都需要用到网络，比如，你一边浏览网页，一边与朋友在线聊天。当一个数据包从互联网上发来的时候，你怎么知道，它是表示网页的内容，还是表示在线聊天的内容？ 也就是说，我们还需要一个参数，表示这个数据包到底供哪个程序（进程）使用。这个参数就叫做\"端口\"（port），它其实是每一个使用网卡的程序的编号。每个数据包都发到主机的特定端口，所以不同的程序就能取到自己所需要的数据。 “端口\"是 0 到 65535 之间的一个整数，正好 16 个二进制位。0 到 1023 的端口被系统占用，用户只能选用大于 1023 的端口。不管是浏览网页还是在线聊天，应用程序会随机选用一个端口，然后与服务器的相应端口联系。 “传输层\"的功能，就是建立\"端口到端口\"的通信。相比之下，“网络层\"的功能是建立\"主机到主机\"的通信。只要确定主机和端口，我们就能实现程序之间的交流。因此，Unix系统就把主机+端口，叫做\"套接字” （socket）。有了它，就可以进行网络应用程序开发了。 ","date":"2022-03-27","objectID":"/net_protocol_glance/:5:1","tags":["network"],"title":"互联网协议简述","uri":"/net_protocol_glance/"},{"categories":["理解计算机"],"content":"UDP 协议 我们必须在数据包中加入端口信息，这就需要新的协议。最简单的实现叫做 UDP 协议，它的格式几乎就是在数据前面，加上端口号。 UDP 数据包，也是由\"标头\"和\"数据\"两部分组成。 UDP数据格式_1UDP数据格式_1 \" UDP数据格式_1 “标头\"部分主要定义了发出端口和接收端口，“数据\"部分就是具体的内容。然后，把整个 UDP 数据包放入 IP 数据包的\"数据\"部分，而前面说过，IP 数据包又是放在以太网数据包之中的，所以整个以太网数据包现在变成了下面这样： UDP数据格式_2UDP数据格式_2 \" UDP数据格式_2 UDP 数据包非常简单，“标头\"部分一共只有 8 个字节，总长度不超过 65,535 字节，正好放进一个IP数据包。 ","date":"2022-03-27","objectID":"/net_protocol_glance/:5:2","tags":["network"],"title":"互联网协议简述","uri":"/net_protocol_glance/"},{"categories":["理解计算机"],"content":"TCP 协议 UDP 协议的优点是比较简单，容易实现，但是缺点是可靠性较差，一旦数据包发出，无法知道对方是否收到。 为了解决这个问题，提高网络可靠性，TCP 协议就诞生了。这个协议非常复杂，但可以近似认为，它就是有确认机制的 UDP 协议，每发出一个数据包都要求确认。如果有一个数据包遗失，就收不到确认，发出方就知道有必要重发这个数据包了。 因此，TCP 协议能够确保数据不会遗失。它的缺点是过程复杂、实现困难、消耗较多的资源。 TCP 数据包和 UDP 数据包一样，都是内嵌在 IP 数据包的“数据”部分。TCP 数据包没有长度限制，理论上可以无限长，但是为了保证网络的效率，通常 TCP 数据包的长度不会超过 IP 数据包的长度，以确保单个 TCP 数据包不必再分割。 ","date":"2022-03-27","objectID":"/net_protocol_glance/:5:3","tags":["network"],"title":"互联网协议简述","uri":"/net_protocol_glance/"},{"categories":["理解计算机"],"content":"应用层 应用程序收到\"传输层\"的数据，接下来就要进行解读。由于互联网是开放架构，数据来源五花八门，必须事先规定好格式，否则根本无法解读。 “应用层”的作用，就是规定应用程序的数据格式。 举例来说，TCP 协议可以为各种各样的程序传递数据，比如 Email、WWW、FTP 等等。那么，必须有不同协议规定电子邮件、网页、FTP 数据的格式，这些应用程序协议就构成了\"应用层”。 这是最高的一层，直接面对用户。它的数据就放在 TCP 数据包的\"数据\"部分。因此，现在的以太网的数据包就变成下面这样。 应用层数据包应用层数据包 \" 应用层数据包 ","date":"2022-03-27","objectID":"/net_protocol_glance/:6:0","tags":["network"],"title":"互联网协议简述","uri":"/net_protocol_glance/"},{"categories":["理解计算机"],"content":"小结 网络通信就是交换数据包。电脑 A 向电脑 B 发送一个数据包，后者收到了，回复一个数据包，从而实现两台电脑之间的通信。数据包的结构，基本上是下面这样： 数据包数据包 \" 数据包 发送这个包，需要知道两个地址： 对方的 MAC 地址 对方的 IP 地址 有了这两个地址，数据包才能准确送到接收者手中。但是，MAC 地址有局限性，如果两台电脑不在同一个子网络，就无法知道对方的 MAC 地址，必须通过网关（gateway）转发。 网关网关 \" 网关 上图中，1 号电脑要向 4 号电脑发送一个数据包。它先判断 4 号电脑是否在同一个子网络，结果发现不是，于是就把这个数据包发到网关 A。网关 A 通过路由协议，发现 4 号电脑位于子网络 B，又把数据包发给网关 B，网关 B 再转发到 4 号电脑。 1 号电脑把数据包发到网关 A，必须知道网关 A 的 MAC 地址。所以，数据包的目标地址，实际上分成两种情况： 场景 数据包地址 同一个子网络 对方的MAC地址，对方的IP地址 非同一个子网络 网关的MAC地址，对方的IP地址 发送数据包之前，电脑必须判断对方是否在同一个子网络，然后选择相应的 MAC 地址。 ","date":"2022-03-27","objectID":"/net_protocol_glance/:7:0","tags":["network"],"title":"互联网协议简述","uri":"/net_protocol_glance/"},{"categories":["理解计算机"],"content":"用户的上网设置 ","date":"2022-03-27","objectID":"/net_protocol_glance/:8:0","tags":["network"],"title":"互联网协议简述","uri":"/net_protocol_glance/"},{"categories":["理解计算机"],"content":"静态IP地址 new computercomputer \" new computer 通常你必须做一些设置。有时，管理员会告诉你下面四个参数，你把它们填入操作系统，计算机就能连上网了： 本机的IP地址 子网掩码 网关的IP地址 DNS的IP地址 下图是Windows系统的设置窗口。 系统设置系统设置 \" 系统设置 这四个参数缺一不可。由于它们是给定的，计算机每次开机，都会分到同样的IP地址，所以这种情况被称作\"静态IP地址上网”。 但是，这样的设置很专业，普通用户望而生畏，而且如果一台电脑的IP地址保持不变，其他电脑就不能使用这个地址，不够灵活。出于这两个原因，大多数用户使用\"动态IP地址上网”。 ","date":"2022-03-27","objectID":"/net_protocol_glance/:8:1","tags":["network"],"title":"互联网协议简述","uri":"/net_protocol_glance/"},{"categories":["理解计算机"],"content":"动态IP地址 所谓\"动态IP地址”，指计算机开机后，会自动分配到一个IP地址，不用人为设定。它使用的协议叫做DHCP协议。 这个协议规定，每一个子网络中，有一台计算机负责管理本网络的所有IP地址，它叫做\"DHCP服务器”。新的计算机加入网络，必须向\"DHCP服务器\"发送一个\"DHCP请求\"数据包，申请IP地址和相关的网络参数。 前面说过，如果两台计算机在同一个子网络，必须知道对方的MAC地址和IP地址，才能发送数据包。但是，新加入的计算机不知道这两个地址，怎么发送数据包呢？ DHCP协议做了一些巧妙的规定。 ","date":"2022-03-27","objectID":"/net_protocol_glance/:8:2","tags":["network"],"title":"互联网协议简述","uri":"/net_protocol_glance/"},{"categories":["理解计算机"],"content":"DHCP协议 首先，它是一种应用层协议，建立在UDP协议之上，所以整个数据包是这样的： HDCP协议数据包HDCP协议数据包 \" HDCP协议数据包 最前面的\"以太网标头\"，设置发出方（本机）的MAC地址和接收方（DHCP服务器）的MAC地址。前者就是本机网卡的MAC地址，后者这时不知道，就填入一个广播地址：FF-FF-FF-FF-FF-FF。 后面的\"IP标头\"，设置发出方的IP地址和接收方的IP地址。这时，对于这两者，本机都不知道。于是，发出方的IP地址就设为0.0.0.0，接收方的IP地址设为255.255.255.255。 最后的\"UDP标头\"，设置发出方的端口和接收方的端口。这一部分是DHCP协议规定好的，发出方是68端口，接收方是67端口。 这个数据包构造完成后，就可以发出了。以太网是广播发送，同一个子网络的每台计算机都收到了这个包。因为接收方的MAC地址是FF-FF-FF-FF-FF-FF ，看不出是发给谁的，所以每台收到这个包的计算机，还必须分析这个包的IP地址，才能确定是不是发给自己的。当看到发出方IP地址是0.0.0.0，接收方是255.255.255.255，于是DHCP服务器知道\" 这个包是发给我的\"，而其他计算机就可以丢弃这个包。 接下来，DHCP服务器读出这个包的数据内容，分配好IP地址，发送回去一个\"DHCP响应\" 数据包。这个响应包的结构也是类似的，以太网标头的MAC地址是双方的网卡地址，IP标头的IP地址是DHCP服务器的IP地址（发出方）和255.255.255.255 （接收方），UDP标头的端口是67（发出方）和68（接收方），分配给请求端的IP地址和本网络的具体参数则包含在Data部分。 新加入的计算机收到这个响应包，于是就知道了自己的IP地址、子网掩码、网关地址、DNS服务器等等参数。 ","date":"2022-03-27","objectID":"/net_protocol_glance/:8:3","tags":["network"],"title":"互联网协议简述","uri":"/net_protocol_glance/"},{"categories":["理解计算机"],"content":"小结 不管是\"静态IP地址\"还是\"动态IP地址\"，电脑上网的首要步骤，是确定四个参数。这四个值很重要，值得重复一遍： 本机的IP地址 子网掩码 网关的IP地址 DNS的IP地址 有了这几个数值，电脑就可以上网\"冲浪\"了。 ","date":"2022-03-27","objectID":"/net_protocol_glance/:8:4","tags":["network"],"title":"互联网协议简述","uri":"/net_protocol_glance/"},{"categories":["理解计算机"],"content":"一个实例 ","date":"2022-03-27","objectID":"/net_protocol_glance/:9:0","tags":["network"],"title":"互联网协议简述","uri":"/net_protocol_glance/"},{"categories":["理解计算机"],"content":"本机参数 我们假定，用户设置好了自己的网络参数： 本机的IP地址：192.168.1.100 子网掩码：255.255.255.0 网关的IP地址：192.168.1.1 DNS的IP地址：8.8.8.8 然后他打开浏览器，想要访问Google，在地址栏输入了网址：www.google.com。 访问google访问google \" 访问google 这意味着，浏览器要向Google发送一个网页请求的数据包。 ","date":"2022-03-27","objectID":"/net_protocol_glance/:9:1","tags":["network"],"title":"互联网协议简述","uri":"/net_protocol_glance/"},{"categories":["理解计算机"],"content":"DNS协议 我们知道，发送数据包，必须要知道对方的IP地址。但是，现在，我们只知道网址www.google.com，不知道它的IP地址。 DNS协议可以帮助我们，将这个网址转换成IP地址。已知DNS服务器为8.8.8.8，于是我们向这个地址发送一个DNS数据包（53端口）。 DNS数据包DNS数据包 \" DNS数据包 然后，DNS服务器做出响应，告诉我们Google的IP地址是172.194.72.105。于是，我们知道了对方的IP地址。 ","date":"2022-03-27","objectID":"/net_protocol_glance/:9:2","tags":["network"],"title":"互联网协议简述","uri":"/net_protocol_glance/"},{"categories":["理解计算机"],"content":"子网掩码 接下来，我们要判断，这个IP地址是不是在同一个子网络，这就要用到子网掩码。 已知子网掩码是255.255.255.0，本机用它对自己的IP地址192.168.1.100，做一个二进制的AND运算（两个数位都为1，结果为1，否则为0），计算结果为192.168.1.0 ；然后对Google的IP地址172.194.72.105也做一个AND运算，计算结果为172.194.72.0。这两个结果不相等，所以结论是，Google与本机不在同一个子网络。 因此，我们要向Google发送数据包，必须通过网关192.168.1.1转发，也就是说，接收方的MAC地址将是网关的MAC地址。 ","date":"2022-03-27","objectID":"/net_protocol_glance/:9:3","tags":["network"],"title":"互联网协议简述","uri":"/net_protocol_glance/"},{"categories":["理解计算机"],"content":"应用层协议 浏览网页用的是HTTP协议，它的整个数据包构造是这样的： HTTP协议数据包HTTP协议数据包 \" HTTP协议数据包 HTTP部分的内容，类似于下面这样： GET / HTTP/1.1 Host: www.google.com Connection: keep-alive User-Agent: Mozilla/5.0 (Windows NT 6.1) ...... Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8 Accept-Encoding: gzip,deflate,sdch Accept-Language: zh-CN,zh;q=0.8 Accept-Charset: GBK,utf-8;q=0.7,*;q=0.3 Cookie: ... ... 我们假定这个部分的长度为 4960 字节，它会被嵌在TCP数据包之中。 ","date":"2022-03-27","objectID":"/net_protocol_glance/:9:4","tags":["network"],"title":"互联网协议简述","uri":"/net_protocol_glance/"},{"categories":["理解计算机"],"content":"TCP协议 TCP数据包需要设置端口，接收方（Google）的HTTP端口默认是80，发送方（本机）的端口是一个随机生成的1024-65535之间的整数，假定为51775。 TCP数据包的标头长度为20字节，加上嵌入HTTP的数据包，总长度变为4980字节。 ","date":"2022-03-27","objectID":"/net_protocol_glance/:9:5","tags":["network"],"title":"互联网协议简述","uri":"/net_protocol_glance/"},{"categories":["理解计算机"],"content":"IP协议 然后，TCP数据包再嵌入IP数据包。IP数据包需要设置双方的IP地址，这是已知的，发送方是192.168.1.100（本机），接收方是172.194.72.105（Google）。 IP数据包的标头长度为20字节，加上嵌入的TCP数据包，总长度变为5000字节。 ","date":"2022-03-27","objectID":"/net_protocol_glance/:9:6","tags":["network"],"title":"互联网协议简述","uri":"/net_protocol_glance/"},{"categories":["理解计算机"],"content":"以太网协议 最后，IP数据包嵌入以太网数据包。以太网数据包需要设置双方的MAC地址，发送方为本机的网卡MAC地址，接收方为网关192.168.1.1的MAC地址（通过ARP协议得到）。 以太网数据包的数据部分，最大长度为1500字节，而现在的IP数据包长度为5000字节。因此，IP数据包必须分割成四个包。因为每个包都有自己的IP标头（20字节），所以四个包的IP数据包的长度分别为1500、1500、1500、560。 以太网协议以太网协议 \" 以太网协议 ","date":"2022-03-27","objectID":"/net_protocol_glance/:9:7","tags":["network"],"title":"互联网协议简述","uri":"/net_protocol_glance/"},{"categories":["理解计算机"],"content":"服务器端响应 经过多个网关的转发，Google的服务器172.194.72.105，收到了这四个以太网数据包。 根据IP标头的序号，Google将四个包拼起来，取出完整的TCP数据包，然后读出里面的\"HTTP请求\"，接着做出\"HTTP响应\"，再用TCP协议发回来。 本机收到HTTP响应以后，就可以将网页显示出来，完成一次网络通信。 服务器相应服务器相应 \" 服务器相应 上面的例子，虽然经过了简化，但它大致上反映了互联网协议的整个通信过程。 ","date":"2022-03-27","objectID":"/net_protocol_glance/:9:8","tags":["network"],"title":"互联网协议简述","uri":"/net_protocol_glance/"},{"categories":["理解计算机"],"content":"参考 互联网协议入门 ","date":"2022-03-27","objectID":"/net_protocol_glance/:10:0","tags":["network"],"title":"互联网协议简述","uri":"/net_protocol_glance/"},{"categories":null,"content":"我们已经在一起 var countDownDate=new Date('2019-09-17T21:21:00').getTime(); window.setInterval(function(){ var distance=new Date().getTime()-countDownDate;var days=Math.floor(distance/(1000*60*60*24)); var hours=Math.floor((distance%(1000*60*60*24))/(1000*60*60)); var minutes=Math.floor((distance%(1000*60*60))/(1000*60)); var seconds=Math.floor((distance%(1000*60))/1000); document.getElementById(\"since\").innerHTML=days+' 天 '+hours+' 时 '+minutes+' 分 '+seconds+' 秒';},1000); ","date":"2022-03-25","objectID":"/love/:0:0","tags":null,"title":"Since 2019/09/17","uri":"/love/"},{"categories":["git"],"content":"git使用，git，git基本操作，git clone,git push,git remote,.gitignore,git pull,git status,git add,git commit,git log,git diff,git rebase,git merge,git stash,git rebase,git rebase --continue,git rebase --skip,git rebase --abort,git","date":"2022-03-23","objectID":"/git_glance/","tags":["git"],"title":"git 使用笔记","uri":"/git_glance/"},{"categories":["git"],"content":"基本概念 基本概念基本概念 \" 基本概念 ","date":"2022-03-23","objectID":"/git_glance/:1:0","tags":["git"],"title":"git 使用笔记","uri":"/git_glance/"},{"categories":["git"],"content":".gitignore文件 # 此为注释 – 将被 Git 忽略 *.a # 忽略所有 .a 结尾的文件 !lib.a # 但 lib.a 除外 /TODO # 仅仅忽略项目根目录下的 TODO 文件，不包括 subdir/TODO build/ # 忽略 build/ 目录下的所有文件 doc/*.txt # 会忽略 doc/notes.txt 但不包括 doc/server/arch.txt ","date":"2022-03-23","objectID":"/git_glance/:2:0","tags":["git"],"title":"git 使用笔记","uri":"/git_glance/"},{"categories":["git"],"content":"git 常用命令 ","date":"2022-03-23","objectID":"/git_glance/:3:0","tags":["git"],"title":"git 使用笔记","uri":"/git_glance/"},{"categories":["git"],"content":"git reset 当已经把代码从暂存区提交到版本库了，git rest命令可以恢复到暂存区的状态。 git rest --hard HEAD $commit_id，如果只会退上一个版本就是HEAD^，上上一个版本就是HEAD^^，当然往上100个版本写100个^比较容易数不过来，所以写成HEAD~100。 如果知道 commit id 的话，可以直接用 commit id，commit id 没必要写全，前6位基本就可以用，git会自动去找。 commit id 可以通过git log命令查看，格式化log可以使用git log --pretty=oneline git log --pretty=onelinegit log \u0026ndash;pretty=oneline \" git log --pretty=oneline --hard 参数的作用 当文件被修改过，并且 add 到了暂存区，git reset 命令会把文件状态恢复到最初的状态，也就是从暂存区撤销掉，此时跟git reset HEAD 命令一样。 如果文件从暂存区 commit 了，说明已经生成了最新的版本号了，此时回退，则需要回退到之前的一个版本，如果知道前一个版本的版本号，git reset 版本号这样就可以了，但是一般我们不会去记版本号， 可以执行git log 命令去查看，也可以使用 git reset HEAD^ 命令用于回退到上一个版本，会重新回到工作区，也就是 add 之前的状态。 如果使用了 --hard 参数会连工作区的状态内容也修改了。 以下是同样的 commit 之后，不加 --hard 参数和使用 --hard 参数的区别： 不使用 --hard 参数不使用 \u0026ndash;hard 参数 \" 不使用 --hard 参数 使用 --hard 参数使用 \u0026ndash;hard 参数 \" 使用 --hard 参数 ","date":"2022-03-23","objectID":"/git_glance/:3:1","tags":["git"],"title":"git 使用笔记","uri":"/git_glance/"},{"categories":["git"],"content":"git diff cmd 说明 git diff [file] 显示暂存区和工作区的差异 git diff --cached [file]/git diff --staged [file] 显示暂存区和上一次提交(commit)的差异 ","date":"2022-03-23","objectID":"/git_glance/:3:2","tags":["git"],"title":"git 使用笔记","uri":"/git_glance/"},{"categories":["git"],"content":"git reflog git reflog 用来记录你的每一次命令，可以查看你最近执行过的命令，可以用来回退到某一个时刻。所以为了好查记录，commit -m 的提交说明文案尽量写清楚。 git refloggit reflog \" git reflog cmd 说明 git reflog –date=local –all | grep dev 查看 dev 分支是基于哪个分支创建的 Tips markdown 表格中使用 | 可以使用\u0026#124; ","date":"2022-03-23","objectID":"/git_glance/:3:3","tags":["git"],"title":"git 使用笔记","uri":"/git_glance/"},{"categories":["git"],"content":"git log git log 不传入任何参数的默认情况下，git log 会按时间先后顺序列出所有的提交，最近的更新排在最上面，当记录太多时会出现分页，可以按空格键翻页，按 q 键退出。 git loggit log \" git log git log --pretty=oneline 将每个提交放在一行显示，在浏览大量的提交时非常有用。 git log --pretty=onelinegit log pretty oneline \" git log --pretty=oneline git log --graph --pretty=oneline --abbrev-commit 仅显示 SHA-1 校验和所有 40 个字符中的前几个字符。--oneline 是 --pretty=oneline --abbrev-commit 合用的简写。 所以 git log --graph --pretty=oneline 可以也可以写为 git log --graph --pretty=oneline --abbrev-commit。 --graph 在日志旁以 ASCII 图形显示分支与合并历史。 git graphgit graph \" git graph ","date":"2022-03-23","objectID":"/git_glance/:3:4","tags":["git"],"title":"git 使用笔记","uri":"/git_glance/"},{"categories":["git"],"content":"git checkout cmd 说明 git checkout dev 切换到dev分支 git checkout -- file 可以丢弃工作区的修改， git checkout -- readme.txt 意思是，把readme.txt文件在工作区的修改全部撤销。 这里有两种情况： 1. readme.txt自修改后还没有被放到暂存区，撤销修改就回到和版本库一模一样的状态。 2. readme.txt已经添加到暂存区后，又作了修改，撤销修改就回到添加到暂存区后的状态 git checkout -b yourbranchname origin/oldbranchname 在本地创建和远程分支对应的分支 ","date":"2022-03-23","objectID":"/git_glance/:3:5","tags":["git"],"title":"git 使用笔记","uri":"/git_glance/"},{"categories":["git"],"content":"git rm git rm 有 2 个常用命令： git rm \u003cfile\u003e：同时从工作区和索引中删除文件。即本地的文件也被删除了，并把此次删除操作提交到了暂存区。 git rm filegit rm file \" git rm file git rm --cached ：从索引中删除文件。但是本地文件还存在，只是不希望这个文件被版本控制。 git rm --cachedgit rm \u0026ndash;cached \" git rm --cached 如果是文件夹需要加上 -r 参数，比如： git rm -r --cached 文件/文件夹名字 Tips 先手动删除文件，然后使用git rm \u003cfile\u003e和git add\u003cfile\u003e效果是一样的。 ","date":"2022-03-23","objectID":"/git_glance/:3:6","tags":["git"],"title":"git 使用笔记","uri":"/git_glance/"},{"categories":["git"],"content":"git remote cmd 说明 git remote add 名字 地址 关联一个远程库时必须给远程库指定一个名字，如：git remote add origin git@server-name:path/repo-name.git git remote -v 查看远程库信息 git remote rm \u003cname\u003e 解除了本地和远程的绑定关系，如：git remote rm origin ","date":"2022-03-23","objectID":"/git_glance/:3:7","tags":["git"],"title":"git 使用笔记","uri":"/git_glance/"},{"categories":["git"],"content":"git push 把本地库的内容推送到远程，用git push命令，比如： git push -u origin master 实际上是把当前分支推送到远程的 master 分支上。 加上了-u参数，git不但会把本地的分支内容推送的远程的master分支，还会把本地的分支和远程的master分支关联起来，在以后的推送或者拉取时就可以简化命令，直接使用 git push。 ","date":"2022-03-23","objectID":"/git_glance/:3:8","tags":["git"],"title":"git 使用笔记","uri":"/git_glance/"},{"categories":["git"],"content":"git branch cmd 说明 git brahcn -b 分支名 新建并切换到新分支，如新建并切换到dev分支：git branch -b dev git branch 列出所有分支，当前分支前面会标一个*号 git branch -d 分支名 删除某个分支 git branch -a 查看远程分支，远程分支会用红色表示出来（如果开了颜色支持的话） git branch -D \u003cname\u003e 强行删除一个没有被合并过的分支 git branch --set-upstream branch-name origin/branch-name 建立本地分支和远程分支的关联 ","date":"2022-03-23","objectID":"/git_glance/:3:9","tags":["git"],"title":"git 使用笔记","uri":"/git_glance/"},{"categories":["git"],"content":"git merge git merge命令用于合并指定分支到当前分支。如：git merge dev 合并 dev 分支到当前分支。 ","date":"2022-03-23","objectID":"/git_glance/:3:10","tags":["git"],"title":"git 使用笔记","uri":"/git_glance/"},{"categories":["git"],"content":"git switch git 2.23+ 版本支持了 switch 命令用来切换分支，实际上，切换分支这个动作，用switch更好理解。 之前切换分支使用git checkout \u003cbranch\u003e，而撤销修改则是git checkout -- \u003cfile\u003e，同一个命令，有两种作用，确实有点令人迷惑。 操作 version 2.23- version 2.23+ 切换分支 git branch dev git switch dev 新建并切换分支 git branch -b dev git switch -c dev ","date":"2022-03-23","objectID":"/git_glance/:3:11","tags":["git"],"title":"git 使用笔记","uri":"/git_glance/"},{"categories":["git"],"content":"git cherry-pick 在合并代码的时候，有两种情况： 需要另一个分支的所有代码变动，那么就采用合并git merge。 只需要部分代码变动（某几个提交），这时可以采用 cherry pick。 git cherry-pick \u003ccommid_1\u003e \u003ccommit_2\u003e ","date":"2022-03-23","objectID":"/git_glance/:3:12","tags":["git"],"title":"git 使用笔记","uri":"/git_glance/"},{"categories":["git"],"content":"git stash 新增的文件，直接执行 git stash 是不会被存储的，需要先执行 git add 把文件加到版本控制里。 文件在版本控制里，并不等于就被stash起来了，git add 和 git stash 没有必然的关系，但是执行 git stash 能正确存储的前提是文件必须在 git 版本控制中才行。 可以多次stash，恢复的时候，先用git stash list查看，然后恢复指定的stash。 cmd 说明 git stash save \"save message\" 执行存储时，添加备注，方便查找，只有git stash 也要可以的，但查找时不方便识别 git stash list 查看stash了哪些存储 git stash show 显示做了哪些改动，默认show第一个存储,如果要显示其他存贮，后面加 stash@{$num}，比如第二个 git stash show stash@{1} git stash show -p 显示第一个存储的改动，如果想显示其他存存储，命令：git stash show stash@{$num} -p ，比如第二个：git stash show stash@{1} -p git stash apply 应用某个存储，但不会把存储从存储列表中删除，默认使用第一个存储，即stash@{0}，如果要使用其他个，git stash apply stash@{$num} ， 比如第二个：git stash apply stash@{1} git stash pop 命令恢复之前缓存的工作目录，将缓存堆栈中的对应stash删除，并将对应修改应用到当前的工作目录下，默认为第一个stash，即stash@{0}，如果要应用并删除其他stash，命令：git stash pop stash@{$num} ，比如应用并删除第二个：git stash pop stash@{1} git stash drop stash@{$num} 丢弃stash@{$num}存储，从列表中删除这个存储 git stash clear 删除所有缓存的stash ","date":"2022-03-23","objectID":"/git_glance/:3:13","tags":["git"],"title":"git 使用笔记","uri":"/git_glance/"},{"categories":["git"],"content":"分支管理 HEAD严格来说不是指向提交，而是指向某个分支，如master分支，master才是指向提交的，所以，HEAD指向的就是当前分支。 HEADHEAD \" HEAD 在合并分支时如果出现冲突，Git用\u003c\u003c\u003c\u003c\u003c\u003c\u003c，=======，\u003e\u003e\u003e\u003e\u003e\u003e\u003e标记出不同分支的内容。 合并分支有冲突merge conflict \" 合并分支有冲突 ","date":"2022-03-23","objectID":"/git_glance/:4:0","tags":["git"],"title":"git 使用笔记","uri":"/git_glance/"},{"categories":["git"],"content":"Fast forward 通常，合并分支时，如果可能，git会用Fast forward模式，但这种模式下，删除分支后，会丢掉分支信息。 可以使用--no-ff强制禁用Fast forward模式，git就会在merge时生成一个新的commit，这样，从分支历史上就可以看出分支信息。 git merge --no-ffgit merge \u0026ndash;no-ff \" git merge --no-ff 因为本次合并要创建一个新的commit，所以加上-m参数，把commit描述写进去。 分支历史分支历史 \" 分支历史 ","date":"2022-03-23","objectID":"/git_glance/:4:1","tags":["git"],"title":"git 使用笔记","uri":"/git_glance/"},{"categories":["git"],"content":"标签Tag tag 是基于某个分支下的某次 commit。如只执行 git tag v1.0，那么标签是打在该分支最新提交的 commit 上的。 创建的标签都只存储在本地，不会自动推送到远程，打错的标签可以在本地安全删除。如果标签已经推送到远程，得先删除本地标签，再删除远程标签。 cmd 说明 git tag -a v0.1 -m \"version 0.1 released\" 1094adb 基于某次 commit 打 tag，-a指定标签名，-m指定说明文字 git show \u003ctagname\u003e 显示 tag 的说明文字 git tag 可以查看所有标签 git tag -d v0.1 删除标签 git push origin \u003ctagname\u003e 推送某个标签到远程，如：git push origin v1.0 git push origin --tags 一次性推送全部尚未推送到远程的本地标签 git push origin :refs/tags/\u003ctagname\u003e 删除一个远程标签 ","date":"2022-03-23","objectID":"/git_glance/:5:0","tags":["git"],"title":"git 使用笔记","uri":"/git_glance/"},{"categories":["git"],"content":"参考 git-fast-version-control Git教程 Git Cheat Sheet git cherry-pick 教程 git stash 用法总结和注意点 ","date":"2022-03-23","objectID":"/git_glance/:6:0","tags":["git"],"title":"git 使用笔记","uri":"/git_glance/"},{"categories":["开发者手册"],"content":"OAuth2.0,第三方登录,令牌,TOKEN,授权码,权限","date":"2022-03-22","objectID":"/oauth2.0/","tags":["web","oauth"],"title":"OAuth2.0的理解与应用","uri":"/oauth2.0/"},{"categories":["开发者手册"],"content":"什么是 OAuth2.0 OAuth 的核心就是向第三方应用颁发令牌，比如网站A想用Github的信息，那么对于Github来说，网站A就是第三方应用。 第三方应用申请令牌之前，都必须先到系统备案，比如申请Github的令牌，得先到github备案登记， 说明自己的身份，然后会拿到两个身份识别码：客户端 ID（client ID）和客户端密钥（client secret）。这是为了防止令牌被滥用，没有备案过的第三方应用，是不会拿到令牌的。 关于 OAuth2.0 是什么可以参考一下文章： OAuth 2.0 的一个简单解释 [简易图解]『 OAuth2.0』 『进阶』 授权模式总结 ","date":"2022-03-22","objectID":"/oauth2.0/:1:0","tags":["web","oauth"],"title":"OAuth2.0的理解与应用","uri":"/oauth2.0/"},{"categories":["开发者手册"],"content":"第三方登录Github 所谓第三方登录，实质就是 OAuth 授权。用户想要登录 A 网站，A 网站让用户提供第三方网站的数据，证明自己的身份。获取第三方网站的身份数据，就需要 OAuth 授权。 比如，A 网站允许 GitHub 登录，背后就是下面的流程： A 网站让用户跳转到 GitHub。 GitHub 要求用户登录，然后询问\"A 网站要求获得 xx 权限，你是否同意？\" 用户同意，GitHub 就会重定向回 A 网站，同时发回一个授权码。 A 网站使用授权码，向 GitHub 请求令牌。 GitHub 返回令牌. A 网站使用令牌，向 GitHub 请求用户数据。 ","date":"2022-03-22","objectID":"/oauth2.0/:2:0","tags":["web","oauth"],"title":"OAuth2.0的理解与应用","uri":"/oauth2.0/"},{"categories":["开发者手册"],"content":"注册 OAuth 应用 现在在 Github 上注册一个 OAuth 应用。 github注册oauth应用 \" 字段 描述 Application name 应用名称 Homepage URL 首页URL，如https://www.xiaobinqt.cn Authorization callback URL 用户在 Github 登录成功后重定向回的 URL 注册成功后会生成 Client ID 和 Client Secret，这两个是用来请求令牌的。 生成的Client信息 \" ","date":"2022-03-22","objectID":"/oauth2.0/:2:1","tags":["web","oauth"],"title":"OAuth2.0的理解与应用","uri":"/oauth2.0/"},{"categories":["开发者手册"],"content":"通过 OAuth 获取用户信息 前端界面 oauth.html \u003c!DOCTYPE html\u003e \u003chtml lang=\"en\"\u003e \u003chead\u003e \u003cmeta charset=\"UTF-8\"\u003e \u003ctitle\u003eTitle\u003c/title\u003e \u003c/head\u003e \u003cbody\u003e \u003ca href=\"https://github.com/login/oauth/authorize?client_id={{.ClientId}}\u0026redirect_uri={{.RedirectUrl}}\"\u003e Github 第三方授权登录\u003c/a\u003e \u003c/body\u003e \u003c/html\u003e go 代码通过OAuth获取用户信息 package main import ( \"encoding/json\" \"flag\" \"fmt\" \"html/template\" \"io/ioutil\" \"log\" \"net/http\" \"os\" ) var ( clientSecret = flag.String(\"cs\", \"\", \"github oauth client secret\") clientID = flag.String(\"ci\", \"\", \"github oauth client id\") ) type Conf struct { ClientId string ClientSecret string RedirectUrl string } type Token struct { AccessToken string `json:\"access_token\"` } // 认证并获取用户信息 func OAuth(w http.ResponseWriter, r *http.Request) { var ( err error ) // 获取 code code := r.URL.Query().Get(\"code\") // 通过 code, 获取 token var tokenAuthUrl = GetTokenAuthURL(code) var token *Token if token, err = GetToken(tokenAuthUrl); err != nil { fmt.Println(err) return } // 通过token，获取用户信息 var userInfo map[string]interface{} if userInfo, err = GetUserInfo(token); err != nil { fmt.Println(\"获取用户信息失败，错误信息为:\", err) return } // 将用户信息返回前端 var userInfoBytes []byte if userInfoBytes, err = json.Marshal(userInfo); err != nil { fmt.Println(\"在将用户信息(map)转为用户信息([]byte)时发生错误，错误信息为:\", err) return } w.Header().Set(\"Content-Type\", \"application/json\") if _, err = w.Write(userInfoBytes); err != nil { fmt.Println(\"在将用户信息([]byte)返回前端时发生错误，错误信息为:\", err) return } } // 通过code获取token认证url func GetTokenAuthURL(code string) string { return fmt.Sprintf( \"https://github.com/login/oauth/access_token?client_id=%s\u0026client_secret=%s\u0026code=%s\", *clientID, *clientSecret, code, ) } // 获取 token func GetToken(url string) (*Token, error) { // 形成请求 var req *http.Request var err error if req, err = http.NewRequest(http.MethodGet, url, nil); err != nil { return nil, err } req.Header.Set(\"accept\", \"application/json\") // 发送请求并获得响应 var ( httpClient = http.Client{} res *http.Response respBody = make([]byte, 0) token Token ) if res, err = httpClient.Do(req); err != nil { return nil, err } respBody, err = ioutil.ReadAll(res.Body) if err != nil { return nil, err } log.Printf(\"token: %s\", string(respBody)) // 将响应体解析为 token，并返回 err = json.Unmarshal(respBody, \u0026token) if err != nil { return nil, err } return \u0026token, nil } // 获取用户信息 func GetUserInfo(token *Token) (map[string]interface{}, error) { // 形成请求 var userInfoUrl = \"https://api.github.com/user\" // github用户信息获取接口 var req *http.Request var err error if req, err = http.NewRequest(http.MethodGet, userInfoUrl, nil); err != nil { return nil, err } req.Header.Set(\"accept\", \"application/json\") req.Header.Set(\"Authorization\", fmt.Sprintf(\"token %s\", token.AccessToken)) // 发送请求并获取响应 var client = http.Client{} var res *http.Response if res, err = client.Do(req); err != nil { return nil, err } // 将响应的数据写入 userInfo 中，并返回 var userInfo = make(map[string]interface{}) if err = json.NewDecoder(res.Body).Decode(\u0026userInfo); err != nil { return nil, err } return userInfo, nil } func Html(w http.ResponseWriter, r *http.Request) { // 解析指定文件生成模板对象 var ( temp *template.Template err error ) dir, _ := os.Getwd() if temp, err = template.ParseFiles(dir + \"/oauth.html\"); err != nil { fmt.Println(\"读取文件失败，错误信息为:\", err) return } // 利用给定数据渲染模板(html页面)，并将结果写入w，返回给前端 if err = temp.Execute(w, Conf{ ClientId: *clientID, ClientSecret: *clientSecret, RedirectUrl: \"http://127.0.0.1:9000/oauth/callback\", }); err != nil { fmt.Println(\"读取渲染html页面失败，错误信息为:\", err) return } } func UserInfo(w http.ResponseWriter, r *http.Request) { token := r.URL.Query().Get(\"token\") log.Printf(\"UserInfo token: %s\", token) var ( err error userInfo map[string]interface{} ) if userInfo, err = GetUserInfo(\u0026Token{AccessToken: token}); err != nil { fmt.Println(\"获取用户信息失败，错误信息为:\", err) return } // 将用户信息返回前端 var userInfoBytes []byte if userInfoBytes, err = json.Marshal(userInfo); err != nil { fmt.Println(\"在将用户信息(map)转为用户信息([]byte)时发生错误，错误信息为:\", err) return } w.Header().Set(\"Content-Type\", \"application/json\") if _, err = w.Write(u","date":"2022-03-22","objectID":"/oauth2.0/:2:2","tags":["web","oauth"],"title":"OAuth2.0的理解与应用","uri":"/oauth2.0/"},{"categories":["开发者手册"],"content":"效果 前端界面前端界面 \" 前端界面 授权页面授权页面 \" 授权页面 github返回的用户信息github返回的用户信息 \" github返回的用户信息 ","date":"2022-03-22","objectID":"/oauth2.0/:3:0","tags":["web","oauth"],"title":"OAuth2.0的理解与应用","uri":"/oauth2.0/"},{"categories":["开发者手册"],"content":"源码 源码地址 ","date":"2022-03-22","objectID":"/oauth2.0/:4:0","tags":["web","oauth"],"title":"OAuth2.0的理解与应用","uri":"/oauth2.0/"},{"categories":["开发者手册"],"content":"参考 Building OAuth Apps OAuth 2.0 的一个简单解释 Go语言实现第三方登录Github (通过OAuth2.0) basics of authentication [简易图解]『 OAuth2.0』 『进阶』 授权模式总结 ","date":"2022-03-22","objectID":"/oauth2.0/:5:0","tags":["web","oauth"],"title":"OAuth2.0的理解与应用","uri":"/oauth2.0/"},{"categories":["hugo"],"content":"HUGO,hugo主题标题支持emoji,emoji表情","date":"2022-03-21","objectID":"/hugo_title_support_emoji/","tags":["hugo","emoji"],"title":"hugo主题标题支持emoji:smile:","uri":"/hugo_title_support_emoji/"},{"categories":["hugo"],"content":"解决方法 hugo 在渲染时默认是不支持标题中的emoji的（有的主题也许是支持的），可以通过修改主题源码来支持。 我用的主题是LoveIt，找到 simple.html 文件，路径为 themes/LoveIt/layouts/posts/single.html 修改标题的渲染方式为 {{ .Title | emojify }}，如下： 修改主题的渲染方式 \" 这样就可以支持 emoji 了。 title support emoji \" 此时列表中还不支持 emoji，同样的修改方式。 list not support emoji \" 修改 themes/LoveIt/layouts/_default/summary.html 文件文件中的 title 的渲染方式为 {{ .Title | emojify }}。 ","date":"2022-03-21","objectID":"/hugo_title_support_emoji/:1:0","tags":["hugo","emoji"],"title":"hugo主题标题支持emoji:smile:","uri":"/hugo_title_support_emoji/"},{"categories":["hugo"],"content":"参考 Hugo should render emojis in page titles if enableEmoji = true ","date":"2022-03-21","objectID":"/hugo_title_support_emoji/:2:0","tags":["hugo","emoji"],"title":"hugo主题标题支持emoji:smile:","uri":"/hugo_title_support_emoji/"},{"categories":["理解计算机"],"content":"tcp, tcp连接管理,三次握手,四次挥手,为什么建立连接需要三次握手,为什么不能用两次握手进行连接,SYN,FIN,ACK,PSH,SYN_SENT,SYN_RECV,ESTABLISHED,FIN_WAIT_1,FIN_WAIT_2,CLOSE_WAIT,LAST_ACK,TIME_WAIT,CLOSE","date":"2022-03-21","objectID":"/tcp_handshark/","tags":["tcp"],"title":"TCP连接管理","uri":"/tcp_handshark/"},{"categories":["理解计算机"],"content":"名词解释 名词 解释 SYN 同步序号，用于建立连接过程，在连接请求中，SYN=1 和 ACK=0 表示该数据段没有使用捎带的确认域，而连接应答捎带一个确认，即 SYN=1 和 ACK=1 FIN finish 标志，用于释放连接，为 1 时表示发送方已经没有数据发送了，即关闭本方数据流 ACK 确认序号标志，为 1 时表示确认号有效，为 0 表示报文中不含确认信息，忽略确认号字段 PSH push 标志，为 1 表示是带有 push 标志的数据，指示接收方在接收到该报文段以后，应尽快将这个报文段交给应用程序，而不是在缓冲区排队 RST 重置连接标志，用于重置由于主机崩溃或其他原因而出现错误的连接。或者用于拒绝非法的报文段和拒绝连接请求 序列号 seq 占 4 个字节，用来标记数据段的顺序，TCP 把连接中发送的所有数据字节都编上一个序号，第一个字节的编号由本地随机产生；给字节编上序号后，就给每一个报文段指派一个序号；序列号 seq 就是这个报文段中的第一个字节的数据编号 确认号 ack 占 4 个字节，期待收到对方下一个报文段的第一个数据字节的序号；序列号表示报文段携带数据的第一个字节的编号；而确认号指的是期望接收到下一个字节的编号；因此当前报文段最后一个字节的编号 +1 （ACK会占一个序号）即为确认号 Info ACK、SYN 和 FIN 这些大写的单词表示标志位，其值要么是 1，要么是 0；ack、seq 小写的单词表示序号。 ACK 是可能与 SYN，FIN 等同时使用的。比如 SYN和ACK可能同时为 1，它表示的就是建立连接之后的响应搜索 如果只是单个的一个SYN，它表示的只是建立连接。 SYN与FIN是不会同时为 1 的，因为前者表示的是建立连接，而后者表示的是断开连接。 RST一般是在FIN之后才会出现为 1 的情况，表示的是连接重置。 一般，当出现FIN包或RST包时，便认为客户端与服务器端断开了连接；而当出现SYN和SYN＋ACK包时，我们认为客户端与服务器建立了一个连接。 PSH为 1 的情况，一般只出现在DATA内容不为 0 的包中，也就是说PSH为1表示的是有真正的 TCP 数据包内容被传递。 ","date":"2022-03-21","objectID":"/tcp_handshark/:1:0","tags":["tcp"],"title":"TCP连接管理","uri":"/tcp_handshark/"},{"categories":["理解计算机"],"content":"三次握手 三次握手三次握手 \" 三次握手 ","date":"2022-03-21","objectID":"/tcp_handshark/:2:0","tags":["tcp"],"title":"TCP连接管理","uri":"/tcp_handshark/"},{"categories":["理解计算机"],"content":"第一次握手 客户端 主动打开（active open），向服务端发送 SYN 报文段SYN=1, SN=client_isn, OPT=client_mss，请求建立连接。 client_isn 是客户端初始序号，动态生成，用于实现可靠传输，client_sn-client_isn 等于客户端已发送字节数。 SYN 报文段虽然不能携带数据，但是会消耗一个序号（相当于发送了1个字节的有效数据），下次客户端再向服务端发送的报文段中 SN=client_isn+1。 除了 SYN 报文段和 ACK-SYN 报文段，其他所有后续报文段的序号 SN 值都等于上次接收的 ACK 报文段中的确认号 AN 值。 client_mss 是客户端最大报文段长度，在 TCP 首部的选项和填充部分，会在客户端与服务端的 MSS 中选择一个较小值使用。 客户端变为 SYN_SENT 状态，然后等待服务端 ACK 报文段。 ","date":"2022-03-21","objectID":"/tcp_handshark/:2:1","tags":["tcp"],"title":"TCP连接管理","uri":"/tcp_handshark/"},{"categories":["理解计算机"],"content":"第二次握手 服务端 接收来自客户端的 SYN 报文段，得知客户端发送能力正常。 被动打开passive open，向客户端发送 SYN-ACK 报文段ACK=1, AN=client_isn+1, SYN=1, SN=server_isn, OPT=server_mss ，应答来自客户端的建立连接请求并向客户端发起建立连接请求。 SN=server_isn 是服务端初始序号，ACK-SYN 报文段虽然不能携带数据，但是会消耗一个序号（相当于发送了1个字节的有效数据），下次服务端再向客户端发送的报文中 SN=server_isn+1 。 OPT=server_mss 是服务端最大报文段长度。 AN=client_isn+1 是确认号，表明服务端接下来要开始接收来自客户端的第 client_isn+1 个字节的有效数据。 服务端变为 SYN_RCVD 状态，并等待客户端 ACK 报文段。 ","date":"2022-03-21","objectID":"/tcp_handshark/:2:2","tags":["tcp"],"title":"TCP连接管理","uri":"/tcp_handshark/"},{"categories":["理解计算机"],"content":"第三次握手 客户端 接收来自服务端的 SYN-ACK 报文段，得知服务端发送能力和接收能力都正常。 向客户端发送 ACK 报文段ACK=1, AN=server_isn+1, SN=client_isn+1, MESSAGE=message，应答来自服务端的建立连接请求。 SN=client_isn+1 是序号，表明当前报文段发送的有效数据首字节是从请求建立连接到现在为止客户端向服务端发送的第 (client_isn+1)-clien_isn+1=2 个字节的有效数据。 有效数据：一般有效数据指的是应用层的报文数据，不过 SYN 报文段、 ACK-SYN 报文段和 FIN 报文段虽然没有携带报文数据，但认为发送了1个字节的有效数据。 AN=server_isn+1 是确认号，表明客户端接下来要开始接收来自服务端的第 server_isn+1 个字节的有效数据。 MESSAGE=message 此时可以在报文段中携带客户端到服务端的报文数据；该 ACK 报文段消耗的序号个数等于 message_length（注意 message_length 可以等于0，即不携带有效数据，此时 ACK报文段不消耗序号），下次客户端再向服务端发送的报文段中 SN=client_isn+1+message_length 。 客户端变为 ESTABLISHED 状态，client——\u003eserver 数据流建立。 服务端 接收来自客户端的 ACK 报文段，得知客户端接收能力正常。 变为 ESTABLISHED 状态，server——\u003eclient 数据流也建立。 ","date":"2022-03-21","objectID":"/tcp_handshark/:2:3","tags":["tcp"],"title":"TCP连接管理","uri":"/tcp_handshark/"},{"categories":["理解计算机"],"content":"四次挥手 TCP四次挥手TCP四次挥手 \" TCP四次挥手 断开连接前，客户端和服务端都处于 ESTABLISHED 状态，两者谁都可以先发起断开连接请求。以下假设客户端先发起断开连接请求。 ","date":"2022-03-21","objectID":"/tcp_handshark/:3:0","tags":["tcp"],"title":"TCP连接管理","uri":"/tcp_handshark/"},{"categories":["理解计算机"],"content":"第一次挥手 客户端 向服务端发送 FIN 报文段FIN=1, SN=client_sn，请求断开连接。 SN=client_sn是序号，表明当前报文段发送的有效数据首字节是从请求建立连接到现在为止客户端向服务端发送的第 client_sn-clien_isn+1 个字节的有效数据。 FIN 报文段虽然不能携带数据，但是会消耗一个序号（相当于发送了1个字节的有效数据），下次客户端再向服务端发送的报文中 SN=client_isn+1 。 客户端变为 FIN_WAIT1 状态，等待服务端 ACK 报文段。 ","date":"2022-03-21","objectID":"/tcp_handshark/:3:1","tags":["tcp"],"title":"TCP连接管理","uri":"/tcp_handshark/"},{"categories":["理解计算机"],"content":"第二次挥手 服务端 接收来自客户端的 FIN 报文段。 向客户端发送 ACK 报文段ACK=1, AN=client_sn+1, SN=server_sn_wave2，应答客户端的断开连接请求。 SN=server_sn_wave2 是序号，表明当前报文段发送的有效数据首字节是从请求建立连接到现在为止服务端向客户端发送的第 server_sn_wave2-client_isn+1 个字节的有效数据。 AN=client_sn+1 是确认号，表明服务端接下来要开始接收来自客户端的第 client_sn+1 个字节的有效数据。 此时服务端变为 CLOSE_WAIT 状态。 客户端 接收来自服务端的 ACK 包。 变为 FIN_WAIT2 状态，等待服务端关闭连接请求FIN报文段。 ","date":"2022-03-21","objectID":"/tcp_handshark/:3:2","tags":["tcp"],"title":"TCP连接管理","uri":"/tcp_handshark/"},{"categories":["理解计算机"],"content":"第三次挥手 服务端 （服务端想断开连接时）向客户端发送 FIN 报文段FIN=1, SN=server_sn，请求断开连接。 SN=server_sn 是序号，表明当前报文段发送的有效数据首字节是从请求建立连接到现在为止服务端向客户端发送的第 server_sn-clien_isn+1 个字节的有效数据。 FIN 报文段虽然不能携带数据，但是会消耗一个序号（相当于发送了1个字节的有效数据），下次服务端再向客户端发送的报文中 SN=client_isn+2 （若断开连接成功，则服务端不会再向客户端发送下一个报文段）。 第二次挥手和第三次挥手之间，服务端又向客户端发送了 server_sn - server_sn_wave2 个字节的有效数据。 服务端变为 LAST_ACK 状态，等待客户端的 ACK 报文段。 ","date":"2022-03-21","objectID":"/tcp_handshark/:3:3","tags":["tcp"],"title":"TCP连接管理","uri":"/tcp_handshark/"},{"categories":["理解计算机"],"content":"第四次挥手 客户端 接收来自服务端的 FIN 报文段。 向服务端发送 ACK 报文段ACK=1, AN=server_sn+1, SN=client_sn+1，应答服务端断开连接请求。 client_sn+1 是序号，表明当前报文段发送的有效数据首字节是从请求建立连接到现在为止客户端向客户端发送的第 client_isn+1)-clien_isn+1 个字节的有效数据。AN=server_sn+1 是确认号，表明服务端接下来要开始接收来自客户端的第 client_sn+1 个字节的有效数据。 客户端变为 TIME_WAIT 状态，等待2MSL时间后进入 CLOSED 状态，至此 client——\u003eserver 数据流被关闭。 服务端 接收来自客户端的 ACK 报文段。 变为 CLOSED 状态，至此 server——\u003eclient 数据流被关闭。 Tips 当收到对方的FIN报文时，仅仅表示对方不再发送数据了但是还能接收数据。 ","date":"2022-03-21","objectID":"/tcp_handshark/:3:4","tags":["tcp"],"title":"TCP连接管理","uri":"/tcp_handshark/"},{"categories":["理解计算机"],"content":"常见问题 ❓ 为什么建立连接需要“三次”握手 客户端和服务端之间建立的TCP是全双工通信，双方都要确保对方发送能力和接收能力正常。 一次握手后，服务端得知客户端发送能力正常。 二次握手后，客户端得知服务端接收能力和发送能力正常。 三次握手后，服务端得知客户端接收能力正常。 ❓ 为什么第四次挥手时要等待2MSL的时间再进入CLOSED状态 MSL（Maximum Segment Lifetime，报文段最大生存时间）是一个未被接受的报文段在网络中被丢弃前存活的最大时间。 保证建立新连接时网络中不存在上次连接时发送的数据包，进入 CLOSED 状态意味着可以建立新连接，等待 \u003eMSL 的时间再进入 CLOSED 状态可以保证建立新连接后，网络中不会存在上次连接时发送出去的数据包。若网络中同时存在发送端在两次连接中发出的数据包，对接收端接收数据可能会有影响。 保证第四次挥手发送的 ACK 能到达接收端，第四次挥手发送的 ACK 可能会出现丢包，另一端接收不到 ACK 会重新发送 FIN。等待 2MSL 的时间可以应对该情况，重发 ACK ，保证另一端能正常关闭连接。 ❓ 已经建立了连接，客户端突然出现故障怎么办 TCP 设有一个保活计时器，客户端如果出现故障，服务器不能一直等下去，白白浪费资源。服务器每收到一次客户端的请求后都会重新复位这个计时器，时间通常是设置为 2 小时，若两小时还没有收到客户端的任何数据，服务器就会发送一个探测报文段，以后每隔 75 秒钟发送一次。若一连发送 10 个探测报文仍然没反应， 服务器就认为客户端出了故障，接着就关闭连接。 ❓ 为什么不能用两次握手进行连接 三次握手完成两个重要的功能，既要双方做好发送数据的准备工作（双方都知道彼此已准备好），也要允许双方就初始序列号进行协商，这个序列号在握手过程中被发送和确认。 现在把三次握手改成仅需要两次握手，死锁是可能发生的。 比如，计算机 S 和 C 之间的通信，假定 C 给 S 发送一个连接请求分组，S 收到了这个分组，并发送了确认应答分组。按照两次握手的协定，S 认为连接已经成功地建立了，可以开始发送数据分组。 可是，C 在 S 的应答分组在传输中被丢失的情况下，将不知道 S 是否已准备好，不知道 S 建立什么样的序列号，C 甚至怀疑 S 是否收到自己的连接请求分组。在这种情况下，C 认为连接还未建立成功，将忽略 S 发来的任何数据分 组，只等待连接确认应答分组，而 S 在发出的分组超时后，重复发送同样的分组，这样就形成了死锁。 ","date":"2022-03-21","objectID":"/tcp_handshark/:4:0","tags":["tcp"],"title":"TCP连接管理","uri":"/tcp_handshark/"},{"categories":["理解计算机"],"content":"参考 计算机网络——TCP连接管理（三次握手和四次挥手） “三次握手，四次挥手”你真的懂吗？ TCP的三次握手与四次挥手理解及面试题（很全面） TCP报文格式详解 面试官，不要再问我三次握手和四次挥手 ","date":"2022-03-21","objectID":"/tcp_handshark/:5:0","tags":["tcp"],"title":"TCP连接管理","uri":"/tcp_handshark/"},{"categories":[""],"content":"前小端 ","date":"2022-03-19","objectID":"/links/:1:0","tags":[""],"title":"友情链接","uri":"/links/"},{"categories":[""],"content":"MakerLi ","date":"2022-03-19","objectID":"/links/:2:0","tags":[""],"title":"友情链接","uri":"/links/"},{"categories":[""],"content":"西瓜 ","date":"2022-03-19","objectID":"/links/:3:0","tags":[""],"title":"友情链接","uri":"/links/"},{"categories":[""],"content":"liupray ","date":"2022-03-19","objectID":"/links/:4:0","tags":[""],"title":"友情链接","uri":"/links/"},{"categories":[""],"content":"xiaowuneng ","date":"2022-03-19","objectID":"/links/:5:0","tags":[""],"title":"友情链接","uri":"/links/"},{"categories":["web"],"content":"执行模式 JS的执行模式是单线程的，当有多个任务时必须排队执行，优点是执行环境简单，缺点是性能低下，当有多个任务时，需要等待上一个任务执行完成才能执行下一个任务， 如果某个任务出现了死循环，那么就会导致程序崩溃。 所以JS出现了同步和异步的概念。 ","date":"2022-03-18","objectID":"/js_cb_asyn/:1:0","tags":["js"],"title":"JS运行机制","uri":"/js_cb_asyn/"},{"categories":["web"],"content":"同步 后一个任务等待前一个任务结束，然后再执行，程序的执行顺序与任务的排列顺序是一致的。 ","date":"2022-03-18","objectID":"/js_cb_asyn/:1:1","tags":["js"],"title":"JS运行机制","uri":"/js_cb_asyn/"},{"categories":["web"],"content":"异步 每一个任务有一个或多个回调函数（callback），前一个任务结束后，不是执行后一个任务，而是执行回调函数，后一个任务则是不等前一个任务结束就执行，所以程序的执行顺序与任务的排列顺序可能是不一致的。 ","date":"2022-03-18","objectID":"/js_cb_asyn/:1:2","tags":["js"],"title":"JS运行机制","uri":"/js_cb_asyn/"},{"categories":["web"],"content":"Event Loop // TODO ","date":"2022-03-18","objectID":"/js_cb_asyn/:2:0","tags":["js"],"title":"JS运行机制","uri":"/js_cb_asyn/"},{"categories":["web"],"content":"Promise Promise 对象代表一个异步操作，then() 第一个参数是成功resolve的回调函数，第二个参数是失败reject的回调函数，当不写第二个 then() 参数时，可以用 catch() 捕获 reject 异常。 ","date":"2022-03-18","objectID":"/js_cb_asyn/:3:0","tags":["js"],"title":"JS运行机制","uri":"/js_cb_asyn/"},{"categories":["web"],"content":"使用 var p1 = new Promise(function (resolve, reject) { // resolve('成功'); reject(\"失败\") }); p1.then(function (res) { console.log(\"第一个fn: \", res) }, function (res) { console.log(\"第二个 fn: \", res) }); resolve和reject除了正常的值外，还可能是另一个promise实例。 const p1 = new Promise(function (resolve, reject) { resolve(1) }); const p2 = new Promise(function (resolve, reject) { // ... resolve(p1); }) p2.then(function (res) { console.log(res) }, function (res) { }) 用 catch 捕获 reject 异常 var p1 = new Promise(function (resolve, reject) { // todo... reject(111111) }); p1.then(function (res) { console.log(\"第一个fn: \", res) }).catch(function (err) { console.log(\"err :\", err) }).finally(function () { console.log(\"finally exec...\") }) ","date":"2022-03-18","objectID":"/js_cb_asyn/:3:1","tags":["js"],"title":"JS运行机制","uri":"/js_cb_asyn/"},{"categories":["web"],"content":"执行顺序 ","date":"2022-03-18","objectID":"/js_cb_asyn/:3:2","tags":["js"],"title":"JS运行机制","uri":"/js_cb_asyn/"},{"categories":["web"],"content":"async/await的用法和理解 async 函数是非常新的语法功能，在 ES7 中可用。 async 函数返回一个 Promise 对象，可以使用 then 方法添加回调函数。await 作为修饰符，只能放在 async 内部使用。 当函数执行的时候，一旦遇到 await 就会先返回，等到触发的异步操作完成，再接着执行函数体内后面的语句。 await 等待右侧表达式的结果。 如果等到的不是一个 promise 对象，那 await 表达式的运算结果就是它等到的东西。 如果它等到的是一个 promise 对象，它会阻塞后面的代码，等着 promise 对象 resolve，然后得到 resolve 的值，作为 await 表达式的运算结果。 async function test() { let promise = new Promise(resolve =\u003e { setTimeout(() =\u003e resolve(\"test\"), 2000); }); await promise.then((ret) =\u003e { console.log(ret) }) let test1Ret = await test1() console.log(test1Ret) console.log(\"test end...\") } function test1() { return \"test1_return\" } test(); console.log('end') 运行结果 \" ","date":"2022-03-18","objectID":"/js_cb_asyn/:4:0","tags":["js"],"title":"JS运行机制","uri":"/js_cb_asyn/"},{"categories":["web"],"content":"宏任务和微任务 // TODO ","date":"2022-03-18","objectID":"/js_cb_asyn/:5:0","tags":["js"],"title":"JS运行机制","uri":"/js_cb_asyn/"},{"categories":["web"],"content":"参考 Javascript异步编程的4种方法 JavaScript 运行机制详解：再谈Event Loop async 函数的含义和用法 JS执行——Promise 你真的了解回调? 回调地狱 js中微任务和宏任务的区别 ","date":"2022-03-18","objectID":"/js_cb_asyn/:6:0","tags":["js"],"title":"JS运行机制","uri":"/js_cb_asyn/"},{"categories":["理解计算机"],"content":"HTTP,HTTP协议,超文本传输协议,互联网,TCP/IP,Transmission Control Protocol,传输控制协议,ISO","date":"2022-03-17","objectID":"/http_glance/","tags":["http"],"title":"http入门笔记","uri":"/http_glance/"},{"categories":["理解计算机"],"content":"该笔记是在学习《透视 HTTP 协议》时整理，还参考了网上的其他资料。鄙人只是网络世界的搬运整理工😂。 ","date":"2022-03-17","objectID":"/http_glance/:0:0","tags":["http"],"title":"http入门笔记","uri":"/http_glance/"},{"categories":["理解计算机"],"content":"总览 http总览 \" ","date":"2022-03-17","objectID":"/http_glance/:1:0","tags":["http"],"title":"http入门笔记","uri":"/http_glance/"},{"categories":["理解计算机"],"content":"http 协议 http（超文本传输协议）是一个用在计算机世界里的协议。它使用计算机能够理解的语言确立了一种计算机之间交流通信的规范，以及相关的各种控制和错误处理方式。 http 是一个在计算机世界里专门在两点之间传输文字、图片、音频、视频等超文本数据的约定和规范。 http 不是编程语言，但是可以用编程语言去实现 HTTP，告诉计算机如何用 HTTP 来与外界通信。 在互联网世界里，HTTP 通常跑在 TCP/IP 协议栈之上，依靠 IP 协议实现寻址和路由、TCP 协议实现可靠数据传输、DNS 协议实现域名查找、SSL/TLS 协议实现安全通信。此外，还有一些协议依赖于 HTTP，例如 WebSocket、HTTPDNS 等。这些协议相互交织，构成了一个协议网，而 HTTP 则处于中心地位。 HTTP 传输的不是 TCP/UDP 这些底层协议里被切分的杂乱无章的二进制包（datagram），而是完整的、有意义的数据，可以被浏览器、服务器这样的上层应用程序处理。 ","date":"2022-03-17","objectID":"/http_glance/:2:0","tags":["http"],"title":"http入门笔记","uri":"/http_glance/"},{"categories":["理解计算机"],"content":"互联网和万维网的区别 我们通常所说的“上网”实际上访问的只是互联网的一个子集“万维网”（World Wide Web），它基于 HTTP 协议，传输 HTML 等超文本资源，能力被限制在 HTTP 协议之内。 互联网上还有许多万维网之外的资源，例如常用的电子邮件、BT 和 Magnet 点对点下载、FTP 文件下载、SSH 安全登录、各种即时通信服务等等，它们需要用各自的专有协议来访问。 不过由于 HTTP 协议非常灵活、易于扩展，而且“超文本”的表述能力很强，所以很多其他原本不属于 HTTP 的资源也可以“包装”成 HTTP 来访问，这就是我们为什么能够总看到各种“网页应用”——例如“微信网页版”“邮箱网页版”——的原因。 ","date":"2022-03-17","objectID":"/http_glance/:2:1","tags":["http"],"title":"http入门笔记","uri":"/http_glance/"},{"categories":["理解计算机"],"content":"TCP/IP TCP/IP 协议实际上是一系列网络通信协议的统称， 其中最核心的两个协议是TCP（Transmission Control Protocol/传输控制协议）和IP（Internet Protocol），其他的还有 UDP、ICMP、ARP 等等，共同构成了一个复杂但有层次的协议栈。 HTTP 是超文本传输协议，TCP 是传输控制协议，都是传输，区别是，HTTP 传输的是完整的、有意义的数据，可以被浏览器、 服务器这样的上层应用程序处理，HTTP 不关心寻址、路由、数据完整性等传输细节，而要求这些工作都由下层（基本都由 TCP）来处理。 TCP 传输的是可靠的、字节流和二进制包。 TCP 是 HTTP 得以实现的基础，HTTP 协议运行在 TCP/IP 上，HTTP 可以更准确地称为 “HTTP over TCP/IP”。 ","date":"2022-03-17","objectID":"/http_glance/:2:2","tags":["http"],"title":"http入门笔记","uri":"/http_glance/"},{"categories":["理解计算机"],"content":"URI/URL URI（Uniform Resource Identifier），中文名称是 统一资源标识符，使用它就能够唯一地标记互联网上资源。 URI 另一个更常用的表现形式是 URL（Uniform Resource Locator）， 统一资源定位符，也就是我们俗称的“网址”，它实际上是 URI 的一个子集，这两者几乎是相同的，差异不大，除非写论文，否则不用特意区分。 ","date":"2022-03-17","objectID":"/http_glance/:2:3","tags":["http"],"title":"http入门笔记","uri":"/http_glance/"},{"categories":["理解计算机"],"content":"SSL/TSL SSL 的全称是“Secure Socket Layer”，网景公司发明，当发展到 3.0 时被标准化，改名为 TLS，即“Transport Layer Security”。 所以 TLS 跟 SSL 是一个东西，相当于张君宝的 2.0 版本是张三丰。 SSL 是一个负责加密通信的安全协议，建立在 TCP/IP 之上，在 HTTP 协议之下。 ","date":"2022-03-17","objectID":"/http_glance/:2:4","tags":["http"],"title":"http入门笔记","uri":"/http_glance/"},{"categories":["理解计算机"],"content":"Proxy 代理 匿名代理：完全“隐匿”了被代理的机器，外界看到的只是代理服务器； 透明代理：顾名思义，它在传输过程中是“透明开放”的，外界既知道代理，也知道客户端； 正向代理：靠近客户端，代表客户端向服务器发送请求； 正向代理正向代理 \" 正向代理 反向代理：靠近服务器端，代表服务器响应客户端的请求； 反向代理反向代理 \" 反向代理 Tip 如何理解反向代理服务器 ","date":"2022-03-17","objectID":"/http_glance/:2:5","tags":["http"],"title":"http入门笔记","uri":"/http_glance/"},{"categories":["理解计算机"],"content":"http 版本 万维网关键技术 URI：即统一资源标识符，作为互联网上资源的唯一身份； HTML：即超文本标记语言，描述超文本文档； HTTP：即超文本传输协议，用来传输超文本。 基于这三项关键技术就可以把超文本系统完美地运行在互联网上，让各地的人们能够自由地共享信息，这个系统称为“万维网”（World Wide Web），也就是我们现在所熟知的 Web。 ","date":"2022-03-17","objectID":"/http_glance/:3:0","tags":["http"],"title":"http入门笔记","uri":"/http_glance/"},{"categories":["理解计算机"],"content":"http/0.9 结构简单，设置之初设想系统里的文档都是只读的，所以只允许用 GET 动作从服务器上获取 HTML 纯文本格式的文档，并且在响应请求之后立即关闭连接，功能非常有限。 ","date":"2022-03-17","objectID":"/http_glance/:3:1","tags":["http"],"title":"http入门笔记","uri":"/http_glance/"},{"categories":["理解计算机"],"content":"http/1.0 HTTP/1.0 并不是一个标准，只是记录已有实践和模式的一份参考文档，不具有实际的约束力，相当于一个备忘录。 在多方面增强了 0.9 版，形式上已经和我们现在的 HTTP 差别不大了，例如： 增加了 HEAD、POST 等新方法； 增加了响应状态码，标记可能的错误原因； 引入了协议版本号概念； 引入了 HTTP Header（头部）的概念，让 HTTP 处理请求和响应更加灵活； 传输的数据不再仅限于文本。 ","date":"2022-03-17","objectID":"/http_glance/:3:2","tags":["http"],"title":"http入门笔记","uri":"/http_glance/"},{"categories":["理解计算机"],"content":"http/1.1 是一个正式的标准，而不是一份可有可无的参考文档，只要用到 HTTP 协议，就必须严格遵守这个标准。 主要变更： 增加了 PUT、DELETE 等新的方法； 增加了缓存管理和控制； 明确了连接管理，允许持久连接； 允许响应数据分块（chunked），利于传输大文件； 强制要求 Host 头，让互联网主机托管成为可能。 ","date":"2022-03-17","objectID":"/http_glance/:3:3","tags":["http"],"title":"http入门笔记","uri":"/http_glance/"},{"categories":["理解计算机"],"content":"http/2 由 google 主导，基于 google 的 SPDY 协议为基础开始制定新版本的 HTTP 协议，最终在 2015 年发布了 HTTP/2。 主要特点： 二进制协议，不再是纯文本； 可发起多个请求，废弃了 1.1 里的管道； 使用专用算法压缩头部，减少数据传输量； 允许服务器主动向客户端推送数据； 增强了安全性，“事实上”要求加密通信。 ","date":"2022-03-17","objectID":"/http_glance/:3:4","tags":["http"],"title":"http入门笔记","uri":"/http_glance/"},{"categories":["理解计算机"],"content":"http/3 由 google 主导，基于 google 的 QUIC 协议为基础开始制定新版本的 HTTP 协议。 ","date":"2022-03-17","objectID":"/http_glance/:3:5","tags":["http"],"title":"http入门笔记","uri":"/http_glance/"},{"categories":["理解计算机"],"content":"网络分层模型 ","date":"2022-03-17","objectID":"/http_glance/:4:0","tags":["http"],"title":"http入门笔记","uri":"/http_glance/"},{"categories":["理解计算机"],"content":"TCP/IP TCP/IP分层模型tcp/ip分层模型 \" TCP/IP分层模型 这里的层次顺序是“从下往上”数的，所以第一层就是最下面的一层。 链接层 第一层叫“链接层”（link layer），负责在以太网、WiFi 这样的底层网络上发送原始数据包，工作在网卡这个层次，使用 MAC 地址来标记网络上的设备，所以有时候也叫 MAC 层。 网络互联层 第二层叫“网际层”或者“网络互连层”（internet layer），IP 协议就处在这一层。因为 IP 协议定义了“IP 地址”的概念，所以就可以在“链接层”的基础上，用 IP 地址取代 MAC 地址，把许许多多的局域网、广域网连接成一个虚拟的巨大网络，在这个网络里找设备时只要把 IP 地址再“翻译”成 MAC 地址就可以了。 传输层 第三层叫“传输层”（transport layer），这个层次协议的职责是保证数据在 IP 地址标记的两点之间“可靠”地传输，是 TCP 协议工作的层次，另外还有它的一个“小伙伴”UDP。 TCP 是一个有状态的协议，需要先与对方建立连接然后才能发送数据，而且保证数据不丢失不重复。而 UDP 则比较简单，它无状态，不用事先建立连接就可以任意发送数据，但不保证数据一定会发到对方。两个协议的另一个重要区别在于数据的形式。TCP 的数据是连续的“字节流”，有先后顺序，而 UDP 则是分散的小数据包，是顺序发，乱序收。 应用层 协议栈的第四层叫“应用层”（application layer），由于下面的三层把基础打得非常好，所以在这一层就“百花齐放”了，有各种面向具体应用的协议。例如 Telnet、SSH、FTP、SMTP，HTTP 等等。 Tip MAC 层（链接层）的传输单位是帧（frame），IP 层（网络互联层）的传输单位是包（packet），TCP 层传输层的传输单位是段（segment）， HTTP （应用层）的传输单位则是消息或报文（message）。这些名词并没有什么本质的区分，可以统称为数据包。 ","date":"2022-03-17","objectID":"/http_glance/:4:1","tags":["http"],"title":"http入门笔记","uri":"/http_glance/"},{"categories":["理解计算机"],"content":"OSI 网络分层模型 OSI 分层模型在发布的时候就明确地表明是一个“参考”，不是强制标准。这是因为 TCP/IP 等协议已经在许多网络上实际运行，不可能推翻重来。 OSI网络模型OSI模型 \" OSI网络模型 第一层：物理层，网络的物理形式，例如电缆、光纤、网卡、集线器等等； 第二层：数据链路层，它基本相当于 TCP/IP 的链接层； 第三层：网络层，相当于 TCP/IP 里的网际层； 第四层：传输层，相当于 TCP/IP 里的传输层； 第五层：会话层，维护网络中的连接状态，即保持会话和同步； 第六层：表示层，把数据转换为合适、可理解的语法和语义； 第七层：应用层，面向具体的应用传输数据。 对比一下就可以发现，TCP/IP 是一个纯软件的栈，没有网络应有的最根基的电缆、网卡等物理设备的位置。而 OSI 则补足了这个缺失， 在理论层面上描述网络更加完整。 OSI 还为每一层标记了明确了编号，最底层是一层，最上层是七层，而 TCP/IP 的层次从来只有名字而没有编号。 ","date":"2022-03-17","objectID":"/http_glance/:4:2","tags":["http"],"title":"http入门笔记","uri":"/http_glance/"},{"categories":["理解计算机"],"content":"两个分层模型的对应关系 两个分层模型的对应关系对应关系 \" 两个分层模型的对应关系 所谓的“四层负载均衡”就是指工作在传输层上，基于 TCP/IP 协议的特性，例如 IP 地址、端口号等实现对后端服务器的负载均衡。 所谓的“七层负载均衡”就是指工作在应用层上，看到的是 HTTP 协议，解析 HTTP 报文里的 URI、主机名、资源类型等数据，再用适当的策略转发给后端服务器。 有一个辨别四层和七层比较好的（但不是绝对的）小窍门，“两个凡是”：凡是由操作系统负责处理的就是四层或四层以下，否则，凡是需要由应用程序（也就是你自己写代码）负责处理的就是七层。 ","date":"2022-03-17","objectID":"/http_glance/:4:3","tags":["http"],"title":"http入门笔记","uri":"/http_glance/"},{"categories":["理解计算机"],"content":"http协议核心 由于 HTTP 是在 TCP/IP 协议之上的，而 TCP/IP 协议负责底层的具体传输工作，所以 http 在传输方面不用太操心，TCP/IP 会去解决，所以 HTTP 关心的就只有他所传输的报文内容，又因为 HTTP 是“纯文本”的，包括头信息都是 ASCII 码的文本，不用借助程序解析可以直接阅读。 http报文 \" ","date":"2022-03-17","objectID":"/http_glance/:5:0","tags":["http"],"title":"http入门笔记","uri":"/http_glance/"},{"categories":["理解计算机"],"content":"常用头字段 注意事项 字段名不区分大小写，例如“Host”也可以写成“host”，但首字母大写的可读性更好； 字段名里不允许出现空格，可以使用连字符“-”，但不能使用下划线“_”。例如，“test-name”是合法的字段名，而“test name”“test_name”是不正确的字段名； 字段名后面必须紧接着“:”，不能有空格，而“:”后的字段值前可以有多个空格； 分类 通用字段：在请求头和响应头里都可以出现； 请求字段：仅能出现在请求头里，进一步说明请求信息或者额外的附加条件； 响应字段：仅能出现在响应头里，补充说明响应报文的信息； 实体字段：它实际上属于通用字段，但专门描述 body 的额外信息。 字段 类型 说明 Host 请求字段 唯一一个 HTTP/1.1 规范里要求必须出现的字段，如果请求头里没有 Host，那这就是一个错误的报文。Host 字段告诉服务器这个请求应该由哪个主机来处理 User-Agent 请求字段 描述发起 HTTP 请求的客户端，服务器可以依据它来返回最合适此浏览器显示的页面 Date 通用字段 表示 HTTP 报文创建的时间，客户端可以使用这个时间再搭配其他字段决定缓存策略 Server 响应字段 告诉客户端当前正在提供 Web 服务的软件名称和版本号 Content-Length 实体字段 报文里 body 的长度，也就是请求头或响应头空行后面数据的长度。服务器看到这个字段，就知道了后续有多少数据，可以直接接收。如果没有这个字段，那么 body 就是不定长的，需要使用 chunked 方式分段传输 ","date":"2022-03-17","objectID":"/http_glance/:5:1","tags":["http"],"title":"http入门笔记","uri":"/http_glance/"},{"categories":["理解计算机"],"content":"请求方式 请求方式 \" 方式 说明 GET 获取资源，可以理解为读取或者下载数据 HEAD 获取资源的元信息，不会返回请求的实体数据，只会传回响应头 POST 向资源提交数据，相当于写入或上传数据 PUT 类似 POST DELETE 删除资源 CONNECT 建立特殊的连接隧道 OPTIONS 列出可对资源实行的方法 TRACE 追踪请求 - 响应的传输路径 ","date":"2022-03-17","objectID":"/http_glance/:5:2","tags":["http"],"title":"http入门笔记","uri":"/http_glance/"},{"categories":["理解计算机"],"content":"状态码 状态码 含义 1×x 提示信息，表示目前是协议处理的中间状态，还需要后续的操作 2×× 成功，报文已经收到并被正确处理 3×× 重定向，资源位置发生变动，需要客户端重新发送请求 4×× 客户端错误，请求报文有误，服务器无法处理 5×× 服务器错误，服务器在处理请求时内部发生了错误 一些常用状态码说明 status code 说明 301 永久重定向，含义是此次请求的资源已经不存在了，需要改用改用新的 URI 再次访问 302 临时重定向，意思是请求的资源还在，但需要暂时用另一个 URI 来访问。比如，你的网站升级到了 HTTPS，原来的 HTTP 不打算用了，这就是“永久”的，所以要配置 301 跳转，把所有的 HTTP 流量都切换到 HTTPS。 再比如，今天夜里网站后台要系统维护，服务暂时不可用，这就属于“临时”的，可以配置成 302 跳转，把流量临时切换到一个静态通知页面，浏览器看到这个 302 就知道这只是暂时的情况，不会做缓存优化，第二天还会访问原来的地址。 304 Not Modified，它用于 If-Modified-Since 等条件请求，表示资源未修改，用于缓存控制。它不具有通常的跳转含义，但可以理解成“重定向已到缓存的文件”（即“缓存重定向”） 405 不允许使用某些方法操作资源，例如不允许 POST 只能 GET 406 Not Acceptable 资源无法满足客户端请求的条件，例如请求中文但只有英文 408 Request Timeout：请求超时，服务器等待了过长的时间 409 Conflict：多个请求发生了冲突，可以理解为多线程并发时的竞态 413 Request Entity Too Large：请求报文里的 body 太大 414 Request-URI Too Long：请求行里的 URI 太大 429 Too Many Requests 客户端发送了太多的请求，通常是由于服务器的限连策略 431 Request Header Fields Too Large 请求头某个字段或总体太大 500 Internal Server Error 与 400 类似，也是一个通用的错误码，服务器究竟发生了什么错误我们是不知道的。不过对于服务器来说这应该算是好事，通常不应该把服务器内部的详细信息，例如出错的函数调用栈告诉外界。虽然不利于调试，但能够防止黑客的窥探或者分析 501 Not Implemented 表示客户端请求的功能还不支持，这个错误码比 500 要温和一些，和“即将开业，敬请期待”的意思差不多，不过具体什么时候“开业”就不好说了 502 Bad Gateway”通常是服务器作为网关或者代理时返回的错误码，表示服务器自身工作正常，访问后端服务器时发生了错误，但具体的错误原因也是不知道的 503 Service Unavailable 表示服务器当前很忙，暂时无法响应服务，我们上网时有时候遇到的“网络服务正忙，请稍后重试”的提示信息就是状态码 503 ","date":"2022-03-17","objectID":"/http_glance/:5:3","tags":["http"],"title":"http入门笔记","uri":"/http_glance/"},{"categories":["golang"],"content":"进程、线程、协程的区别 ","date":"2022-03-16","objectID":"/gmp_model/:1:0","tags":["golang"],"title":"go GMP 模型","uri":"/gmp_model/"},{"categories":["golang"],"content":"协程的上下文切换比线程的上下文切换代价小 ","date":"2022-03-16","objectID":"/gmp_model/:2:0","tags":["golang"],"title":"go GMP 模型","uri":"/gmp_model/"},{"categories":["golang"],"content":"go 调度器机制 ","date":"2022-03-16","objectID":"/gmp_model/:3:0","tags":["golang"],"title":"go GMP 模型","uri":"/gmp_model/"},{"categories":["golang"],"content":"知识点 Go程序中没有语言级的关键字让你去创建一个内核线程，你只能创建 goroutine，内核线程只能由 runtime 根据实际情况去创建。 Go运行时系统并没有内核调度器的中断能力，内核调度器会发起抢占式调度将长期运行的线程中断并让出CPU资源，让其他线程获得执行机会。 ","date":"2022-03-16","objectID":"/gmp_model/:3:1","tags":["golang"],"title":"go GMP 模型","uri":"/gmp_model/"},{"categories":["golang"],"content":"参考 Go 为什么这么“快” 让你很快就能理解-go的协程调度原理 Golang goroutine与调度器 Go语言的并发模型 ","date":"2022-03-16","objectID":"/gmp_model/:4:0","tags":["golang"],"title":"go GMP 模型","uri":"/gmp_model/"},{"categories":["golang"],"content":"go build 常用命令","date":"2022-03-16","objectID":"/go_build_args/","tags":["golang"],"title":"go 常用命令","uri":"/go_build_args/"},{"categories":["golang"],"content":"常用编译参数 参数 说明 -o 指定输出可执行文件名 -v 编译时显示包名，可以理解成输出详细编译信息 -race 开启竞态检测 *.go 编译当前目录下的所有go文件，也可以写成 f2.go f2.go … -a 强制重新构建 -w 去掉DWARF调试信息，得到的程序就不能用gdb调试了 -s 去掉符号表,panic时候的stack trace就没有任何文件名/行号信息了，这个等价于普通C/C++程序被strip的效果 -X 设置包中的变量值 -gcflags \"-N -l\" 编译目标程序的时候会嵌入运行时(runtime)的二进制，禁止优化和内联可以让运行时(runtime)中的函数变得更容易调试。gcflags 其实是给go编译器传入参数，也就是传给go tool compile的参数，因此可以用go tool compile --help查看所有可用的参数 -ldflags 给go链接器传入参数，实际是给go tool link的参数，可以用go tool link --help查看可用的参数。 -ldflags '-extldflags \"-static\"' 静态编译 ","date":"2022-03-16","objectID":"/go_build_args/:1:0","tags":["golang"],"title":"go 常用命令","uri":"/go_build_args/"},{"categories":["golang"],"content":"交叉编译 参数 说明 GOOS GOARCH linux 386 / amd64 / arm darwin 386 / amd64 feedbsd 386 / amd64 windows 386 / amd64 对于编译给ARM使用的Go程序，需要根据实际情况配置$GOARM，这是用来控制CPU的浮点协处理器的参数。 $GOARM默认是6，对于不支持VFP使用软件运算的老版本ARM平台要设置成5，支持VFPv1的设置成6，支持VFPv3的设置成7。 示例 GOARM=7 GOARCH=arm GOOS=linux go build -v -o fca ","date":"2022-03-16","objectID":"/go_build_args/:2:0","tags":["golang"],"title":"go 常用命令","uri":"/go_build_args/"},{"categories":["golang"],"content":"go mod // TODO ","date":"2022-03-16","objectID":"/go_build_args/:3:0","tags":["golang"],"title":"go 常用命令","uri":"/go_build_args/"},{"categories":["golang"],"content":"参考 golang编译时的参数传递（gcflags, ldflags） Golang交叉编译（跨平台编译）简述 交叉编译Go程序 ARM flags GOARM go mod使用 ","date":"2022-03-16","objectID":"/go_build_args/:4:0","tags":["golang"],"title":"go 常用命令","uri":"/go_build_args/"},{"categories":["web"],"content":"刚在打包项目时执行 yarn run build 时出现了 oom 的情况，具体报错信息如下： JavaScript heap out of memory \" 我的环境是 win10 专业版 WSL。 解决办法，设置 export NODE_OPTIONS=--max_old_space_size=4096，设置完之后重新执行 yarn run build 即可。 ","date":"2022-03-16","objectID":"/node_oom/:0:0","tags":["web","node"],"title":"JavaScript heap out of memory","uri":"/node_oom/"},{"categories":["web"],"content":"参考 Node.js heap out of memory ","date":"2022-03-16","objectID":"/node_oom/:1:0","tags":["web","node"],"title":"JavaScript heap out of memory","uri":"/node_oom/"},{"categories":["开发者手册"],"content":"Google,浏览器插件,插件下载","date":"2022-03-16","objectID":"/googe-plugin-download/","tags":["chrome"],"title":"将google浏览器插件下载到本地","uri":"/googe-plugin-download/"},{"categories":["开发者手册"],"content":"国内的网络太复杂了，在不能访问 google 的情况下，甚至都不能打开网上应用商店，所以我们需要一个方便的方式来下载google浏览器插件并分享 给需要的小伙伴。 我们打开任意一个浏览器插件，如： 浏览器插件 \" URL 地址栏中有一串字符串，这是唯一的，通过这个字符串可以获取到插件的下载地址，如： 插件UUID \" 下载地址为： https://clients2.google.com/service/update2/crx?response=redirect\u0026os=win\u0026arch=x64\u0026os_arch=x86_64\u0026nacl_arch=x86-64\u0026prod=chromecrx\u0026prodchannel=\u0026prodversion=77.0.3865.90\u0026lang=zh-CN\u0026acceptformat=crx2,crx3\u0026x=id%3D{XXXX}%26installsource%3Dondemand%26uc 将以上的 {XXXX} 替换为插件的 ID，就可以下载到本地了。 以下这个地址是Mote：语音笔记和反馈插件的下载地址，成功下载的插件是 .crx 结尾的文件。直接拖到浏览器中就会自动安装。 https://clients2.google.com/service/update2/crx?response=redirect\u0026os=win\u0026arch=x64\u0026os_arch=x86_64\u0026nacl_arch=x86-64\u0026prod=chromecrx\u0026prodchannel=\u0026prodversion=77.0.3865.90\u0026lang=zh-CN\u0026acceptformat=crx2,crx3\u0026x=id%3Dajphlblkfpppdpkgokiejbjfohfohhmk%26installsource%3Dondemand%26uc ","date":"2022-03-16","objectID":"/googe-plugin-download/:0:0","tags":["chrome"],"title":"将google浏览器插件下载到本地","uri":"/googe-plugin-download/"},{"categories":null,"content":"xiaobinqt's personal website,xiaobinqt,程序员,程序猿,xiaobinqt@163.com","date":"2022-03-06","objectID":"/about/","tags":null,"title":"About Me","uri":"/about/"},{"categories":null,"content":"缘起 很喜欢电影《五亿探长雷洛传》，电影一开头，由潮州迁居香港的青年雷洛，为了生计，投考香港警察，面试官问他，为什么要当警察，他回答，为了吃饭。 为了吃饭为了吃饭 \" 为了吃饭 大学毕业后，为了吃饭，便利用自己了解的一点编程知识开始码农之路。大学学的是通信工程，非计算机专业，编程之路困难重重，但好歹自己有自知之明，笨人多努力，相信通过自己的努力，可以让自己的编程技术更加完善。 好记性不如烂笔头，想着把自己工作期间遇到的问题，平时看到的好的文章，记录下来，也是记录自己的不足和成长，便有个这个网站。 建站的初衷不是为了炫耀所知，而是记录无知。 人知道得越多，就会发现无知的越多。有更广袤的世界可以探索，是莫大的快乐呀！ ","date":"2022-03-06","objectID":"/about/:1:0","tags":null,"title":"About Me","uri":"/about/"},{"categories":null,"content":"关于作者 👨‍💻 半路出家的程序猿，技术不精，但有一个成为技术大拿的梦想。 🤪 拖延症患者，持续性混吃等死，间接性踌躇满志。 💕 爱好读书，但总是边读边忘 😢。 ","date":"2022-03-06","objectID":"/about/:2:0","tags":null,"title":"About Me","uri":"/about/"},{"categories":null,"content":"职业生涯 2017/4 - 2019/3 在西安一家科技公司从事 PHP 开发。 2019/4 - 2021/3 在北京腾讯外包从事 PHP 和 Go 开发。 2021/4 - 至今 版权说明 本站图片和文字，除原创作品之外，部分来自互联网。 此类资源的原版权所有者可在任何时候、以任何理由要求本站停止使用，其中包括被本站编辑（比如加注说明）过的资源， 联系方式见下文。 ","date":"2022-03-06","objectID":"/about/:3:0","tags":null,"title":"About Me","uri":"/about/"},{"categories":null,"content":"联系方式 邮箱：xiaobinqt@163.com Github：@xiaobinqt 微信： 个人微信\" 个人微信 ","date":"2022-03-06","objectID":"/about/:4:0","tags":null,"title":"About Me","uri":"/about/"},{"categories":["golang"],"content":"RPC 是一种跨语言的协议，它可以让我们在不同的语言之间进行通信。 远程过程调用（英语：Remote Procedure Call，缩写为 RPC）是一个计算机通信协议。该协议允许运行于一台计算机的程序调用另一个 地址空间（通常为一个开放网络的一台计算机）的子程序，而程序员就像调用本地程序一样，无需额外地为这个交互作用编程（无需关注细节）。 RPC是一种服务器-客户端（Client/Server）模式，经典实现是一个通过发送请求-接受回应进行信息交互的系统。 ","date":"2022-03-05","objectID":"/grpc_demo/:0:0","tags":["golang"],"title":"grpc 入门应用","uri":"/grpc_demo/"},{"categories":["golang"],"content":"安装 go install github.com/golang/protobuf/protoc-gen-go@v1.4.0 go install google.golang.org/grpc/cmd/protoc-gen-go-grpc@v1.1 不推荐使用 google.golang.org/protobuf/cmd/protoc-gen-go@v1.26 这个版本太高了，可能会遇到以下这个问题， --go_out: protoc-gen-go: plugins are not supported; use 'protoc --go-grpc_out=...' to generate gRPC See https://grpc.io/docs/languages/go/quickstart/#regenerate-grpc-code for more information. 生成代码遇到的问题 \" 参考解决方案记一次奇妙的go-protobuf包升级之旅 protoc 工具安装 下载地址，下载解压将 bin 目录添加到环境变量中。 protoc \" ","date":"2022-03-05","objectID":"/grpc_demo/:1:0","tags":["golang"],"title":"grpc 入门应用","uri":"/grpc_demo/"},{"categories":["golang"],"content":"定义 proto 文件 syntax = \"proto3\"; // 使用protobuf版本3 option go_package = \"./protobuf\"; // 这个影响生成的目录及go的package命名 // 定义一个计算服务, 输入为CalcRequest, 输出为CalcResponse service CalculatorService { rpc calc(CalcRequest) returns (CalcResponse) {};}// 计算两个数某种运算(如加法)的参数 message CalcRequest { double a = 1; double b = 2; string op = 3;}// 计算结果 message CalcResponse { double r = 1;} ","date":"2022-03-05","objectID":"/grpc_demo/:2:0","tags":["golang"],"title":"grpc 入门应用","uri":"/grpc_demo/"},{"categories":["golang"],"content":"生成 .pb.go 文件 protoc --go_out=plugins=grpc:. calculator.proto 整体目录结构 \" ","date":"2022-03-05","objectID":"/grpc_demo/:3:0","tags":["golang"],"title":"grpc 入门应用","uri":"/grpc_demo/"},{"categories":["golang"],"content":"rpc server package main import ( \"context\" \"fmt\" \"net\" \"go.src/grpc/calculator/protobuf\" \"google.golang.org/grpc\" ) // 实现: CalculatorServiceServer接口, 在calculator.pb.go中定义 type server struct{} func (s server) Calc(ctx context.Context, req *protobuf.CalcRequest) (resp *protobuf.CalcResponse, err error) { a := req.GetA() b := req.GetB() op := req.GetOp() resp = \u0026protobuf.CalcResponse{} switch op { case \"+\": resp.R = a + b case \"-\": resp.R = a - b case \"*\": resp.R = a * b case \"/\": if b == 0 { err = fmt.Errorf(\"divided by zero\") return } resp.R = a / b } return } // 启动rpc server func main() { listener, err := net.Listen(\"tcp\", \"localhost:3233\") if err != nil { panic(err) } s := grpc.NewServer() protobuf.RegisterCalculatorServiceServer(s, \u0026server{}) fmt.Println(\"server start\") err = s.Serve(listener) if err != nil { panic(err) } } ","date":"2022-03-05","objectID":"/grpc_demo/:4:0","tags":["golang"],"title":"grpc 入门应用","uri":"/grpc_demo/"},{"categories":["golang"],"content":"rpc client package main import ( \"context\" \"fmt\" \"log\" \"go.src/grpc/calculator/protobuf\" \"google.golang.org/grpc\" \"google.golang.org/grpc/credentials/insecure\" ) func main() { // 连上grpc server //conn, err := grpc.Dial(\"localhost:3233\", grpc.WithInsecure()) conn, err := grpc.Dial(\"localhost:3233\", grpc.WithTransportCredentials(insecure.NewCredentials())) if err != nil { log.Fatalf(\"did not connect: %v\", err) } defer conn.Close() c := protobuf.NewCalculatorServiceClient(conn) // 调用远程方法 resp, err := c.Calc(context.Background(), \u0026protobuf.CalcRequest{ A: 1, B: 2, Op: \"+\", }) if err != nil { fmt.Println(\"calc err: \", err.Error()) return } fmt.Println(\"calc success,respR: \", resp.GetR()) // 3 } ","date":"2022-03-05","objectID":"/grpc_demo/:5:0","tags":["golang"],"title":"grpc 入门应用","uri":"/grpc_demo/"},{"categories":["golang"],"content":"运行测试 serverserver \" server clientclient \" client ","date":"2022-03-05","objectID":"/grpc_demo/:6:0","tags":["golang"],"title":"grpc 入门应用","uri":"/grpc_demo/"},{"categories":["golang"],"content":"示例下载 示例源码地址 ","date":"2022-03-05","objectID":"/grpc_demo/:7:0","tags":["golang"],"title":"grpc 入门应用","uri":"/grpc_demo/"},{"categories":["web"],"content":"Ajax 在请求时携带 cookie 信息,cookie 信息会被添加到请求头中,Cookie","date":"2022-03-01","objectID":"/ajax_req_add_cookie/","tags":["web"],"title":"ajax 在请求时携带 cookie 信息","uri":"/ajax_req_add_cookie/"},{"categories":["web"],"content":"最近有个需求在使用 $.ajax 时需要把 cookie 信息也带着，google 下发现可以这么写： $.ajax({ url: \"/nodered/nodes\", headers: { Accept: \"text/html\", }, xhrFields: { withCredentials: true // 携带 cookie 信息 }, success: function (data) { console.log(data) $(\"#red-ui-palette-container\").html(data) }, error: function (jqXHR) { console.log(jqXHR) } }); ","date":"2022-03-01","objectID":"/ajax_req_add_cookie/:0:0","tags":["web"],"title":"ajax 在请求时携带 cookie 信息","uri":"/ajax_req_add_cookie/"},{"categories":["c语言"],"content":"C语言定义字符串的方法,C语言，字符串","date":"2022-02-17","objectID":"/c_define_string/","tags":["c语言"],"title":"C语言定义字符串的方法","uri":"/c_define_string/"},{"categories":["c语言"],"content":" #include \u003cstdio.h\u003e int main(void) { char a[6] = {'F', 'i', 's', 'h', 'C', '\\0'}; // 需要主动加上 \\0 char a1[] = {'F', 'i', 's', 'h', 'C', '\\0'}; // 需要主动加上 \\0 char a2[] = {\"FishC\"}; char a3[] = \"FishC\"; printf(\"a: %s \\n\", a); printf(\"a1: %s \\n\", a1); printf(\"a2: %s \\n\", a2); printf(\"a3: %s \\n\", a3); return 0; } 运行结果： c语言定义字符串 \" ","date":"2022-02-17","objectID":"/c_define_string/:0:0","tags":["c语言"],"title":"C语言定义字符串的方法","uri":"/c_define_string/"},{"categories":["golang"],"content":"在 php 中可以直接在 break 和 continue 后加 num ，比如 break 2或 continue 2。 break num 是结束外层第 num 层整个循环体，continue num 是结束外层第 num 层单次循环。 类比 php ，go 中不能直接在关键字后加 num ，但是可以用 label 关键字代替 num。 ","date":"2022-02-16","objectID":"/break_continue_goto_label/:0:0","tags":["golang"],"title":"golang break，continue，goto label 的区别","uri":"/break_continue_goto_label/"},{"categories":["golang"],"content":"continue label package main import ( \"fmt\" \"math\" ) func main() { // 找出 int 切片的最小值 var matrix = []int{10, 2, 4, 0} var min = math.MinInt64 next: for _, v := range matrix { for _, v1 := range matrix { if v \u003e v1 { continue next // 终止当前循环，跳到 label 继续下一次循环 } } min = v } fmt.Println(\"最小值为: \", min) } ","date":"2022-02-16","objectID":"/break_continue_goto_label/:1:0","tags":["golang"],"title":"golang break，continue，goto label 的区别","uri":"/break_continue_goto_label/"},{"categories":["golang"],"content":"break label package main import ( \"fmt\" \"math\" ) func main() { // 获取 index 2 的值，这里使用 2 层循环主要是为了说明问题 var matrix = []int{10, 2, 4, 0} var index2Val = math.MinInt64 next: for _, v := range matrix { fmt.Println(v) for index, v1 := range matrix { index2Val = v1 if index == 2 { break next // 跳出循环到 label 处 } } } fmt.Println(\"index 3 值为: \", index2Val) } ","date":"2022-02-16","objectID":"/break_continue_goto_label/:2:0","tags":["golang"],"title":"golang break，continue，goto label 的区别","uri":"/break_continue_goto_label/"},{"categories":["golang"],"content":"goto label 非必要不使用，可以跳到任何地方。 package main import ( \"fmt\" \"math\" ) func main() { var matrix = []int{10, 2, 4, 0} var index2Val = math.MinInt64 for _, v := range matrix { fmt.Println(v) for index, v1 := range matrix { index2Val = v1 if index == 2 { goto next } } } fmt.Println(\"index 3 值为: \", index2Val) next: fmt.Println(\"goto this....\") } ","date":"2022-02-16","objectID":"/break_continue_goto_label/:3:0","tags":["golang"],"title":"golang break，continue，goto label 的区别","uri":"/break_continue_goto_label/"},{"categories":["golang"],"content":"今天在编译 go 项目时出现了如下错误： /usr/local/go/pkg/tool/linux_amd64/link: running gcc failed: exit status 1 /usr/bin/ld: cannot find -lpthread /usr/bin/ld: cannot find -lc collect2: error: ld returned 1 exit status 解决办法： yum install glibc-static.x86_64 -y ","date":"2022-02-10","objectID":"/build_running_gcc_failed/:0:0","tags":["golang","build"],"title":"running gcc failed: exit status 1","uri":"/build_running_gcc_failed/"},{"categories":["算法与数学"],"content":"一致性Hash,hash算法,数据倾斜","date":"2022-01-15","objectID":"/consistent_hash/","tags":["算法"],"title":"一致性 hash","uri":"/consistent_hash/"},{"categories":["算法与数学"],"content":"存在的意义 一致性哈希算法解决了普通余数 Hash 算法伸缩性差的问题，可以保证在上线、下线服务器的情况下尽量有多的请求命中原来路由到的服务器。 ","date":"2022-01-15","objectID":"/consistent_hash/:1:0","tags":["算法"],"title":"一致性 hash","uri":"/consistent_hash/"},{"categories":["算法与数学"],"content":"优化 一致性哈希算法在服务节点太少时，容易因为节点分部不均匀而造成数据倾斜问题。可以通过通过增加虚拟节点来解决数据倾斜问题。 如果存在大量的虚拟节点，节点的查找性能就成为必须考虑的因数。可以使用红黑树 来加快查找速度， ","date":"2022-01-15","objectID":"/consistent_hash/:2:0","tags":["算法"],"title":"一致性 hash","uri":"/consistent_hash/"},{"categories":["算法与数学"],"content":"参考 一致性Hash(Consistent Hashing)原理剖析及Java实现 图解一致性哈希算法 golang实现一致性hash环及优化方法 一致性哈希 ","date":"2022-01-15","objectID":"/consistent_hash/:3:0","tags":["算法"],"title":"一致性 hash","uri":"/consistent_hash/"},{"categories":["收藏"],"content":"在线书籍 build-web-application-with-golang Mastering_Go golang 修养之路 Go语言101 PHP扩展开发及内核应用 JavaScript 标准参考教程 ES6 入门教程 JavaScript 教程 网道 PHP编程之道 gairuo Kubernetes 文档 ","date":"2021-10-17","objectID":"/memo/:1:0","tags":["备忘录"],"title":"书籍/工具收藏","uri":"/memo/"},{"categories":["收藏"],"content":"工具收藏 navicat premium15破解教程 ","date":"2021-10-17","objectID":"/memo/:2:0","tags":["备忘录"],"title":"书籍/工具收藏","uri":"/memo/"},{"categories":["收藏"],"content":"文章收藏 go1.16 embed 用法 Go常见面试题【由浅入深】2022版 ","date":"2021-10-17","objectID":"/memo/:3:0","tags":["备忘录"],"title":"书籍/工具收藏","uri":"/memo/"},{"categories":["golang"],"content":"总结 make用于内建类型（map、slice 和channel）的内存分配。new用于各种类型的内存分配。 new返回指针，指向新分配的类型 T 的零值。 make返回初始化后的（非零）值。 ","date":"2021-06-21","objectID":"/new_make_difference/:1:0","tags":["golang"],"title":"golang make 和 new 的区别","uri":"/new_make_difference/"},{"categories":["golang"],"content":"参考 make、new操作 Go make 和 new的区别 ","date":"2021-06-21","objectID":"/new_make_difference/:2:0","tags":["golang"],"title":"golang make 和 new 的区别","uri":"/new_make_difference/"},{"categories":["git"],"content":"入职新公司，就在 git 的使用上被各种虐。整理一篇文档，对这个问题梳理总结下。 之前用 git 都是直接新建分支，然后 PR review 后合到主分支，现在是先 fork 下，之前没用过 fork 😢 ，其实就是多了一步，从自己仓库的分支提 PR 。 ","date":"2021-04-29","objectID":"/pull_request/:0:0","tags":["git"],"title":"github PR 简单使用","uri":"/pull_request/"},{"categories":["git"],"content":"clone 代码 forkfork \" fork fork 代码后 clone 到本地。 git clone git@github.com:xxxxx/dev-git.git cloneclone \" clone 我们可以用 git remote -v 看下远程仓库情况： git remote -vgit remote -v \" git remote -v ","date":"2021-04-29","objectID":"/pull_request/:1:0","tags":["git"],"title":"github PR 简单使用","uri":"/pull_request/"},{"categories":["git"],"content":"添加远程仓库 用 git remote add 添加远程仓库，这里的远程就是我 fork 的那个仓库。 git remote add upstream git@github.xxxxx/dev-git.git 这里的 upstream 是远程仓库的别名，类似 origin 。 git remoteadd upstream \" git remote 现在我们可以看到已经有 2 个远程仓库地址了，origin 是我自己的远程仓库，upstream 是别人的，也就是真实项目的远程仓库。 ","date":"2021-04-29","objectID":"/pull_request/:2:0","tags":["git"],"title":"github PR 简单使用","uri":"/pull_request/"},{"categories":["git"],"content":"PR 我们现在可以 upstream 远程仓库中提交一个 PR。先 fetch 一下 upstream 远程仓库的代码。确保我们的代码是最新的。 fetch \" 接下来就可以在 ide 上操作了。 ide operate \" 我们可以看到远程分支了 upstream/main 和 origin/main ，upstream 是真正的项目地址，origin 是 fork 到我们仓库的分支。 checkout 下 upstream/main ： ide operate \" \" 再拉下最新的代码 ide operate \" 再切回到我们的 origin/main 分支 从我们的分支 checkout 一个新的开发分支 dev origin main \" dev branch \" rebase 下远程分支的代码 \" 我们简单修改一行，提下代码 add \" push push1 \" push2 \" push 完成后我们的仓库会出现提示 \" 现在我们就可以提一个 PR 了。 \" 成功提了一个 PR \" ","date":"2021-04-29","objectID":"/pull_request/:3:0","tags":["git"],"title":"github PR 简单使用","uri":"/pull_request/"},{"categories":["git"],"content":"更新代码 \" PR 合并之后我们需要更新下代码： checkout 到 upstream-main 分支，拉下代码 \" 再切到 origin/dev 分支 rebase 下 upstream-main \" \" 以上，一个闭环结束。 ","date":"2021-04-29","objectID":"/pull_request/:4:0","tags":["git"],"title":"github PR 简单使用","uri":"/pull_request/"},{"categories":["golang"],"content":"server package main import ( \"fmt\" \"net\" \"time\" ) func main() { // 创建监听 socket, err := net.ListenUDP(\"udp4\", \u0026net.UDPAddr{ IP: []byte{127, 0, 0, 1}, Port: 8080, }) if err != nil { fmt.Println(\"监听失败!\", err) return } defer socket.Close() for { // 读取数据 data := make([]byte, 4096) read, remoteAddr, err := socket.ReadFromUDP(data) if err != nil { fmt.Println(\"读取数据失败!\", err) continue } fmt.Println(read, remoteAddr) fmt.Printf(\"接收到客户端数据，%s\\n\\n\", data) // 发送数据 senddata := []byte(\"server send data，hello client!\" + time.Now().Format(\"2006-01-02 15:04:05\")) _, err = socket.WriteToUDP(senddata, remoteAddr) if err != nil { fmt.Println(\"发送数据失败!\", err.Error()) return } } } ","date":"2021-04-01","objectID":"/upd_demo/:1:0","tags":["golang"],"title":"golang udp 简单使用","uri":"/upd_demo/"},{"categories":["golang"],"content":"client package main import ( \"fmt\" \"net\" \"time\" ) func main() { // 创建连接 socket, err := net.DialUDP(\"udp4\", nil, \u0026net.UDPAddr{ IP: []byte{127, 0, 0, 1}, Port: 8080, }) if err != nil { fmt.Println(\"连接失败!\", err) return } defer socket.Close() // 发送数据 senddata := []byte(\"client send message，hello server!\" + time.Now().Format(\"2006-01-02 15:04:05\")) _, err = socket.Write(senddata) if err != nil { fmt.Println(\"发送数据失败!\", err) return } // 接收数据 data := make([]byte, 4096) read, remoteAddr, err := socket.ReadFromUDP(data) if err != nil { fmt.Println(\"读取数据失败!\", err) return } fmt.Println(read, remoteAddr) fmt.Printf(\"接收到服务器端数据，%s\\n\", data) } ","date":"2021-04-01","objectID":"/upd_demo/:2:0","tags":["golang"],"title":"golang udp 简单使用","uri":"/upd_demo/"},{"categories":["golang"],"content":"源码 源码地址 ","date":"2021-04-01","objectID":"/upd_demo/:3:0","tags":["golang"],"title":"golang udp 简单使用","uri":"/upd_demo/"},{"categories":["算法与数学"],"content":"常见缓存淘汰策略，淘汰策略的实现，FIFO，LRU，LFU","date":"2020-03-05","objectID":"/common_cache_-strategies/","tags":["算法"],"title":"常见缓存淘汰策略","uri":"/common_cache_-strategies/"},{"categories":["算法与数学"],"content":"常见缓存淘汰策略 ","date":"2020-03-05","objectID":"/common_cache_-strategies/:0:0","tags":["算法"],"title":"常见缓存淘汰策略","uri":"/common_cache_-strategies/"},{"categories":["算法与数学"],"content":"FIFO First In First Out(FIFO)，先进先出，也就是淘汰缓存中最老(最早添加)的记录。FIFO 认为，最早添加的记录，其不再被使用的可能性比刚添加的可能性大。这种算法的实现也非常简单，创建一个队列，新增记录添加到队尾， 每次内存不够时，淘汰队首。但是很多场景下，部分记录虽然是最早添加但也最常被访问，而不得不因为呆的时间太长而被淘汰。这类数据会被频繁地添加进缓存，又被淘汰出去，导致缓存命中率降低。 ","date":"2020-03-05","objectID":"/common_cache_-strategies/:1:0","tags":["算法"],"title":"常见缓存淘汰策略","uri":"/common_cache_-strategies/"},{"categories":["算法与数学"],"content":"LFU Least Frequently Used(LFU)，最少使用，也就是淘汰缓存中访问频率最低的记录。LFU 认为，如果数据过去被访问多次， 那么将来被访问的频率也更高。LFU 的实现需要维护一个按照访问次数排序的队列，每次访问，访问次数加1，队列重新排序， 淘汰时选择访问次数最少的即可。LFU 算法的命中率是比较高的，但缺点也非常明显，维护每个记录的访问次数，对内存的消耗是很高的； 另外，如果数据的访问模式发生变化，LFU 需要较长的时间去适应，也就是说 LFU 算法受历史数据的影响比较大。例如某个数据历史上访问次数奇高，但在某个时间点之后几乎不再被访问，但因为历史访问次数过高，而迟迟不能被淘汰。 ","date":"2020-03-05","objectID":"/common_cache_-strategies/:2:0","tags":["算法"],"title":"常见缓存淘汰策略","uri":"/common_cache_-strategies/"},{"categories":["算法与数学"],"content":"LRU Least Recently Used(LRU)，最近最少使用，相对于仅考虑时间因素的 FIFO 和仅考虑访问频率的 LFU，LRU 算法可以认为是相对平衡的 一种淘汰算法。LRU 认为，如果数据最近被访问过，那么将来被访问的概率也会更高。LRU 算法的实现非常简单，维护一个队列，如果某条记录被访问了， 则移动到队尾，那么队首则是最近最少访问的数据，淘汰该条记录即可。 ","date":"2020-03-05","objectID":"/common_cache_-strategies/:3:0","tags":["算法"],"title":"常见缓存淘汰策略","uri":"/common_cache_-strategies/"},{"categories":["开发者手册"],"content":"阿里云,SSL,免费证书使用,aliyun,ali,证书,TLS","date":"2019-06-07","objectID":"/ali_ssl/","tags":["ssl","aliyun"],"title":"阿里云 SSL 免费证书使用","uri":"/ali_ssl/"},{"categories":["开发者手册"],"content":"申请 证书申请地址 在这里插入图片描述 \" 申请完成页面 在这里插入图片描述 \" 将主机记录解析 在这里插入图片描述 \" 在这里插入图片描述 \" 在这里插入图片描述 \" 将主机记录和记录值填写 在这里插入图片描述 \" 解析成功后下载证书 在这里插入图片描述 \" 我用的是 Apache ,所以下载的是 Apache 在这里插入图片描述 \" ","date":"2019-06-07","objectID":"/ali_ssl/:1:0","tags":["ssl","aliyun"],"title":"阿里云 SSL 免费证书使用","uri":"/ali_ssl/"},{"categories":["开发者手册"],"content":"上传证书 由于本人使用的是 apache ,以下配置是 apache 的通用配置,具体可参看官方 文档 在 apache 的路径下新建一个 cert 目录,其实该目录建在哪里都可以,但是放在 apache 下方便管理。 \" 在 cert 目录下可以建不同的文件夹放在不同域名或子域名的 ssl 文件。 \" 把我们刚才下载的证书上传到服务器上 \" ","date":"2019-06-07","objectID":"/ali_ssl/:2:0","tags":["ssl","aliyun"],"title":"阿里云 SSL 免费证书使用","uri":"/ali_ssl/"},{"categories":["开发者手册"],"content":"配置 这是基本的配置语句 # 添加 SSL 协议支持协议，去掉不安全的协议 SSLProtocol all -SSLv2 -SSLv3 # 修改加密套件如下 SSLCipherSuite HIGH:!RC4:!MD5:!aNULL:!eNULL:!NULL:!DH:!EDH:!EXP:+MEDIUM SSLHonorCipherOrder on # 证书公钥配置 SSLCertificateFile cert/a_public.crt # 证书私钥配置 SSLCertificateKeyFile cert/a.key # 证书链配置，如果该属性开头有 '#'字符，请删除掉 SSLCertificateChainFile cert/a_chain.crt 我们将默认的配置 copy 一份出来,取一个跟域名有关的文件名 cp /etc/apache2/sites-available/000-default.conf /etc/apache2/sites-available/www.xiaobinqt.cn.conf 具体配置可参考 \u003cVirtualHost *:80\u003e ServerName www.xiaobinqt.cn Redirect permanent / https://www.xiaobinqt.cn/ \u003c/VirtualHost\u003e \u003cVirtualHost *:443\u003e SSLEngine On # 添加 SSL 协议支持协议，去掉不安全的协议 SSLProtocol all -SSLv2 -SSLv3 # 修改加密套件如下 SSLCipherSuite HIGH:!RC4:!MD5:!aNULL:!eNULL:!NULL:!DH:!EDH:!EXP:+MEDIUM SSLHonorCipherOrder on # 证书公钥配置 SSLCertificateFile cert/xiaobinqt.cn/2324042_www.xiaobinqt.cn_public.crt # 证书私钥配置 SSLCertificateKeyFile cert/xiaobinqt.cn/2324042_www.xiaobinqt.cn.key # 证书链配置，如果该属性开头有 '#'字符，请删除掉 SSLCertificateChainFile cert/xiaobinqt.cn/2324042_www.xiaobinqt.cn_chain.crt # etc ServerName www.xiaobinqt.cn ProxyPreserveHost On ProxyRequests Off ProxyPass / http://localhost:30007/ ProxyPassReverse / http://localhost:30007/ \u003c/VirtualHost\u003e 我用的是 docker 服务,如果你的只是项目文件夹可以参考这样配置 \u003cVirtualHost *:80\u003e # The ServerName directive sets the request scheme, hostname and port that # the server uses to identify itself. This is used when creating # redirection URLs. In the context of virtual hosts, the ServerName # specifies what hostname must appear in the request's Host: header to # match this virtual host. For the default virtual host (this file) this # value is not decisive as it is used as a last resort host regardless. # However, you must set it for any further virtual host explicitly. #ServerName www.example.com #ServerAdmin webmaster@localhost ServerName www.xiaobinqt.cn DocumentRoot /var/www/html Redirect permanent / https://www.xiaobinqt.cn/ # Available loglevels: trace8, ..., trace1, debug, info, notice, warn, # error, crit, alert, emerg. # It is also possible to configure the loglevel for particular # modules, e.g. #LogLevel info ssl:warn ErrorLog ${APACHE_LOG_DIR}/error.log CustomLog ${APACHE_LOG_DIR}/access.log combined # For most configuration files from conf-available/, which are # enabled or disabled at a global level, it is possible to # include a line for only one particular virtual host. For example the # following line enables the CGI configuration for this host only # after it has been globally disabled with \"a2disconf\". #Include conf-available/serve-cgi-bin.conf \u003c/VirtualHost\u003e \u003cVirtualHost *:443\u003e SSLEngine On # 添加 SSL 协议支持协议，去掉不安全的协议 SSLProtocol all -SSLv2 -SSLv3 # 修改加密套件如下 SSLCipherSuite HIGH:!RC4:!MD5:!aNULL:!eNULL:!NULL:!DH:!EDH:!EXP:+MEDIUM SSLHonorCipherOrder on # 证书公钥配置 SSLCertificateFile cert/xiaobinqt.cn/public.pem # 证书私钥配置 SSLCertificateKeyFile cert/xiaobinqt.cn/214792197160511.key # 证书链配置，如果该属性开头有 '#'字符，请删除掉 SSLCertificateChainFile cert/xiaobinqt.cn/chain.pem # etc ServerName www.xiaobinqt.cn \u003c/VirtualHost\u003e 以上配置全部基于 apache ,如果你用的不是 apache ,以上配置可能不适合你. 关于 apache 服务的一些其他知识可以参考这篇文章,该文章可能需要翻~墙访问. 配置完成后重启服务,可以利用 curl 命令查看是否配置成功. curl -I localhost:xxx \" 对于 ssl 是否配置成功可以通过浏览器查看. \" 可以看到这是我们最新申请的一年的 ssl 证书. \" ","date":"2019-06-07","objectID":"/ali_ssl/:3:0","tags":["ssl","aliyun"],"title":"阿里云 SSL 免费证书使用","uri":"/ali_ssl/"},{"categories":["开发者手册"],"content":"Windows,系统,重做系统,win,win10,U盘安装系统","date":"2018-10-07","objectID":"/redo_system/","tags":["windows"],"title":"windows 重做系统","uri":"/redo_system/"},{"categories":["开发者手册"],"content":"下载系统 首先我们需要一个最小 4G 大的 U 盘 image \" 进入大白菜网站下载大白菜装机版安装到电脑 image \" image \" 将 U 盘插到电脑上,双击打开大白菜装机版,它会自动读到我们插入的 U 盘，自动匹配默认模式,不需要手动选择。 image \" 点击开始制作 –\u003e 确认 image \" 等待写入数据包完成和格式化完成后关掉大白菜软件 image \" image \" image \" 制作完 U 盘启动盘后我们的 U 盘会变成这样说明启动盘已经制作成功 ! image去itellyou下载需要安装的操作系统 ! image \" 比如我们要安装这个版本的 win10 image \" 通过百度网盘下载 ed2k 文件资源,然后再通过百度网盘下载到电脑本地,可以放在除 C 盘外的其他盘中 image \" 下载到本地的文件是这样的光盘映像文件 ! image \" 将我们下载到电脑本地的光盘映像文件复制到刚制作完成的 U 盘启动盘中,复制完成后我们 U 盘启动盘就全部制作完成了 image \" ","date":"2018-10-07","objectID":"/redo_system/:1:0","tags":["windows"],"title":"windows 重做系统","uri":"/redo_system/"},{"categories":["开发者手册"],"content":"重做系统 将我们制作好的 U 盘启动盘插到需要重做系统的电脑上,重启电脑一直按 F12 进入 bios 界面(不同的电脑可能按键不同,可以百度) image \" 选择 usb 方式,回车进入大白菜启动方式,选择 02 方式进入 image \" 进入 u 盘驱动界面,系统默认会选择 C 盘为系统盘,直接点击确定 image \" 确定后进入格式化 C 盘阶段,所有配置为默认配置,直接确定,等待格式化完成! image \" 格式化完成后选择 是 重启电脑,拔出 u 盘 等待电脑重启 ","date":"2018-10-07","objectID":"/redo_system/:2:0","tags":["windows"],"title":"windows 重做系统","uri":"/redo_system/"},{"categories":["开发者手册"],"content":"安装系统完成 image \" image \" ","date":"2018-10-07","objectID":"/redo_system/:3:0","tags":["windows"],"title":"windows 重做系统","uri":"/redo_system/"}]